{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"],"fields":{"title":{"boost":1000.0},"text":{"boost":1.0},"tags":{"boost":1000000.0}}},"docs":[{"location":"","title":"Live STT Documentation (v7.3)","text":"<p>Welcome to the documentation for Live STT, a resilient, real-time transcription appliance designed for church environments.</p> <p>Current Version: v7.3 (Industrial Split-Brain)</p>"},{"location":"#getting-started","title":"\ud83d\ude80 Getting Started","text":"<ul> <li>Quickstart Guide: Deploy the system in 10 minutes.</li> <li>Hardware Bill of Materials: What to buy (ASRock NUC, Focusrite).</li> <li>User Journey Maps: Understand how the system is used.</li> </ul>"},{"location":"#developer-resources","title":"\ud83d\udee0\ufe0f Developer Resources","text":"<ul> <li>Contributing Guide: Setup your dev environment.</li> <li>API Reference: NATS &amp; REST API documentation.</li> <li>Project Charter: Project goals and stakeholders.</li> </ul>"},{"location":"#search","title":"\ud83d\udd0d Search","text":"<p>Use the search bar at the top to find specific topics.</p>"},{"location":"ToDo/","title":"ToDo","text":"<ul> <li>[ ] Clean up mkdocs navigation</li> </ul>"},{"location":"api/","title":"API Reference (v7.3)","text":""},{"location":"api/#overview","title":"Overview","text":"<p>This document documents the internal APIs used for inter-service communication (NATS) and the external REST API exposed by the <code>api-gateway</code>.</p>"},{"location":"api/#1-rest-api-api-gateway","title":"1. REST API (<code>api-gateway</code>)","text":"<p>Base URL: <code>http://localhost:8000</code> Docs URL: <code>http://localhost:8000/docs</code> (Swagger UI)</p>"},{"location":"api/#authentication","title":"Authentication","text":"<p>Currently, the API is open for local network access. Future versions (M7) will implement JWT auth.</p>"},{"location":"api/#endpoints","title":"Endpoints","text":""},{"location":"api/#system-status","title":"System Status","text":"<ul> <li>GET <code>/health</code></li> <li>Description: System health check.</li> <li>Response: <code>{\"status\": \"ok\", \"services\": {\"nats\": \"ok\", ...}}</code></li> </ul>"},{"location":"api/#transcription-management","title":"Transcription Management","text":"<ul> <li>GET <code>/v1/transcription/status</code></li> <li>Description: Check if transcription is active.</li> <li>POST <code>/v1/transcription/start</code></li> <li>Description: Manually start transcription stream.</li> <li>POST <code>/v1/transcription/stop</code></li> <li>Description: Manually stop transcription stream.</li> </ul>"},{"location":"api/#vocabulary-management","title":"Vocabulary Management","text":"<ul> <li>GET <code>/v1/admin/phrases</code></li> <li>Description: List custom vocabulary.</li> <li>POST <code>/v1/admin/phrases</code></li> <li>Description: Add new phrase.</li> <li>Body: <code>{\"phrase\": \"Eucharist\", \"boost\": 5}</code></li> <li>DELETE <code>/v1/admin/phrases/{id}</code></li> <li>Description: Remove phrase.</li> </ul>"},{"location":"api/#biometric-enrollment","title":"Biometric Enrollment","text":"<ul> <li>POST <code>/v1/admin/enrollment</code></li> <li>Description: Start enrollment session for a speaker.</li> <li>Body: <code>{\"name\": \"Pastor Mike\"}</code></li> <li>DELETE <code>/v1/admin/enrollment/{id}</code></li> <li>Description: Delete voiceprint and crypto-shred key.</li> </ul>"},{"location":"api/#2-websocket-api-api-gateway","title":"2. WebSocket API (<code>api-gateway</code>)","text":"<p>Endpoint: <code>ws://localhost:8000/ws/sub</code></p>"},{"location":"api/#client-protocol","title":"Client Protocol","text":"<p>Clients (Web UI) connect to receive real-time updates.</p>"},{"location":"api/#message-types","title":"Message Types","text":"<p>1. Transcript (Final)</p> <pre><code>{\n  \"type\": \"transcript\",\n  \"payload\": {\n    \"text\": \"Welcome to the service.\",\n    \"is_final\": true,\n    \"speaker\": \"Pastor Mike\",\n    \"timestamp\": 1715432100.5\n  }\n}\n</code></pre> <p>2. Transcript (Interim)</p> <pre><code>{\n  \"type\": \"transcript\",\n  \"payload\": {\n    \"text\": \"Welcome to the...\",\n    \"is_final\": false,\n    \"speaker\": \"Unknown\",\n    \"timestamp\": 1715432100.6\n  }\n}\n</code></pre> <p>3. System Status</p> <pre><code>{\n  \"type\": \"status\",\n  \"payload\": {\n    \"state\": \"connected\",  // connected, connecting, error\n    \"audio_level\": -20.5   // dBFS\n  }\n}\n</code></pre>"},{"location":"api/#3-nats-internal-api","title":"3. NATS Internal API","text":"<p>Broker URL: <code>nats://nats:4222</code></p>"},{"location":"api/#subject-structure","title":"Subject Structure","text":"Subject Publisher Subscriber Payload Format <code>audio.raw</code> audio-producer stt-provider, identifier Binary PCM (16kHz, S16LE) <code>text.transcript</code> stt-provider identity-manager JSON <code>identity.event</code> identifier identity-manager JSON <code>events.merged</code> identity-manager api-gateway JSON <code>system.alert</code> all api-gateway JSON"},{"location":"api/#message-schemas","title":"Message Schemas","text":"<p>See Data Dictionary for full schema definitions.</p>"},{"location":"api/#4-data-models","title":"4. Data Models","text":"<p>See Data Dictionary.</p>"},{"location":"quickstart/","title":"Quickstart Guide (v7.3)","text":""},{"location":"quickstart/#overview","title":"Overview","text":"<p>This guide will help you deploy the Live STT system on the Tier 1 (Industrial x86) platform or a Tier 2 (Desktop) environment for testing.</p> <p>[!IMPORTANT] This guide is for end-users and administrators. If you are a developer looking to contribute code, please see CONTRIBUTING.md.</p>"},{"location":"quickstart/#prerequisites","title":"Prerequisites","text":""},{"location":"quickstart/#hardware","title":"Hardware","text":"<ul> <li>Compute: ASRock Industrial NUC BOX-N97 (Tier 1) OR Desktop PC (Tier 2)</li> <li>Audio: Focusrite Scarlett Solo (or similar USB interface)</li> <li>Network: Ethernet connection (preferred)</li> </ul>"},{"location":"quickstart/#software-accounts","title":"Software Accounts","text":"<ul> <li>Deepgram: Sign up and create an API Key.</li> <li>BalenaCloud (Tier 1 only): Sign up for a free account.</li> </ul>"},{"location":"quickstart/#option-a-production-deployment-industrial-nuc-balena","title":"Option A: Production Deployment (Industrial NUC + Balena)","text":""},{"location":"quickstart/#1-create-fleet","title":"1. Create Fleet","text":"<ol> <li>Log in to BalenaCloud.</li> <li>Click \"Create Fleet\".</li> <li>Name: <code>live-stt-production</code>.</li> <li>Device Type: Generic x86_64 (GPT).</li> </ol>"},{"location":"quickstart/#2-flash-device","title":"2. Flash Device","text":"<ol> <li>Click \"Add Device\" in your new fleet.</li> <li>Download the BalenaOS image (Development edition recommended for initial setup).</li> <li>Flash to USB Drive using BalenaEtcher.</li> <li>Insert USB into NUC, power on, and boot from USB (F11/F12).</li> <li>Install BalenaOS to internal NVMe when prompted.</li> </ol>"},{"location":"quickstart/#3-configure-variables","title":"3. Configure Variables","text":"<p>In the Balena Dashboard, go to Variables and add: - <code>DEEPGRAM_API_KEY</code>: <code>&lt;your-deepgram-key&gt;</code> - <code>LOG_LEVEL</code>: <code>INFO</code></p>"},{"location":"quickstart/#4-deploy-code","title":"4. Deploy Code","text":"<p>Install Balena CLI on your computer:</p> <pre><code># Login\nbalena login\n\n# Push code\ngit clone https://github.com/yourusername/live-stt.git\ncd live-stt\nbalena push live-stt-production\n</code></pre>"},{"location":"quickstart/#5-verify","title":"5. Verify","text":"<p>Visit the device's public URL (enable in Balena dashboard) or local IP: <code>https://&lt;device-ip&gt;:8000</code>.</p>"},{"location":"quickstart/#option-b-local-testing-docker-compose","title":"Option B: Local Testing (Docker Compose)","text":""},{"location":"quickstart/#1-install-docker","title":"1. Install Docker","text":"<p>Ensure Docker Desktop is installed and running.</p>"},{"location":"quickstart/#2-clone-configure","title":"2. Clone &amp; Configure","text":"<pre><code>git clone https://github.com/yourusername/live-stt.git\ncd live-stt\n\n# Create environment file\ncp .env.example .env\n</code></pre>"},{"location":"quickstart/#3-set-api-key","title":"3. Set API Key","text":"<p>Edit <code>.env</code> and paste your key:</p> <pre><code>DEEPGRAM_API_KEY=a1b2c3d4...\n</code></pre>"},{"location":"quickstart/#4-run","title":"4. Run","text":"<pre><code>docker compose up\n</code></pre>"},{"location":"quickstart/#5-access","title":"5. Access","text":"<p>Open browser to <code>http://localhost:8000</code>.</p>"},{"location":"quickstart/#next-steps","title":"Next Steps","text":"<ul> <li>Connect Audio: Setup your Focusrite interface.</li> <li>Operations: Learn how to manage the system.</li> <li>Troubleshooting: Fix common issues.</li> </ul>"},{"location":"00_meta/compliance_matrix/","title":"Compliance Matrix","text":"Regulation Requirement Status Implementation Details GDPR Right to be Forgotten TODO CCPA Data Access Request TODO BIPA Biometric Consent TODO"},{"location":"00_meta/project_charter/","title":"Project Charter","text":""},{"location":"00_meta/project_charter/#1-project-authorization","title":"1. Project Authorization","text":"<p>Project Name: Live STT Date: 2025-11-20</p>"},{"location":"00_meta/project_charter/#2-project-goal","title":"2. Project Goal","text":"<p>To provide a resilient, real-time speech-to-text appliance for live events that ensures accessibility for the hearing impaired without recurring subscription costs.</p>"},{"location":"00_meta/project_charter/#3-scope","title":"3. Scope","text":""},{"location":"00_meta/project_charter/#in-scope","title":"In-Scope","text":"<ul> <li>Real-time transcription of live audio feeds (PA system).</li> <li>Local web interface for viewing transcripts on personal devices.</li> <li>Speaker identification for known staff (e.g., \"Pastor Mike\").</li> <li>Multi-tier hardware support (Industrial x86 NUC, Desktop GPU, CPU-only).</li> <li>Secure management of biometric data (voiceprints).</li> </ul>"},{"location":"00_meta/project_charter/#out-of-scope","title":"Out-of-Scope","text":"<ul> <li>Projector/HDMI output for open captioning (deferred to V2).</li> <li>Translation into other languages (deferred to V2).</li> <li>Cloud-based archiving or VOD integration.</li> <li>Mobile app (web UI is responsive).</li> </ul>"},{"location":"00_meta/project_charter/#4-project-maintainer","title":"4. Project Maintainer","text":"<p>Creator/Maintainer: Tom Dakan (tomdakan@gmail.com)</p>"},{"location":"00_meta/project_charter/#5-target-audience","title":"5. Target Audience","text":"<p>This is an open-source project designed to serve churches and other live event venues seeking accessible, cost-effective real-time transcription. While initially developed for a specific church community, the goal is to create a generalizable solution for any organization with similar needs.</p>"},{"location":"00_meta/raci_matrix/","title":"RACI Matrix","text":"<p>R = Responsible (Doer) A = Accountable (Approver - Only One) C = Consulted (Two-way communication) I = Informed (One-way communication)</p> Deliverable / Activity PM Tech Lead Dev QA Ops Requirements Gathering A C I I I Architecture Design I A C I C Implementation I C R I I Testing I I C R I Deployment I I I C R"},{"location":"10_requirements/prd/","title":"Product Requirements Document (PRD)","text":""},{"location":"10_requirements/prd/#1-problem-statement","title":"1. Problem Statement","text":"<p>Churches need live transcription of sermons and liturgy for: - Accessibility: Deaf/hard-of-hearing congregants - Multilingual support: Non-native speakers following along - Archival: Automated transcript logging for later reference</p> <p>Existing solutions (cloud transcription services) require: - High Per-minute costs (\\$0.006+/min \u2192 \\$360+/month for 1000 min/month) - Complex integration (no turnkey appliance) - Expensive hardware</p> <p>Goal: Provide a self-hosted, cost-effective transcription appliance for use with personal devices to display the transcriptions.</p>"},{"location":"10_requirements/prd/#2-user-stories","title":"2. User Stories","text":"ID As a... I want to... So that... Priority US-001 User View live transcripts on my personal device I can follow along during the service P0 US-002 Kiosk Operator See connection status (live/reconnecting) I know if the system is working P0 US-003 Admin Upload custom vocabulary (staff names, biblical terms) Transcripts have correct spellings P1 US-004 Admin Review low-confidence transcript snippets I can correct errors and improve the model P1 US-005 Admin Enroll speaker voiceprints The system labels speakers by name (not Speaker 0) P2 US-006 Admin Configure profanity filtering Inappropriate words never appear on screen P1 US-007 Operator Deploy to hardware without technical expertise I don't need to hire a consultant P0 US-008 Developer Test the system without GPU hardware I can contribute on my laptop P1"},{"location":"10_requirements/prd/#3-functional-requirements","title":"3. Functional Requirements","text":""},{"location":"10_requirements/prd/#core-transcription-m0-m6","title":"Core Transcription (M0-M6)","text":"<ul> <li>FR-001: The system SHALL capture audio from a USB audio interface at 16kHz, 16-bit PCM</li> <li>FR-002: The system SHALL stream audio to Deepgram API via WebSocket</li> <li>FR-003: The system SHALL display transcripts on a web UI with \\&lt;500ms latency</li> <li>FR-004: The system SHALL detect audio clipping and alert the operator</li> <li>FR-005: The system SHALL buffer audio to disk during internet outages</li> <li>FR-006: The system SHALL catch up on buffered audio upon reconnection</li> </ul>"},{"location":"10_requirements/prd/#administration-m7-m11","title":"Administration (M7-M11)","text":"<ul> <li>FR-007: The system SHALL provide an admin dashboard for configuration</li> <li>FR-008: The system SHALL support custom vocabulary (PhraseSet JSON upload)</li> <li>FR-009: The system SHALL save low-confidence snippets (\\&lt;0.85) for review</li> <li>FR-010: The system SHALL encrypt all saved audio snippets with AES-256</li> <li>FR-011: The system SHALL support profanity filtering (hard blocklist + soft allowlist)</li> </ul>"},{"location":"10_requirements/prd/#speaker-identification-m12-m13","title":"Speaker Identification (M12-M13)","text":"<ul> <li>FR-012: The system SHALL identify enrolled speakers via voiceprint matching</li> <li>FR-013: The system SHALL label transcripts with speaker names (overriding Deepgram's Speaker 0/1)</li> <li>FR-014: The system SHALL support crypto-shredding of voiceprints (delete key \u2192 file unrecoverable)</li> </ul>"},{"location":"10_requirements/prd/#deployment-m0-m2","title":"Deployment (M0-M2)","text":"<ul> <li>FR-015: The system SHALL run on Jetson Orin Nano (Tier 1)</li> <li>FR-016: The system SHALL run on desktop GPU (Tier 2) and CPU-only (Tier 3) for development</li> <li>FR-017: The system SHALL deploy via BalenaOS with zero-config networking</li> </ul>"},{"location":"10_requirements/prd/#4-non-functional-requirements","title":"4. Non-Functional Requirements","text":""},{"location":"10_requirements/prd/#performance","title":"Performance","text":"<ul> <li>NFR-001: Transcript latency SHALL be \\&lt;500ms (microphone \u2192 UI display)</li> <li>NFR-002: The system SHALL handle continuous 2-hour sessions without restart</li> </ul>"},{"location":"10_requirements/prd/#reliability","title":"Reliability","text":"<ul> <li>NFR-003: The system SHALL achieve 99.9% uptime (excluding scheduled maintenance)</li> <li>NFR-004: The UI SHALL remain responsive even if transcription service crashes</li> <li>NFR-005: The system SHALL auto-restart crashed containers within 10 seconds</li> </ul>"},{"location":"10_requirements/prd/#security","title":"Security","text":"<ul> <li>NFR-006: All PII (voiceprints, audio snippets) SHALL be encrypted at rest (AES-256)</li> <li>NFR-007: Encryption keys SHALL be sealed to TPM on Tier 1 hardware</li> <li>NFR-008: The system SHALL NOT log API keys in plaintext</li> </ul>"},{"location":"10_requirements/prd/#usability","title":"Usability","text":"<ul> <li>NFR-009: Operators with no technical background SHALL complete deployment in \\&lt;30 minutes</li> <li>NFR-010: The Web UI SHALL be accessible from mobile devices (responsive design)</li> <li>NFR-011: Error messages SHALL be actionable (not stack traces)</li> </ul>"},{"location":"10_requirements/prd/#scalability","title":"Scalability","text":"<ul> <li>NFR-012: The system is optimized for single-device deployment (not fleet-wide load balancing)</li> <li>NFR-013: The system SHALL support up to 30 concurrent WebSocket clients</li> </ul>"},{"location":"10_requirements/prd/#5-out-of-scope-v10","title":"5. Out of Scope (V1.0)","text":"<ul> <li>Multi-language support (English-only)</li> <li>On-device STT (cloud-only for V1)</li> <li>Multi-site transcription (1 device per church)</li> <li>Real-time translation (transcript \u2192 Spanish, etc.)</li> <li>Video captioning (audio-only for V1)</li> <li>Projector display mode (V1 targets personal devices only)</li> </ul>"},{"location":"10_requirements/prd/#6-success-metrics","title":"6. Success Metrics","text":"Metric Target Measurement Word Error Rate (WER) \\&lt;10% on liturgical content Manual review of 1000-word samples Deployment Time \\&lt;30 min (non-technical user) User testing with church volunteers Cost Savings &gt;80% vs. cloud STT (\\$360/mo \u2192 \\$68/mo) Deepgram API usage + hardware amortization Uptime &gt;99% over 30-day period Health-watchdog logs"},{"location":"10_requirements/prd/#7-acceptance-criteria","title":"7. Acceptance Criteria","text":"<ul> <li>[ ] Live transcripts display on web UI during 2-hour church service</li> <li>[ ] System recovers automatically from 10-minute internet outage (zero data loss)</li> <li>[ ] Admin can upload custom vocabulary and see improved accuracy</li> <li>[ ] Low-confidence snippets (\\&lt;0.85) saved to <code>/data/review/</code> (encrypted)</li> </ul> <p>See Also: - System Design - Technical architecture - Roadmap - Development milestones - Traceability Matrix - Requirements \u2192 Design \u2192 Milestones mapping</p>"},{"location":"10_requirements/traceability_matrix/","title":"Requirements Traceability Matrix","text":""},{"location":"10_requirements/traceability_matrix/#overview","title":"Overview","text":"<p>This document maps functional/non-functional requirements to design decisions and implementation milestones, ensuring complete coverage.</p>"},{"location":"10_requirements/traceability_matrix/#functional-requirements-traceability","title":"Functional Requirements Traceability","text":"Req ID Requirement Design Component Milestone Test Plan FR-001 Generate initial phrases from YouTube captions <code>scripts/mine_phrases.py</code> M0.5 Manual execution: Output <code>initial_phrases.json</code> FR-002 Maintain Gold Standard test corpus (WER &lt; 5%) Manual transcription M0.5 CI: Run clips through stt-provider, measure WER FR-003 Capture audio from USB audio interface (16kHz PCM) audio-producer service M2 Integration test: Mock audio \u2192 broker FR-004 Stream audio to Deepgram via WebSocket stt-provider service M3 Integration test: Live Deepgram connection FR-005 Display transcripts with &lt;500ms latency api-gateway WebSocket broadcast M3 Performance test: Measure end-to-end latency FR-006 Detect audio clipping and alert audio-producer RMS monitoring M1 Unit test: Inject clipped audio, verify alert FR-007 Buffer audio during internet outages stt-provider on-disk buffer M5 Resilience test: Disconnect network, verify buffer FR-008 Catch up on buffered audio stt-provider catch-up logic M5 Resilience test: Reconnect, verify no data loss FR-009 Save low-confidence snippets (&lt;0.85) stt-provider QA loop M9 Unit test: Mock low confidence, verify save FR-010 Encrypt saved audio snippets (AES-256) stt-provider per-file encryption M7 Security test: Attempt decrypt without key FR-011 Profanity filtering (blocklist/allowlist) stt-provider sanitizer M4 Unit test: Inject profanity, verify filtered FR-012 Identify enrolled speakers via voiceprint identifier service (SpeechBrain) M12 Integration test: Enroll voiceprint, verify match FR-013 Label transcripts with speaker names api-gateway correlation engine M13 Integration test: Map Speaker 0 \u2192 Tom FR-014 Crypto-shredding of voiceprints api-gateway crypto-shred API M10 Security test: Delete key, verify unrecoverable FR-015 Run on Jetson Orin Nano (Tier 1) Multi-arch Docker builds M0 Deployment test: Flash BalenaOS, deploy FR-016 Run on desktop GPU (Tier 2) and CPU (Tier 3) Docker ARG BASE_IMAGE strategy M0 CI test: Build on multiple platforms FR-017 Deploy via BalenaOS with zero-config Balena Public URL, Supervisor M2 Deployment test: <code>balena push</code> from CLI"},{"location":"10_requirements/traceability_matrix/#non-functional-requirements-traceability","title":"Non-Functional Requirements Traceability","text":"Req ID Requirement Design Decision Verification ADR NFR-001 Transcript latency \\&lt;500ms ZMQ direct routing, local broker Performance benchmark ADR-0001 NFR-002 Handle 2-hour sessions without restart Stateless services, memory limits Load test: 2-hour continuous stream - NFR-003 99.9% uptime <code>restart: always</code>, decoupled services Health-watchdog monitoring ADR-0002 NFR-004 UI responsive during transcription crash Separate stt-provider service Fault injection: Kill stt-provider ADR-0002 NFR-005 Auto-restart crashed containers \\&lt;10s Docker restart policy Integration test: Kill container, measure recovery - NFR-006 Encrypt PII at rest (AES-256) Per-file encryption + TPM sealing Security audit: Verify encryption Threat Model NFR-007 TPM key sealing (Tier 1) Balena TPM integration Security test: Boot compromise detection Threat Model NFR-008 No plaintext API keys in logs Environment vars, log sanitization Code review: Grep for API key logging - NFR-009 Deployment \\&lt;30 min (non-technical) Balena one-command deploy User testing: Church volunteer deploy ADR-0005 NFR-010 Responsive UI (mobile) FastAPI + responsive HTML/CSS Browser test: iOS/Android viewport - NFR-011 Actionable error messages Custom exception handlers in api-gateway Manual test: Trigger errors, verify messages - NFR-012 Single-device optimization No distributed coordination Architecture review - NFR-013 Support 30 concurrent WebSocket clients FastAPI async WebSocket handling Load test: 30 concurrent connections -"},{"location":"10_requirements/traceability_matrix/#milestone-requirement-coverage","title":"Milestone \u2192 Requirement Coverage","text":"Milestone Requirements Addressed Deliverable M0 FR-015, FR-016 Docker builds, multi-arch support M0.5 FR-001, FR-002 Data Harvest: Silver (phrase mining), Gold (regression corpus) M1 FR-003, FR-006 audio-producer, broker, api-gateway skeleton M2 FR-017, NFR-009 Balena deployment, public URL M3 FR-002, FR-003, FR-008, NFR-001 stt-provider, end-to-end transcription M4 FR-011 Profanity filtering (sanitizer) M5 FR-005, FR-006 On-disk buffering, resilience M6 NFR-003, NFR-004 health-watchdog, status monitoring M7 FR-010, NFR-006, NFR-007 Encryption, TPM sealing, WebSocket auth M8 FR-007 sqladmin dashboard M9 FR-009 QA loop, low-confidence snippets M10 FR-014 Voiceprint enrollment, crypto-shredding M12 FR-012 identifier service (SpeechBrain) M13 FR-013, NFR-013 Correlation engine, speaker labels"},{"location":"10_requirements/traceability_matrix/#user-story-requirement-milestone-map","title":"User Story \u2192 Requirement \u2192 Milestone Map","text":"User Story Requirements Milestone US-001 (View live transcripts) FR-003, NFR-001 M3 US-002 (Connection status) NFR-003, NFR-004 M6 US-003 (Custom vocabulary) FR-008 M3 US-004 (Review low-confidence snippets) FR-009 M9 US-005 (Enroll voiceprints) FR-012, FR-014 M10, M12 US-006 (Profanity filtering) FR-011 M4 US-007 (Easy deployment) FR-017, NFR-009 M2 US-008 (Test without GPU) FR-016 M0"},{"location":"10_requirements/traceability_matrix/#orphaned-requirements-check","title":"Orphaned Requirements Check","text":"<p>\u2705 All requirements traced to design components and milestones.</p> <p>See Also: - PRD - Full requirements specification - Roadmap - Milestone definitions - Master Test Plan - Test coverage</p>"},{"location":"10_requirements/user_journey_maps/","title":"User Journey Maps","text":""},{"location":"10_requirements/user_journey_maps/#overview","title":"Overview","text":"<p>This document visualizes key user workflows for the Live STT system, identifying touchpoints, pain points, and opportunities.</p>"},{"location":"10_requirements/user_journey_maps/#journey-1-av-operator-sunday-service","title":"Journey 1: AV Operator - Sunday Service","text":""},{"location":"10_requirements/user_journey_maps/#persona","title":"Persona","text":"<p>Name: Sarah Role: Church volunteer audiovisual coordinator Tech Savvy: Low (familiar with iPad, not with servers)</p>"},{"location":"10_requirements/user_journey_maps/#journey","title":"Journey","text":"<pre><code>journey\n    title Sunday Service Transcription Workflow\n    section Pre-Service (8:00 AM)\n        Check system status: 3: Sarah\n        Verify microphone connected: 5: Sarah\n        Share URL with congregation: 4: Sarah\n    section During Service (9:00 AM)\n        Congregants view transcripts on phones: 5: Congregation\n        Monitor connection status on iPad: 4: Sarah\n        Notice \"Reconnecting...\" alert: 2: Sarah\n        System recovers automatically: 5: Sarah\n    section Post-Service (11:00 AM)\n        No cleanup required: 5: Sarah\n</code></pre>"},{"location":"10_requirements/user_journey_maps/#touchpoints","title":"Touchpoints","text":"Step Touchpoint Experience Pain Points 1 Open web UI Navigate to <code>https://&lt;device-url&gt;:8000</code> Pain: Must share URL with congregation (QR code would help) 2 Check status Green \"Live\" badge visible \u2705 Clear visual feedback 3 View transcripts (congregants) Text appears in real-time on personal devices \u2705 Responsive UI works on phones 4 Handle outage \"Reconnecting...\" banner appears \u2705 System recovers without intervention"},{"location":"10_requirements/user_journey_maps/#opportunities","title":"Opportunities","text":"<ul> <li>QR code generator: Display QR code on admin dashboard for easy URL sharing</li> <li>Font size controls: User-adjustable text size in web UI</li> <li>Dark mode: Reduce screen glare in dimly lit church sanctuary</li> <li>V2 - Projector mode: Dedicated large-screen display mode (future enhancement)</li> </ul>"},{"location":"10_requirements/user_journey_maps/#journey-2-administrator-weekly-configuration","title":"Journey 2: Administrator - Weekly Configuration","text":""},{"location":"10_requirements/user_journey_maps/#persona_1","title":"Persona","text":"<p>Name: Pastor Mike Role: Church senior pastor Tech Savvy: Medium (comfortable with web apps)</p>"},{"location":"10_requirements/user_journey_maps/#journey_1","title":"Journey","text":"<pre><code>journey\n    title Weekly Vocab &amp; QA Review\n    section Monday Morning\n        Log into admin dashboard: 4: Mike\n        Review low-confidence snippets: 3: Mike\n        Play encrypted audio snippet: 4: Mike\n        Add new staff name to PhraseSet: 5: Mike\n        Save changes: 5: Mike\n    section Thursday Testing\n        Download transcript archive: 4: Mike\n        Review accuracy on sermon keywords: 3: Mike\n</code></pre>"},{"location":"10_requirements/user_journey_maps/#touchpoints_1","title":"Touchpoints","text":"Step Touchpoint Experience Pain Points 1 Navigate to <code>/admin</code> Login with credentials Pain: No SSO (manual password) 2 sqladmin UI CRUD interface for tables \u2705 Familiar database admin UI 3 Review queue List of low-confidence snippets Pain: No sorting by date/confidence 4 Play snippet In-browser audio player (encrypted stream) \u2705 Seamless playback 5 Edit PhraseSet JSON editor for custom vocabulary Pain: Raw JSON (not form-based)"},{"location":"10_requirements/user_journey_maps/#opportunities_1","title":"Opportunities","text":"<ul> <li>Form-based vocab editor: Replace JSON textarea with structured form (add/edit/delete individual phrases)</li> <li>Confidence histogram: Visualize snippet distribution by confidence score</li> </ul>"},{"location":"10_requirements/user_journey_maps/#journey-3-developer-first-time-setup","title":"Journey 3: Developer - First-Time Setup","text":""},{"location":"10_requirements/user_journey_maps/#persona_2","title":"Persona","text":"<p>Name: Alex Role: Open-source contributor Tech Savvy: High (Python developer, no Docker experience)</p>"},{"location":"10_requirements/user_journey_maps/#journey_2","title":"Journey","text":"<pre><code>journey\n    title Local Development Setup\n    section Day 1 - Environment\n        Clone repository: 5: Alex\n        Read README.md: 4: Alex\n        Install mise: 3: Alex\n        Run just install: 5: Alex\n        Confused by Docker setup: 1: Alex\n    section Day 1 - First Run\n        Read CONTRIBUTING.md: 4: Alex\n        Run docker compose up: 3: Alex\n        Mock audio not playing: 2: Alex\n        Find debug docs in runbooks: 4: Alex\n        See first transcript: 5: Alex\n</code></pre>"},{"location":"10_requirements/user_journey_maps/#touchpoints_2","title":"Touchpoints","text":"Step Touchpoint Experience Pain Points 1 README.md Clear <code>mise install</code> instructions \u2705 Standard Python setup 2 Docker setup Run <code>docker compose up</code> Pain: Unclear which services are optional 3 Mock audio Set <code>MOCK_FILE=/path/to/audio.wav</code> Pain: No sample audio file provided 4 First transcript Deepgram API key required Pain: Must sign up for Deepgram account 5 Debugging Check <code>docker compose logs stt-provider</code> \u2705 Docker logs accessible"},{"location":"10_requirements/user_journey_maps/#opportunities_2","title":"Opportunities","text":"<ul> <li>Sample audio files: Include <code>tests/fixtures/sermon_sample.wav</code></li> <li>Dev environment script: <code>just dev-setup</code> \u2192 Pulls mock audio, sets env vars</li> <li>Optional services docs: Clearly document which Docker Compose profiles are needed</li> </ul>"},{"location":"10_requirements/user_journey_maps/#journey-4-system-administrator-deployment-to-industrial-nuc","title":"Journey 4: System Administrator - Deployment to Industrial NUC","text":""},{"location":"10_requirements/user_journey_maps/#persona_3","title":"Persona","text":"<p>Name: Tom Role: Developer deploying to production Tech Savvy: Expert</p>"},{"location":"10_requirements/user_journey_maps/#journey_3","title":"Journey","text":"<pre><code>journey\n    title Balena Production Deployment (x86)\n    section Initial Setup\n        Flash NUC with BalenaOS (Generic x86): 3: Tom\n        Create Balena fleet: 5: Tom\n        Add device to fleet: 5: Tom\n        Configure BIOS (Power/Watchdog): 3: Tom\n    section First Deploy\n        Set env vars (DEEPGRAM_API_KEY): 4: Tom\n        Run balena push live-stt-fleet: 5: Tom\n        Wait for image build (10 min): 3: Tom\n        Device downloads image: 4: Tom\n        Services start successfully: 5: Tom\n    section First Transcript\n        Navigate to public device URL: 5: Tom\n        See live transcripts: 5: Tom\n</code></pre>"},{"location":"10_requirements/user_journey_maps/#touchpoints_3","title":"Touchpoints","text":"Step Touchpoint Experience Pain Points 1 Flash BalenaOS Use Balena Etcher GUI \u2705 Standard Balena workflow 2 BIOS Config Manual keyboard/monitor setup Pain: Requires physical access 3 balena CLI <code>balena push</code> command \u2705 Familiar to Balena users 4 Env variable management Balena dashboard web UI \u2705 Centralized config 5 Public URL Auto-generated HTTPS endpoint \u2705 Zero network config"},{"location":"10_requirements/user_journey_maps/#opportunities_3","title":"Opportunities","text":"<ul> <li>TPM provision script: Automate TPM key sealing in first-boot script</li> <li>Health dashboard: Balena dashboard plugin for service-specific metrics</li> <li>Rollback UI: One-click rollback to previous release</li> </ul>"},{"location":"10_requirements/user_journey_maps/#cross-journey-insights","title":"Cross-Journey Insights","text":""},{"location":"10_requirements/user_journey_maps/#common-pain-points","title":"Common Pain Points","text":"<ol> <li>No sample data: Mock audio, sample vocab files missing</li> <li>JSON config: Raw JSON editing (PhraseSet) vs. form-based UI</li> <li>URL memorization: No mDNS/local discovery</li> </ol>"},{"location":"10_requirements/user_journey_maps/#common-delights","title":"Common Delights","text":"<ol> <li>Auto-recovery: System handles outages without manual intervention</li> <li>Docker simplicity: <code>docker compose up</code> just works (Tier 3)</li> <li>Public URL: BalenaOS eliminates network config headaches</li> </ol> <p>See Also: - PRD - User stories and acceptance criteria - Quickstart - End-user deployment guide - CONTRIBUTING.md - Developer setup guide</p>"},{"location":"20_architecture/architecture_definition/","title":"Architecture Definition Document (ADD)","text":""},{"location":"20_architecture/architecture_definition/#1-system-overview","title":"1. System Overview","text":"<p>The Live STT system is a high-reliability, real-time speech-to-text appliance designed for \"Industrial Split-Brain\" deployment on x86 hardware (ASRock Industrial NUC). It implements a dual-stream architecture where transcription is offloaded to the cloud (Deepgram Nova-3) while biometric identification runs locally on the edge (OpenVINO), synchronized via a \"Time Zipper\" service.</p> <p>Key Design Principles: - Split-Brain Processing: Decoupled cloud transcription (high accuracy) and edge biometrics (low latency/privacy) - Industrial Reliability: Fanless x86 hardware with Power Loss Protection (PLP) and \"Black Box\" filesystem - Event-Driven: NATS-based messaging backbone for persistence and observability</p>"},{"location":"20_architecture/architecture_definition/#2-system-context-c4-level-1","title":"2. System Context (C4 Level 1)","text":"<pre><code>C4Context\n  title System Context - Live STT Appliance (v7.3)\n\n  Person(operator, \"AV Operator\", \"Church staff member\")\n  Person(admin, \"System Administrator\", \"Manages configuration and reviews transcripts\")\n\n  System(livesst, \"Live STT Appliance\", \"Real-time speech transcription &amp; identification\")\n\n  System_Ext(deepgram, \"Deepgram API\", \"Cloud STT service (Nova-3)\")\n  System_Ext(balena, \"Balena Cloud\", \"Fleet management and deployment\")\n\n  Rel(operator, livesst, \"Views live transcripts\", \"WebSocket\")\n  Rel(admin, livesst, \"Manages config, reviews QA queue\", \"HTTPS\")\n  Rel(livesst, deepgram, \"Streams audio, receives transcripts\", \"WSS\")\n  Rel(balena, livesst, \"Deploys updates\", \"Docker Registry\")\n</code></pre>"},{"location":"20_architecture/architecture_definition/#3-container-diagram-c4-level-2","title":"3. Container Diagram (C4 Level 2)","text":"<pre><code>C4Container\n  title Container Diagram - Live STT Microservices (v7.3)\n\n  Person(user, \"User\")\n\n  Container_Boundary(appliance, \"Live STT Appliance\") {\n    Container(gateway, \"api-gateway\", \"FastAPI/Python\", \"Web UI, WebSocket server, config management\")\n    Container(broker, \"NATS Server\", \"Go\", \"Central event bus with JetStream persistence\")\n    Container(producer, \"audio-producer\", \"Python/PipeWire\", \"Microphone capture, RMS monitoring\")\n    Container(stt, \"stt-provider\", \"Python/Deepgram SDK\", \"Cloud STT client, offline buffering\")\n    Container(identifier, \"identifier\", \"Python/OpenVINO\", \"Speaker biometric ID (WeSpeaker)\")\n    Container(manager, \"identity-manager\", \"Python\", \"Time Zipper (merges text + identity)\")\n  }\n\n  System_Ext(deepgram, \"Deepgram API\")\n  ContainerDb(lancedb, \"LanceDB\", \"Vector DB for Biometrics\")\n  ContainerDb(blackbox, \"Black Box Storage\", \"Loopback ext4 (data=journal)\", \"Crash-proof persistence\")\n\n  Rel(user, gateway, \"Views transcripts\", \"WSS\")\n  Rel(producer, broker, \"Publishes audio.raw\", \"NATS\")\n  Rel(broker, stt, \"Routes audio.raw\", \"NATS\")\n  Rel(broker, identifier, \"Routes audio.raw\", \"NATS\")\n  Rel(stt, deepgram, \"Streams PCM\", \"WSS\")\n  Rel(stt, broker, \"Publishes text.transcript\", \"NATS\")\n  Rel(identifier, lancedb, \"Queries embeddings\")\n  Rel(identifier, broker, \"Publishes identity.event\", \"NATS\")\n  Rel(broker, manager, \"Routes text + identity\", \"NATS\")\n  Rel(manager, broker, \"Publishes merged events\", \"NATS\")\n  Rel(broker, gateway, \"Routes final events\", \"NATS\")\n  Rel(stt, blackbox, \"Buffers offline audio\")\n</code></pre>"},{"location":"20_architecture/architecture_definition/#4-component-list","title":"4. Component List","text":"Service Technology Purpose Resilience Strategy NATS Go Central event bus JetStream persistence, cluster-ready audio-producer Python/PipeWire Mic capture Ring buffer, non-blocking I/O stt-provider Python/Deepgram Cloud STT client \"Black Box\" buffering, auto-reconnect identifier Python/OpenVINO Speaker ID Local iGPU inference, fallback to CPU identity-manager Python Sensor Fusion Hybrid tagging strategy (no timestamp drift) api-gateway FastAPI Web UI, config Read-only NATS access, decoupled UI"},{"location":"20_architecture/architecture_definition/#5-deployment-view","title":"5. Deployment View","text":""},{"location":"20_architecture/architecture_definition/#production-industrial-x86","title":"Production (Industrial x86)","text":"<pre><code>BalenaOS (Generic x86):\n  - Fleet managed via Balena Cloud\n  - Hardware: ASRock NUC BOX-N97\n  - Storage: /data (Transcend PLP NVMe)\n  - Audio: Focusrite Scarlett Solo (PipeWire)\n  - Watchdog: Hardware WDT enabled\n</code></pre>"},{"location":"20_architecture/architecture_definition/#6-data-flow-split-brain","title":"6. Data Flow (Split-Brain)","text":"<pre><code>sequenceDiagram\n    participant Mic as audio-producer\n    participant NATS as NATS JetStream\n    participant STT as stt-provider\n    participant ID as identifier\n    participant Zip as identity-manager\n    participant UI as api-gateway\n\n    par Split-Brain\n        Mic-&gt;&gt;NATS: Pub audio.raw\n        NATS-&gt;&gt;STT: Stream audio\n        NATS-&gt;&gt;ID: Stream audio\n    end\n\n    par Parallel Processing\n        STT-&gt;&gt;Deepgram: WSS Stream\n        Deepgram--&gt;&gt;STT: Transcript (Speaker A)\n        STT-&gt;&gt;NATS: Pub text.transcript\n\n        ID-&gt;&gt;OpenVINO: Inference\n        OpenVINO--&gt;&gt;ID: Vector\n        ID-&gt;&gt;LanceDB: Lookup\n        ID-&gt;&gt;NATS: Pub identity.event (Speaker A = Alice)\n    end\n\n    NATS-&gt;&gt;Zip: Sub text + identity\n    Zip-&gt;&gt;Zip: Hybrid Tagging (Apply \"Alice\" to \"Speaker A\")\n    Zip-&gt;&gt;NATS: Pub events.merged\n    NATS-&gt;&gt;UI: Sub events.merged\n    UI-&gt;&gt;User: WebSocket Broadcast\n</code></pre>"},{"location":"20_architecture/architecture_definition/#7-key-architectural-decisions","title":"7. Key Architectural Decisions","text":"<p>See ADRs for detailed rationale: - ADR-0007: Pivot to x86 Industrial Platform - ADR-0008: Split-Brain Architecture - ADR-0009: Migration to NATS</p>"},{"location":"20_architecture/architecture_definition/#8-quality-attributes","title":"8. Quality Attributes","text":"Attribute Target Implementation Latency &lt; 100ms (ID), &lt; 500ms (Text) Parallel processing, local biometrics Reliability Zero Corruption PLP Hardware + \"Black Box\" Journaling Silence 0dB (Fanless) ASRock NUC N97 (Passive Cooling) Accuracy &gt; 95% WER Deepgram Nova-3 (Cloud) Privacy Biometrics Local Face/Voice vectors never leave device"},{"location":"20_architecture/architecture_definition/#9-technology-stack","title":"9. Technology Stack","text":"<ul> <li>Broker: NATS (JetStream)</li> <li>Services: Python 3.13, FastAPI, PipeWire</li> <li>ML: OpenVINO (WeSpeaker), Deepgram Nova-3</li> <li>Database: LanceDB (Vectors), SQLite (Config)</li> <li>OS: BalenaOS (x86_64)</li> <li>Hardware: ASRock Industrial NUC BOX-N97</li> </ul> <p>See Also: - System Design v7.3 - Detailed technical specification - HSI - Hardware/Software interface details - Threat Model - Security architecture</p>"},{"location":"20_architecture/hsi/","title":"Hardware/Software Interface (HSI) Document (v7.3)","text":""},{"location":"20_architecture/hsi/#1-overview","title":"1. Overview","text":"<p>This document defines the hardware/software interface for the Live STT system (v7.3), including Docker service configurations, NATS topology, volume mounts, and hardware dependencies.</p>"},{"location":"20_architecture/hsi/#2-docker-service-topology","title":"2. Docker Service Topology","text":""},{"location":"20_architecture/hsi/#21-service-mesh","title":"2.1 Service Mesh","text":"<pre><code>services:\n  nats:               # Central event bus (JetStream)\n  audio-producer:     # Analog audio capture (PipeWire)\n  stt-provider:       # Deepgram client (Cloud Ear)\n  identifier:         # Biometric ID (Edge Eye)\n  identity-manager:   # Time Zipper (Hybrid Tagging)\n  api-gateway:        # Web UI &amp; WebSocket server\n  nats-surveyor:      # Observability (Dev only)\n</code></pre>"},{"location":"20_architecture/hsi/#22-network-configuration","title":"2.2 Network Configuration","text":"<pre><code>networks:\n  host:               # Required for PipeWire access (audio-producer)\n  internal_overlay:   # For other services\n</code></pre>"},{"location":"20_architecture/hsi/#3-nats-topology","title":"3. NATS Topology","text":""},{"location":"20_architecture/hsi/#31-broker-configuration","title":"3.1 Broker Configuration","text":"<ul> <li>Image: <code>nats:2.10-alpine</code></li> <li>Flags: <code>-js</code> (Enable JetStream)</li> <li>Store: <code>/data/nats</code> (Mapped to \"Black Box\" loopback)</li> </ul>"},{"location":"20_architecture/hsi/#32-subject-hierarchy","title":"3.2 Subject Hierarchy","text":"Subject Publisher Subscriber(s) Payload Format <code>audio.raw</code> audio-producer stt-provider, identifier Binary PCM (16-bit, 16kHz, mono) <code>text.transcript</code> stt-provider identity-manager JSON: <code>{\"text\": \"...\", \"speaker\": 0}</code> <code>identity.event</code> identifier identity-manager JSON: <code>{\"user\": \"Alice\", \"conf\": 0.92}</code> <code>events.merged</code> identity-manager api-gateway JSON: <code>{\"text\": \"...\", \"user\": \"Alice\"}</code>"},{"location":"20_architecture/hsi/#4-volume-mounts","title":"4. Volume Mounts","text":""},{"location":"20_architecture/hsi/#41-black-box-storage-data","title":"4.1 \"Black Box\" Storage (<code>/data</code>)","text":"<p>To prevent corruption, we use a loopback filesystem with data journaling.</p> <pre><code># Host Setup (entrypoint.sh)\nmount -o loop,data=journal /data/nats.img /var/lib/nats\n</code></pre>"},{"location":"20_architecture/hsi/#42-application-data","title":"4.2 Application Data","text":"<pre><code>volumes:\n  - ./data/lancedb:/data/lancedb  # Vector DB (Biometrics)\n  - ./config:/config:ro           # Configuration\n</code></pre>"},{"location":"20_architecture/hsi/#5-hardware-dependencies","title":"5. Hardware Dependencies","text":""},{"location":"20_architecture/hsi/#51-audio-input-pipewire","title":"5.1 Audio Input (PipeWire)","text":"<ul> <li>Interface: PipeWire (via <code>libpipewire</code>)</li> <li>Device: Focusrite Scarlett Solo</li> <li>Format: 16-bit PCM, 16kHz, mono</li> <li>Latency: &lt; 10ms (Hardware Direct)</li> </ul>"},{"location":"20_architecture/hsi/#52-gpu-openvino","title":"5.2 GPU (OpenVINO)","text":"<ul> <li>Hardware: Intel UHD Graphics (N97)</li> <li>Driver: <code>/dev/dri</code> mapped to container</li> <li>Runtime: OpenVINO 2024.x</li> </ul>"},{"location":"20_architecture/hsi/#53-watchdog","title":"5.3 Watchdog","text":"<ul> <li>Device: <code>/dev/watchdog</code></li> <li>Timeout: 60s</li> <li>Service: <code>health-watchdog</code> (pings hardware WDT)</li> </ul>"},{"location":"20_architecture/hsi/#6-port-mappings","title":"6. Port Mappings","text":"Service Internal Port External Port Protocol Purpose api-gateway 8000 8000 HTTP/WSS Web UI nats 4222 4222 TCP NATS Client nats 8222 8222 HTTP NATS Monitoring"},{"location":"20_architecture/hsi/#7-resource-limits-tier-1-nuc-n97","title":"7. Resource Limits (Tier 1 - NUC N97)","text":"<pre><code>services:\n  identifier:\n    deploy:\n      resources:\n        limits:\n          cpus: '2'\n          memory: 4G\n    devices:\n      - /dev/dri:/dev/dri  # iGPU Access\n</code></pre> <p>See Also: - Architecture Definition - High-level system design - System Design v7.3 - Detailed technical specs</p>"},{"location":"20_architecture/system_design_v7.3/","title":"System Design Document: v7.3 (Industrial Split-Brain)","text":"<p>Status: ARCHITECTURE LOCKED Target Platform: Industrial x86 (Intel N97) Pattern: Parallel Processing Streams (Cloud Text + Edge Identity) Date: November 26, 2025</p>"},{"location":"20_architecture/system_design_v7.3/#1-executive-summary","title":"1. Executive Summary","text":"<p>The v7.3 architecture solves the \"Resource Contention\" and \"Reliability\" risks of the previous v6.x Jetson design by pivoting to a robust industrial x86 platform.</p> <ul> <li>The Shift: Abandon NVIDIA Jetson for a Fanless ASRock Industrial NUC (N97).</li> <li>The Strategy: Decouple Transcription (Cloud) from Identification (Edge). This allows us to use massive cloud models for high-accuracy text (Deepgram Nova-3) while running zero-latency biometric security locally on the Intel iGPU (OpenVINO).</li> <li>The Result: A headless, 365-day \"Set and Forget\" appliance that eliminates OOM (Out of Memory) kills and filesystem corruption.</li> </ul>"},{"location":"20_architecture/system_design_v7.3/#2-system-architecture","title":"2. System Architecture","text":""},{"location":"20_architecture/system_design_v7.3/#21-hardware-topology","title":"2.1 Hardware Topology","text":"<p>The system is contained within a single physical enclosure (The \"Brain\").</p> <ul> <li>Compute: ASRock Industrial NUC BOX-N97 (Fanless)</li> <li>Role: Runs all logic, databases, and Docker containers.</li> <li>Memory: 16GB DDR4-3200 (Single SODIMM)</li> <li>Benefit: Eliminates swap-thrashing; fits entire OS + Databases in RAM.</li> <li>Storage: Transcend MTE712A 256GB NVMe (Industrial Grade)</li> <li>Feature: Power Loss Protection (PLP) capacitors prevent file corruption during hard power cuts.</li> <li>Audio Input: Focusrite Scarlett Solo 4th Gen</li> <li>Benefit: -127dB EIN noise floor provides \"Clean Lab\" quality audio for Biometric Vectorization.</li> <li>Watchdog: Hardware WDT (ITE IT8xxx Chipset)</li> <li>Role: Hard-resets the CPU if the OS kernel hangs for &gt;60 seconds.</li> </ul>"},{"location":"20_architecture/system_design_v7.3/#22-data-path-the-split-brain","title":"2.2 Data Path (The \"Split-Brain\")","text":"<p>The audio signal splits immediately upon capture into two parallel processing streams:</p> <ol> <li> <p>Stream A (Cloud \"Ear\"):</p> <ul> <li><code>Audio</code> \u2192 <code>Deepgram API</code> \u2192 <code>Text/Diarization</code> (Latency: ~500ms)</li> <li>Role: High-accuracy transcription and speaker segmentation (Speaker A vs Speaker B).</li> </ul> </li> <li> <p>Stream B (Edge \"Eye\"):</p> <ul> <li><code>Audio</code> \u2192 <code>Silero VAD</code> \u2192 <code>WeSpeaker (OpenVINO)</code> \u2192 <code>Vector ID</code> (Latency: ~100ms)</li> <li>Role: Biometric identification (Speaker A = \"Alice\").</li> </ul> </li> <li> <p>The Merge (Hybrid Tagging):</p> <ul> <li>The Identity Manager applies the biometric labels to the Deepgram speaker segments.</li> <li>Strategy: \"Hybrid Tagging\" - Use Deepgram for when someone spoke, use Local Biometrics only to tag who it was. This avoids timestamp drift issues.</li> </ul> </li> </ol>"},{"location":"20_architecture/system_design_v7.3/#3-component-design-microservices","title":"3. Component Design (Microservices)","text":""},{"location":"20_architecture/system_design_v7.3/#31-service-audio-producer-hardware-abstraction","title":"3.1 Service: <code>audio-producer</code> (Hardware Abstraction)","text":"<ul> <li>Role: The single source of truth for audio data.</li> <li>Input: PipeWire Source (Focusrite Scarlett Solo).</li> <li>Configuration: 16kHz, Mono, S16LE.</li> <li>Logic:</li> <li>Direct Hardware Access (via PipeWire) to prevent drift.</li> <li>Publishes raw PCM chunks to internal NATS subject <code>audio.raw</code>.</li> <li>Safety: Uses a Ring Buffer to prevent blocking if consumers lag.</li> </ul>"},{"location":"20_architecture/system_design_v7.3/#32-service-stt-provider-the-ear","title":"3.2 Service: <code>stt-provider</code> (The Ear)","text":"<ul> <li>Role: Transcription &amp; Rough Diarization.</li> <li>Logic:</li> <li>Subscribes to <code>audio.raw</code>.</li> <li>Streams via WebSocket to Deepgram Nova-3.</li> <li>Config: <code>smart_format=true</code>, <code>diarize=true</code>, <code>interim_results=true</code>.</li> <li>Resilience:</li> <li>Offline Mode: If internet is lost, diverts audio to the \"Black Box\" Loopback Filesystem to catch up later.</li> <li>Output: Publishes ephemeral text events to <code>text.transcript</code>.</li> </ul>"},{"location":"20_architecture/system_design_v7.3/#33-service-identifier-the-biometric-brain","title":"3.3 Service: <code>identifier</code> (The Biometric Brain)","text":"<ul> <li>Role: Speaker Identification (Who is speaking?).</li> <li>Engine: OpenVINO Runtime (Targeting N97 iGPU).</li> <li>Pipeline:</li> <li>Trigger: Silero VAD v5 (ONNX) detects voice activity.</li> <li>Capture: Accumulates 1.5s of audio.</li> <li>Inference: WeSpeaker ResNet34 (INT8 Quantized) extracts a 256-dimension vector.</li> <li>Lookup: Queries local LanceDB vector store.</li> <li>Threshold: Matches if Cosine Similarity &gt; 0.85.</li> <li>Output: Publishes <code>identity.event</code> (e.g., <code>User: Alice, Conf: 0.92</code>) to NATS.</li> </ul>"},{"location":"20_architecture/system_design_v7.3/#34-service-identity-manager-the-time-zipper","title":"3.4 Service: <code>identity-manager</code> (The Time Zipper)","text":"<ul> <li>Role: Sensor Fusion / Hybrid Tagging.</li> <li>Problem: Deepgram knows what was said (but uses generic \"Speaker 0\"). The Identifier knows who spoke (but has no text).</li> <li>Logic (Hybrid Tagging):</li> <li>Listens to both <code>text.transcript</code> and <code>identity.event</code>.</li> <li>Maintains a \"Session Map\" of <code>Deepgram Speaker ID</code> \u2192 <code>Biometric User ID</code>.</li> <li>Rule: If \"Speaker 0\" is active, and Biometrics identifies \"Alice\" with high confidence, map <code>Speaker 0 = Alice</code> for the session.</li> <li>Lazy Re-identification: Only re-scan speaker if confidence drops or silence &gt; 30s.</li> <li>Output: Broadcasts the merged event to the API Gateway.</li> </ul>"},{"location":"20_architecture/system_design_v7.3/#35-service-api-gateway-the-facade","title":"3.5 Service: <code>api-gateway</code> (The Facade)","text":"<ul> <li>Role: Secure Public Interface.</li> <li>Protocol: WebSocket (<code>ws://0.0.0.0:8000/events</code>).</li> <li>Logic:</li> <li>Subscribes to internal NATS topics.</li> <li>Sanitizes JSON (removes internal debug flags).</li> <li>Broadcasts to any connected LAN clients (BYOD / Dashboards).</li> <li>Security: Enforces \"Read-Only\" (External clients cannot publish to NATS).</li> </ul>"},{"location":"20_architecture/system_design_v7.3/#4-data-strategy","title":"4. Data Strategy","text":""},{"location":"20_architecture/system_design_v7.3/#41-black-box-persistence","title":"4.1 \"Black Box\" Persistence","text":"<p>To prevent filesystem corruption on the NUC, we do not write NATS data directly to the OS partition.</p> <ul> <li>Mechanism: A pre-allocated 4GB Loopback File (<code>/data/nats.img</code>).</li> <li>Format: <code>ext4</code> with <code>data=journal</code> (Full Data Journaling).</li> <li>Mount: Mounted at <code>/var/lib/nats</code> inside the container.</li> <li>Guarantee: Atomic writes. If power is cut, the journal replays on boot, ensuring zero corruption.</li> </ul>"},{"location":"20_architecture/system_design_v7.3/#42-biometric-enrollment","title":"4.2 Biometric Enrollment","text":"<ul> <li>Storage: LanceDB (Embedded Vector DB).</li> <li>Backup: Since Vector IDs are critical, the LanceDB folder is rsync'd to the \"Black Box\" partition hourly.</li> </ul>"},{"location":"20_architecture/system_design_v7.3/#5-master-roadmap-v73-build","title":"5. Master Roadmap (v7.3 Build)","text":""},{"location":"20_architecture/system_design_v7.3/#phase-1-the-ironclad-foundation","title":"Phase 1: The \"Ironclad\" Foundation","text":"<ul> <li>Goal: Crash-proof Hardware Setup.</li> <li>Tasks:</li> <li>Provision ASRock N97 with BalenaOS.</li> <li>Configure BIOS: \"Power On After Fail\", \"Watchdog Enabled\".</li> <li>Implement <code>entrypoint.sh</code> for <code>data=journal</code> loopback mount.</li> <li>Validation: 50x Hard Power Pull Test.</li> </ul>"},{"location":"20_architecture/system_design_v7.3/#phase-2-the-model-conversion","title":"Phase 2: The Model Conversion","text":"<ul> <li>Goal: Fit AI into the N97.</li> <li>Tasks:</li> <li>Export Silero VAD and WeSpeaker to ONNX.</li> <li>Run ONNX Quantization (Float32 \u2192 INT8).</li> <li>Write OpenVINO Python shim for iGPU offload.</li> <li>Validation: Inference speed &lt; 50ms per chunk.</li> </ul>"},{"location":"20_architecture/system_design_v7.3/#phase-3-the-zipper-logic","title":"Phase 3: The \"Zipper\" Logic","text":"<ul> <li>Goal: Accurate Speaker Attribution.</li> <li>Tasks:</li> <li>Implement <code>identity-manager</code> service.</li> <li>Build \"Session Map\" class.</li> <li>Implement \"Hybrid Tagging\" logic.</li> <li>Validation: Conversation Test (Two speakers swapping turns).</li> </ul>"},{"location":"20_architecture/system_design_v7.3/#phase-4-integration-burn-in","title":"Phase 4: Integration &amp; Burn-In","text":"<ul> <li>Goal: Deployment Ready.</li> <li>Tasks:</li> <li>Integrate Focusrite Audio Source (PipeWire).</li> <li>Full System Burn-in (7 Days).</li> <li>Validation: No memory leaks, no zombie processes.</li> </ul>"},{"location":"20_architecture/system_design_v7.3/#6-bill-of-materials-bom","title":"6. Bill of Materials (BOM)","text":"Component Model Specification Est. Price Compute ASRock Ind. NUC BOX-N97 Intel N97, Fanless Chassis $240 Memory Crucial 16GB SODIMM DDR4-3200 $35 Storage Transcend MTE712A 256GB NVMe w/ PLP $65 Audio Focusrite Scarlett Solo 4th Gen Low-Noise Preamp (-127dB EIN) $140 Cabling USB-C to USB-C High-quality Shielded $15 Total ~$495"},{"location":"20_architecture/system_design_v8.0/","title":"System Design Document: v8.0 (\"Buffered Brain\")","text":"<p>Status: DRAFT Target Platform: Industrial x86 (Intel N97) Pattern: Buffered Split-Brain (Store-and-Forward + Parallel Processing) Date: December 2025</p>"},{"location":"20_architecture/system_design_v8.0/#1-executive-summary","title":"1. Executive Summary","text":"<p>The v8.0 architecture combines the \"Split-Brain\" reliability of v7.3 with a robust \"Store-and-Forward\" data strategy. It introduces a pre-roll buffer to catch audio before a session starts and ensures that both Transcription (Deegram) and Identification (OpenVINO) are applied to every second of audio, whether Live or Backfilled.</p> <p>Key Changes from v7.3: 1.  Pre-Roll Buffering: Always-on recording into a memory ring buffer ensures no words are lost during \"Wake Up\". 2.  Dual-Lane Processing: Both <code>stt-provider</code> and <code>identifier</code> act as dual-consumers, processing high-priority \"Live\" data and background \"Backfill\" data simultaneously. 3.  Server-Side Fusion: The <code>identity-manager</code> provides a strict \"Zipper\" layer, ensuring that the Web UI receives fully attributed text rather than raw streams.</p>"},{"location":"20_architecture/system_design_v8.0/#2-system-architecture","title":"2. System Architecture","text":""},{"location":"20_architecture/system_design_v8.0/#21-hardware-topology","title":"2.1 Hardware Topology","text":"<p>Remains unchanged from v7.3. - Compute: ASRock Industrial NUC BOX-N97. - Storage: Transcend 256GB NVMe (Power Loss Protected) + Loopback Journaling. - Audio: Focusrite Scarlett Solo (-127dB EIN).</p>"},{"location":"20_architecture/system_design_v8.0/#22-nats-stream-topology-the-backbone","title":"2.2 NATS Stream Topology (The Backbone)","text":"<p>We utilize 3 distinct persistence layers to manage data lifecycle and separation of concerns.</p>"},{"location":"20_architecture/system_design_v8.0/#a-pre_buffer-the-rolling-cache","title":"A. <code>PRE_BUFFER</code> (The Rolling Cache)","text":"<p>Captures \"Idle\" audio. - Subjects: <code>preroll.audio</code> - Storage: Memory (Ring Buffer) - Retention: Limits (Max Age: 6 Minutes) - Role: Allows the user to \"Go Back in Time\" 5 minutes when hitting Record.</p>"},{"location":"20_architecture/system_design_v8.0/#b-audio_stream-the-source-of-truth","title":"B. <code>AUDIO_STREAM</code> (The Source of Truth)","text":"<p>Stores the permanent session audio. - Subjects: <code>audio.live.&gt;</code>, <code>audio.backfill.&gt;</code> - Storage: File (NVMe) - Retention: WorkQueue (Messages persist until Ack'd by processors) - Max Age: 60 Minutes (Safety Net)</p>"},{"location":"20_architecture/system_design_v8.0/#c-transcription_stream-the-result","title":"C. <code>TRANSCRIPTION_STREAM</code> (The Result)","text":"<p>Stores all generated text, identity events, and fused results. - Subjects:     - <code>transcript.raw.&gt;</code> (Deepgram Output)     - <code>transcript.identity.&gt;</code> (OpenVINO Output)     - <code>transcript.final.&gt;</code> (Fused \"Zipped\" Output) - Storage: File (NVMe) - Retention: Limits (Max Age: 7 Days) - Role: Serves as the database for the Web UI.</p>"},{"location":"20_architecture/system_design_v8.0/#3-component-design","title":"3. Component Design","text":""},{"location":"20_architecture/system_design_v8.0/#31-service-audio-producer-the-ingress","title":"3.1 Service: <code>audio-producer</code> (The Ingress)","text":"<ul> <li>State: <code>IDLE</code> vs <code>ACTIVE</code>.</li> <li>Logic:<ul> <li>Atomic Switch: Routes microphone data to <code>preroll.audio</code> (IDLE) or <code>audio.live</code> (ACTIVE).</li> <li>Flash Flush: On \"Start Session\", triggers a background task to move <code>PRE_BUFFER</code> data to <code>audio.backfill</code>.</li> <li>EOS: Appends End-of-Stream headers to the backfill stream.</li> </ul> </li> </ul>"},{"location":"20_architecture/system_design_v8.0/#32-service-stt-provider-the-ear","title":"3.2 Service: <code>stt-provider</code> (The Ear)","text":"<ul> <li>Role: Deepgram Transcription.</li> <li>Dual Pipeline:<ol> <li>Live Worker: Priority <code>High</code>. Subscribes to <code>audio.live</code>. Minimal Latency.</li> <li>Backfill Worker: Priority <code>Background</code>. Subscribes to <code>audio.backfill</code>. Throttled upload to Deepgram.</li> </ol> </li> <li>Output: Publishes to <code>transcript.raw.{session_id}</code>.</li> </ul>"},{"location":"20_architecture/system_design_v8.0/#33-service-identifier-the-biometric-brain","title":"3.3 Service: <code>identifier</code> (The Biometric Brain)","text":"<ul> <li>Role: OpenVINO Speaker Identification.</li> <li>Dual Pipeline:<ol> <li>Live Worker: Priority <code>High</code>. Fast-path vector lookup.</li> <li>Backfill Worker: Priority <code>Background</code>. Processes backfill audio chunks to identify \"Who spoke 3 minutes ago\".</li> </ol> </li> <li>Output: Publishes to <code>transcript.identity.{session_id}</code>.</li> </ul>"},{"location":"20_architecture/system_design_v8.0/#34-service-identity-manager-the-zipper","title":"3.4 Service: <code>identity-manager</code> (The Zipper)","text":"<ul> <li>Role: Server-Side Data Fusion.</li> <li>Logic:<ul> <li>Subscribes to <code>transcript.raw</code> (Text) AND <code>transcript.identity</code> (Who).</li> <li>Buffering: Maintains a sliding window of recent text segments.</li> <li>Matching: Applies \"Identity Tags\" to Text Segments based on overlapping Timestamps.</li> <li>Resolution: Handles out-of-order arrival (e.g., Backfill identity arrives after Live text).</li> </ul> </li> <li>Output: Publishes <code>transcript.final.{session_id}</code> containing fully attributed JSON objects (Text + Speaker Name).</li> </ul>"},{"location":"20_architecture/system_design_v8.0/#35-service-api-gateway-the-view","title":"3.5 Service: <code>api-gateway</code> (The View)","text":"<ul> <li>Role: Simple Relay.</li> <li>Logic:<ul> <li>Replays <code>transcript.final.{session_id}</code> to connected WebSockets.</li> <li>Does NOT perform business logic or merging.</li> </ul> </li> </ul>"},{"location":"20_architecture/system_design_v8.0/#4-workflows","title":"4. Workflows","text":""},{"location":"20_architecture/system_design_v8.0/#41-the-time-travel-start","title":"4.1 \"The Time Travel Start\"","text":"<ol> <li>System is IDLE. <code>audio-producer</code> loops audio into <code>PRE_BUFFER</code>.</li> <li>User clicks \"Start Session\".</li> <li><code>audio-producer</code>:<ul> <li>Switches Live Microphone -&gt; <code>audio.live</code>.</li> <li>Spawns Task: Drain <code>PRE_BUFFER</code> -&gt; <code>audio.backfill</code>.</li> </ul> </li> <li><code>stt-provider</code> &amp; <code>identifier</code>:<ul> <li>Spin up Live Workers immediately (Latency &lt; 500ms).</li> <li>Spin up Backfill Workers to process the past 5 mins.</li> </ul> </li> <li><code>identity-manager</code>:<ul> <li>Receives Live events (Real-time).</li> <li>Receives Backfill events (Burst).</li> <li>Merges and emits <code>transcript.final</code>.</li> </ul> </li> <li>Web UI:<ul> <li>Receives a flood of \"Past\" messages (Backfill) followed by smooth \"Live\" messages.</li> </ul> </li> </ol>"},{"location":"20_architecture/threat_model/","title":"Threat Model (v7.3)","text":""},{"location":"20_architecture/threat_model/#1-overview","title":"1. Overview","text":"<p>This document identifies security threats to the Live STT system (v7.3 Industrial Split-Brain) and documents mitigations.</p>"},{"location":"20_architecture/threat_model/#2-assets-risks","title":"2. Assets &amp; Risks","text":"Asset Classification Storage Risk Voiceprints PII (Biometric) <code>/data/lancedb</code> HIGH Transcripts Sensitive <code>/data/nats</code> MEDIUM API Keys Credentials Env Vars HIGH"},{"location":"20_architecture/threat_model/#3-attack-surface","title":"3. Attack Surface","text":""},{"location":"20_architecture/threat_model/#31-nats-message-bus","title":"3.1 NATS Message Bus","text":"<ul> <li>Threat: Unauthorized subscription to <code>text.transcript</code> or <code>identity.event</code>.</li> <li>Mitigation:<ul> <li>NATS is isolated in <code>internal_overlay</code> network.</li> <li>No external port exposure (except 8222 for monitoring, localhost only).</li> </ul> </li> </ul>"},{"location":"20_architecture/threat_model/#32-physical-access-x86-nuc","title":"3.2 Physical Access (x86 NUC)","text":"<ul> <li>Threat: Theft of device.</li> <li>Mitigation:<ul> <li>Full Disk Encryption (LUKS): Data unreadable without passphrase/TPM.</li> <li>Secure Boot: Prevents booting malicious OS.</li> <li>BIOS Password: Prevents changing boot order.</li> </ul> </li> </ul>"},{"location":"20_architecture/threat_model/#33-cloud-connection","title":"3.3 Cloud Connection","text":"<ul> <li>Threat: Interception of audio stream to Deepgram.</li> <li>Mitigation: TLS 1.3 (HTTPS/WSS) for all outbound traffic.</li> </ul>"},{"location":"20_architecture/threat_model/#4-threat-scenarios","title":"4. Threat Scenarios","text":""},{"location":"20_architecture/threat_model/#41-evil-maid-attack","title":"4.1 \"Evil Maid\" Attack","text":"<p>Scenario: Attacker gains physical access to NUC in church AV rack. Defense: - BIOS Password prevents USB boot. - Chassis intrusion switch (if supported) logs event. - LUKS encryption prevents mounting drive on another machine.</p>"},{"location":"20_architecture/threat_model/#42-nats-injection","title":"4.2 NATS Injection","text":"<p>Scenario: Compromised container tries to inject fake identity events. Defense: - <code>identity-manager</code> validates <code>trace_id</code> correlation. - Future: NATS 2.10 Auth (User/Pass per service).</p>"},{"location":"20_architecture/threat_model/#5-security-architecture","title":"5. Security Architecture","text":""},{"location":"20_architecture/threat_model/#51-black-box-integrity","title":"5.1 \"Black Box\" Integrity","text":"<p>The loopback filesystem (<code>/data/nats.img</code>) is mounted with <code>data=journal</code>. - Benefit: Prevents corruption on power loss. - Security: Can be unmounted and encrypted as a single file for transport.</p>"},{"location":"20_architecture/threat_model/#52-biometric-privacy","title":"5.2 Biometric Privacy","text":"<ul> <li>Crypto-Shredding: Deleting the encryption key for archived audio renders it useless.</li> <li>Vector Anonymity: WeSpeaker embeddings cannot be easily reversed to raw audio.</li> </ul> <p>See Also: - Biometric Policy - HSI</p>"},{"location":"20_architecture/adrs/0000-use-record-architecture/","title":"ADR_TITLE_PLACEHOLDER","text":"<ul> <li>Status: Proposed * Date: YYYY-MM-DD ---</li> </ul>"},{"location":"20_architecture/adrs/0000-use-record-architecture/#context","title":"Context","text":"<p>Briefly describe the problem or issue this decision addresses. Include relevant background, constraints, assumptions, and forces influencing the decision.</p>"},{"location":"20_architecture/adrs/0000-use-record-architecture/#decision","title":"Decision","text":"<p>Clearly state the decision made. Be specific and concise.</p>"},{"location":"20_architecture/adrs/0000-use-record-architecture/#consequences","title":"Consequences","text":"<p>Describe the results and impact of this decision. Consider: * Positive consequences (benefits, improvements) * Negative consequences (drawbacks, trade-offs, limitations) * Risks and how they might be mitigated * Impact on other parts of the system or future decisions</p>"},{"location":"20_architecture/adrs/0000-use-record-architecture/#alternatives-considered","title":"Alternatives Considered","text":"<p>List other options that were evaluated before reaching the final decision. * Alternative 1: Description and why it wasn't chosen. * Alternative 2: Description and why it wasn't chosen. * (Add more as needed)</p>"},{"location":"20_architecture/adrs/0000-use-record-architecture/#references-optional","title":"References (Optional)","text":"<p>Link to relevant documentation, issues, discussions, or external resources.</p>"},{"location":"20_architecture/adrs/0001-zmq-broker/","title":"Use ZeroMQ XPUB/XSUB Broker Pattern","text":"<ul> <li>Status: SUPERSEDED by ADR-0009</li> <li>Date: 2025-11-19</li> </ul>"},{"location":"20_architecture/adrs/0001-zmq-broker/#context","title":"Context","text":"<p>The Live STT system requires a robust inter-process communication (IPC) mechanism to route audio data and events between 7 microservices (audio-producer, stt-provider, api-gateway, etc.). The system must support:</p> <ol> <li>High throughput: 16kHz PCM audio (~32 KB/s per channel)</li> <li>Low latency: \\&lt; 500ms end-to-end (microphone \u2192 UI)</li> <li>Decoupling: Services should not know about each other's existence</li> <li>Resilience: Individual service failures should not crash the message bus</li> <li>Simplicity: Minimal operational overhead (no external dependencies like Kafka/RabbitMQ)</li> </ol> <p>The system is deployed on edge hardware (Jetson Orin Nano) with limited resources and must run entirely offline (except for Deepgram API connectivity).</p>"},{"location":"20_architecture/adrs/0001-zmq-broker/#decision","title":"Decision","text":"<p>We will use ZeroMQ (\u00d8MQ) with the XPUB/XSUB proxy pattern as the central message broker.</p>"},{"location":"20_architecture/adrs/0001-zmq-broker/#implementation","title":"Implementation","text":"<ul> <li>Broker: Single C++ binary (<code>zmq_proxy</code>) running in a scratch Docker container</li> <li>Topology: Publishers connect to XSUB socket (<code>tcp://*:5555</code>), subscribers connect to XPUB socket (<code>tcp://*:5556</code>)</li> <li>Topics: Services publish/subscribe to topics (<code>audio.raw</code>, <code>text.transcript</code>, <code>system.alert</code>, <code>identity.event</code>)</li> <li>Protocol: TCP over Docker internal network</li> </ul>"},{"location":"20_architecture/adrs/0001-zmq-broker/#code-example","title":"Code Example","text":"<pre><code>// audio-broker/src/main.cpp\nzmq::context_t context(1);\nzmq::socket_t frontend(context, ZMQ_XSUB);\nzmq::socket_t backend(context, ZMQ_XPUB);\n\nfrontend.bind(\"tcp://*:5555\");\nbackend.bind(\"tcp://*:5556\");\nzmq::proxy(frontend, backend);\n</code></pre>"},{"location":"20_architecture/adrs/0001-zmq-broker/#consequences","title":"Consequences","text":""},{"location":"20_architecture/adrs/0001-zmq-broker/#positive","title":"Positive","text":"<ul> <li>Zero configuration: No broker config files, no queues to declare, no exchanges to configure</li> <li>Low latency: Direct memory-to-memory transfer, no persistence layer</li> <li>Lightweight: Broker binary is \\&lt;1MB, uses \\&lt;10MB RAM</li> <li>Automatic reconnection: ZMQ handles connection drops transparently</li> <li>Language agnostic: Python services use <code>pyzmq</code>, C++ broker uses libzmq</li> </ul>"},{"location":"20_architecture/adrs/0001-zmq-broker/#negative","title":"Negative","text":"<ul> <li>No persistence: Messages are dropped if no subscribers are connected (acceptable for real-time audio)</li> <li>No guaranteed delivery: Fire-and-forget model (mitigated by on-disk buffering in stt-provider)</li> <li>No built-in authentication: Trust-based (acceptable since all services run in same Docker network)</li> <li>Manual topic filtering: Services must subscribe to specific topics (not a pub/sub \"smart broker\")</li> </ul>"},{"location":"20_architecture/adrs/0001-zmq-broker/#risks-and-mitigations","title":"Risks and Mitigations","text":"<ul> <li>Risk: Broker becomes single point of failure</li> <li>Mitigation: <code>restart: always</code> policy, broker is stateless so restarts are instant</li> <li>Risk: Topic namespace collisions</li> <li>Mitigation: Structured topic naming (<code>category.subcategory</code>), documented in HSI</li> </ul>"},{"location":"20_architecture/adrs/0001-zmq-broker/#impact-on-other-decisions","title":"Impact on Other Decisions","text":"<ul> <li>Enables ADR-0002 - Services communicate via broker, not direct HTTP calls</li> <li>Simplifies Multi-Tier Hardware - ZMQ works identically on Jetson, desktop, and cloud</li> </ul>"},{"location":"20_architecture/adrs/0001-zmq-broker/#alternatives-considered","title":"Alternatives Considered","text":""},{"location":"20_architecture/adrs/0001-zmq-broker/#alternative-1-rabbitmq","title":"Alternative 1: RabbitMQ","text":"<p>Why rejected: - Requires separate Erlang runtime (\\~100MB+ overhead) - Persistence layer unnecessary for real-time streams - Configuration complexity (exchanges, queues, bindings) - Not designed for low-latency binary data</p>"},{"location":"20_architecture/adrs/0001-zmq-broker/#alternative-2-mqtt-mosquitto","title":"Alternative 2: MQTT (Mosquitto)","text":"<p>Why rejected: - Designed for IoT telemetry (small messages), not audio streaming - QoS levels add latency - Broker state management (subscriptions, retained messages) unnecessary</p>"},{"location":"20_architecture/adrs/0001-zmq-broker/#alternative-3-grpc-streaming","title":"Alternative 3: gRPC Streaming","text":"<p>Why rejected: - Requires service discovery (services must know each other's addresses) - HTTP/2 overhead for high-frequency messages - No native pub/sub (would need manual fan-out logic)</p>"},{"location":"20_architecture/adrs/0001-zmq-broker/#alternative-4-redis-pubsub","title":"Alternative 4: Redis Pub/Sub","text":"<p>Why rejected: - Requires Redis server (\\~30MB memory baseline) - All messages broadcast to all subscribers (no topic filtering until client-side) - No native binary support (would need base64 encoding overhead)</p>"},{"location":"20_architecture/adrs/0001-zmq-broker/#references","title":"References","text":"<ul> <li>ZeroMQ Guide</li> <li>HSI Document - ZMQ topology details</li> <li>System Design - Section 2.3 (Messaging Core)</li> </ul>"},{"location":"20_architecture/adrs/0002-decoupled-ui/","title":"Split stt-provider from api-gateway (Decoupled UI)","text":"<ul> <li>Status: Accepted</li> <li>Date: 2025-11-19</li> <li>Supersedes: Version 5.x architecture (monolithic \"Brain\" service)</li> </ul>"},{"location":"20_architecture/adrs/0002-decoupled-ui/#context","title":"Context","text":"<p>In system design Version 5.x, the <code>api-gateway</code> service handled both: 1. UI/Orchestration: Serving the web interface, managing WebSocket connections, storing config in SQLite 2. Transcription: Managing the Deepgram WebSocket  connection, handling reconnection logic, buffering audio</p> <p>This created a failure domain coupling: if the Deepgram client crashed (e.g., due to a network error or API bug), the entire UI would become unresponsive, preventing admins from diagnosing the issue or manually recovering the system.</p> <p>Problem Statement: The kiosk UI must remain live and manageable even if the transcription engine encounters a fatal error or network outage.</p>"},{"location":"20_architecture/adrs/0002-decoupled-ui/#decision","title":"Decision","text":"<p>We will split transcription logic into a separate <code>stt-provider</code> service (Version 6.0).</p>"},{"location":"20_architecture/adrs/0002-decoupled-ui/#new-architecture","title":"New Architecture","text":"<pre><code>audio-producer \u2192 broker \u2192 stt-provider (Deepgram client)\n                                \u2193 (publishes text.transcript)\n                          broker \u2192 api-gateway (UI)\n</code></pre>"},{"location":"20_architecture/adrs/0002-decoupled-ui/#responsibilities","title":"Responsibilities","text":"Service Role Cannot Touch stt-provider Cloud integration, resilience, QA Web UI, config DB api-gateway Web UI, config, correlation Raw audio, Deepgram API"},{"location":"20_architecture/adrs/0002-decoupled-ui/#communication","title":"Communication","text":"<ul> <li><code>stt-provider</code> subscribes to <code>audio.raw</code> from broker</li> <li><code>stt-provider</code> publishes <code>text.transcript</code> and <code>system.alert</code> to broker</li> <li><code>api-gateway</code> subscribes to <code>text.transcript</code> and <code>system.alert</code></li> </ul>"},{"location":"20_architecture/adrs/0002-decoupled-ui/#consequences","title":"Consequences","text":""},{"location":"20_architecture/adrs/0002-decoupled-ui/#positive","title":"Positive","text":"<ul> <li>Fault isolation: Deepgram SDK crash does not affect UI responsiveness</li> <li>Independent scaling: <code>stt-provider</code> can be restarted without dropping WebSocket connections to clients</li> <li>Clear separation of concerns: <code>api-gateway</code> has no audio processing code</li> <li>Improved testability: Can mock <code>text.transcript</code> events to test UI without Deepgram API</li> </ul>"},{"location":"20_architecture/adrs/0002-decoupled-ui/#negative","title":"Negative","text":"<ul> <li>Additional container: One more service to monitor (mitigated by <code>health-watchdog</code>)</li> <li>Increased complexity: Correlation logic must be added to <code>api-gateway</code> (maps Speaker 0 \u2192 Tom via identity events)</li> </ul>"},{"location":"20_architecture/adrs/0002-decoupled-ui/#risks-and-mitigations","title":"Risks and Mitigations","text":"<ul> <li>Risk: Broker becomes bottleneck</li> <li>Mitigation: ZMQ is designed for high-throughput IPC, benchmarked at &gt;1M msg/s</li> <li>Risk: Message ordering issues (transcript arrives before identity event)</li> <li>Mitigation: Timestamps in payloads, <code>api-gateway</code> maintains correlation buffer</li> </ul>"},{"location":"20_architecture/adrs/0002-decoupled-ui/#impact-on-security","title":"Impact on Security","text":"<ul> <li>Benefit: <code>api-gateway</code> cannot be compromised via audio buffer overflow attacks (no raw audio access)</li> <li>Trade-off: More attack surface (two services vs. one), mitigated by container isolation</li> </ul>"},{"location":"20_architecture/adrs/0002-decoupled-ui/#alternatives-considered","title":"Alternatives Considered","text":""},{"location":"20_architecture/adrs/0002-decoupled-ui/#alternative-1-keep-monolithic-brain","title":"Alternative 1: Keep Monolithic Brain","text":"<p>Why rejected: - Single point of failure violates high-availability requirement - Difficult to debug transcription issues when UI is frozen</p>"},{"location":"20_architecture/adrs/0002-decoupled-ui/#alternative-2-run-stt-provider-in-separate-thread-not-container","title":"Alternative 2: Run stt-provider in Separate Thread (Not Container)","text":"<p>Why rejected: - Python threading does not provide crash isolation (one uncaught exception crashes process) - Cannot independently restart transcription logic without restarting UI</p>"},{"location":"20_architecture/adrs/0002-decoupled-ui/#alternative-3-use-supervisor-systemd-style-process-manager","title":"Alternative 3: Use Supervisor (systemd-style Process Manager)","text":"<p>Why rejected: - Adds complexity vs. Docker's built-in <code>restart: always</code> - Does not provide network-level isolation</p>"},{"location":"20_architecture/adrs/0002-decoupled-ui/#references","title":"References","text":"<ul> <li>System Design V6.0 - Section 3 (Component Design)</li> <li>Architecture Definition - Component interaction diagram</li> <li>Roadmap - Phase 2 (M3: stt-provider implementation)</li> </ul>"},{"location":"20_architecture/adrs/0003-multi-tier-hardware/","title":"Multi-Tier Hardware Strategy","text":"<ul> <li>Status: Accepted</li> <li>Date: 2025-11-19</li> </ul>"},{"location":"20_architecture/adrs/0003-multi-tier-hardware/#context","title":"Context","text":"<p>The Live STT system requires GPU acceleration for optional features (speaker identification via SpeechBrain), but must also support:</p> <ol> <li>Development: Developers on laptops without NVIDIA GPUs</li> <li>Testing: CI/CD pipelines on cloud runners (CPU-only)</li> <li>Production: Jetson Orin Nano (embedded ARM64 + CUDA)</li> <li>BYOD Deployment: Users with desktop GPUs (x64 + CUDA/ROCm)</li> </ol> <p>The system must be portable across hardware tiers without maintaining separate codebases per platform.</p>"},{"location":"20_architecture/adrs/0003-multi-tier-hardware/#decision","title":"Decision","text":"<p>We will implement a Three-Tier Hardware Strategy with conditional feature enablement:</p>"},{"location":"20_architecture/adrs/0003-multi-tier-hardware/#hardware-tiers","title":"Hardware Tiers","text":"Tier Target Hardware GPU Arch Services Enabled Tier 1 Jetson Orin Nano NVIDIA (CUDA) ARM64 All (including <code>identifier</code>) Tier 2 Desktop GPU NVIDIA/AMD x86_64 All (including <code>identifier</code>) Tier 3 CPU-only None x86_64 Core stack (no <code>identifier</code>)"},{"location":"20_architecture/adrs/0003-multi-tier-hardware/#implementation-strategy","title":"Implementation Strategy","text":"<p>1. Unified Dockerfile with Build Args</p> <pre><code># services/identifier/Dockerfile\nARG BASE_IMAGE=python:3.13-slim  # Default: Tier 3\nFROM ${BASE_IMAGE}\n\n# GPU dependencies only installed if base image has CUDA\nRUN if [ -f /usr/local/cuda/version.txt ]; then \\\n      pip install torch torchvision --index-url https://download.pytorch.org/whl/cu121; \\\n    else \\\n      pip install torch torchvision --index-url https://download.pytorch.org/whl/cpu; \\\n    fi\n</code></pre> <p>2. Docker Compose Profiles</p> <pre><code>services:\n  identifier:\n    profiles: [\"gpu\"]  # Only started with `docker compose --profile gpu up`\n    build:\n      context: ./services/identifier\n      args:\n        BASE_IMAGE: ${IDENTIFIER_BASE_IMAGE:-python:3.13-slim}\n</code></pre> <p>3. Hardware-Specific Overrides</p> <pre><code># Tier 1 (Jetson)\nexport IDENTIFIER_BASE_IMAGE=nvcr.io/nvidia/l4t-pytorch:r36.2.0-pth2.1-py3\n\n# Tier 2 (Desktop GPU)\nexport IDENTIFIER_BASE_IMAGE=pytorch/pytorch:2.1.0-cuda12.1-cudnn8-runtime\n\n# Tier 3 (CPU)\n# Use default (no override needed)\n</code></pre>"},{"location":"20_architecture/adrs/0003-multi-tier-hardware/#consequences","title":"Consequences","text":""},{"location":"20_architecture/adrs/0003-multi-tier-hardware/#positive","title":"Positive","text":"<ul> <li>Single codebase: No platform-specific branches</li> <li>Zero-config for Tier 3: Developers can run <code>docker compose up</code> without modifications</li> <li>Graceful degradation: Core transcription works on all tiers, GPU features optional</li> <li>Future-proof: Can add Tier 4 (Cloud TPU), Tier 5 (WebGPU), etc. with same pattern</li> </ul>"},{"location":"20_architecture/adrs/0003-multi-tier-hardware/#negative","title":"Negative","text":"<ul> <li>Build complexity: Developers must understand build args and profiles</li> <li>Testing matrix: Must test on all 3 tiers (CI runs Tier 3, manual testing on Tier 1/2)</li> <li>Documentation burden: Must clearly document which features require GPU</li> </ul>"},{"location":"20_architecture/adrs/0003-multi-tier-hardware/#risks-and-mitigations","title":"Risks and Mitigations","text":"<ul> <li>Risk: User tries to run <code>identifier</code> on Tier 3, gets cryptic error</li> <li>Mitigation: <code>identifier</code> service checks for GPU at startup, exits gracefully with clear message</li> <li>Risk: Image size bloat (CUDA libraries in Tier 1/2 images)</li> <li>Mitigation: Multi-stage builds, separate dev/prod images</li> </ul>"},{"location":"20_architecture/adrs/0003-multi-tier-hardware/#alternatives-considered","title":"Alternatives Considered","text":""},{"location":"20_architecture/adrs/0003-multi-tier-hardware/#alternative-1-separate-repositories-per-tier","title":"Alternative 1: Separate Repositories per Tier","text":"<p>Why rejected: - Code duplication (bug fixes must be ported across repos) - Fragmented documentation - Difficult to ensure feature parity</p>"},{"location":"20_architecture/adrs/0003-multi-tier-hardware/#alternative-2-runtime-gpu-detection","title":"Alternative 2: Runtime GPU Detection","text":"<p>Why rejected: - Still requires bundling GPU libraries in all images (bloat) - Startup time increased by probing hardware - Harder to test (cannot force CPU mode on GPU machine)</p>"},{"location":"20_architecture/adrs/0003-multi-tier-hardware/#alternative-3-cloud-only-gpu-offload-to-aws-lambda","title":"Alternative 3: Cloud-Only GPU (Offload to AWS Lambda)","text":"<p>Why rejected: - Violates edge-first architecture - Adds latency (network round-trip for every identification) - Additional ongoing costs (AWS Lambda)</p>"},{"location":"20_architecture/adrs/0003-multi-tier-hardware/#references","title":"References","text":"<ul> <li>System Design - Section 2.2 (Hardware Tiers)</li> <li>Deployment Runbooks - Tier-specific deploy procedures</li> <li>Hardware BOM - Recommended hardware per tier</li> </ul>"},{"location":"20_architecture/adrs/0004-deepgram-selection/","title":"Select Deepgram as STT Provider","text":"<ul> <li>Status: Accepted</li> <li>Date: 2025-11-19</li> </ul>"},{"location":"20_architecture/adrs/0004-deepgram-selection/#context","title":"Context","text":"<p>The Live STT system requires a cloud-based Speech-to-Text (STT) service with the following requirements:</p> <ol> <li>Real-time streaming: WebSocket-based, not batch transcription</li> <li>High accuracy: Church liturgy, biblical terminology, proper nouns (staff names)</li> <li>Endpointing: Automatic sentence segmentation (reduces UI flicker)</li> <li>Custom vocabulary: Support for domain-specific phrases (e.g., \"Eucharist\", \"homily\")</li> <li>Speaker diarization: Distinguish multiple speakers (optional but preferred)</li> <li>Resilience: Graceful handling of connection drops, support for audio catch-up</li> </ol> <p>Non-Requirements: - On-device STT (GPU constraints on Jetson, model size) - Multi-language support (English-only for V1)</p>"},{"location":"20_architecture/adrs/0004-deepgram-selection/#decision","title":"Decision","text":"<p>We will use Deepgram as the primary STT provider.</p>"},{"location":"20_architecture/adrs/0004-deepgram-selection/#integration-details","title":"Integration Details","text":"<ul> <li>API: Deepgram Live Streaming API (WebSocket)</li> <li>Model: <code>nova-2</code> (latest general model)</li> <li>Features Used:</li> <li><code>punctuate=true</code>: Automatic punctuation</li> <li><code>diarize=true</code>: Speaker labels (Speaker 0, Speaker 1, ...)</li> <li><code>smart_format=true</code>: Format numbers, dates</li> <li><code>keywords</code>: Custom PhraseSet (initial_phrases.json)</li> <li><code>endpointing=300</code>: 300ms silence triggers utterance boundary</li> </ul>"},{"location":"20_architecture/adrs/0004-deepgram-selection/#example-connection","title":"Example Connection","text":"<pre><code>from deepgram import DeepgramClient, LiveOptions\n\nclient = DeepgramClient(api_key=os.getenv(\"DEEPGRAM_API_KEY\"))\noptions = LiveOptions(\n    model=\"nova-2\",\n    punctuate=True,\n    diarize=True,\n    smart_format=True,\n    keywords=[\"Eucharist:5\", \"homily:5\"],  # Boost weight\n    endpointing=300\n)\nconnection = client.listen.websocket.v(\"1\")\n</code></pre>"},{"location":"20_architecture/adrs/0004-deepgram-selection/#consequences","title":"Consequences","text":""},{"location":"20_architecture/adrs/0004-deepgram-selection/#positive","title":"Positive","text":"<ul> <li>Superior accuracy: Deepgram Nova-2 achieves ~90% WER on general speech (subjectively better than competitors on liturgical content)</li> <li>Low latency: Typically \\&lt;300ms from audio chunk \u2192 transcript event</li> <li>Excellent docs: Python SDK well-maintained, WebSocket reconnection handled by library</li> <li>Custom vocabulary: PhraseSet API allows boosting rare terms without retraining</li> <li>Generous pricing: \\$0.0043/min (vs. Google \\$0.006/min, AWS \\$0.024/min)</li> </ul>"},{"location":"20_architecture/adrs/0004-deepgram-selection/#negative","title":"Negative","text":"<ul> <li>Cloud dependency: Requires persistent internet (mitigated by on-disk buffering in <code>stt-provider</code>)</li> <li>Vendor lock-in: Switching to different STT provider requires rewriting <code>stt-provider</code> client code</li> <li>No on-prem option: Cannot run Deepgram models locally (acceptable for V1)</li> </ul>"},{"location":"20_architecture/adrs/0004-deepgram-selection/#risks-and-mitigations","title":"Risks and Mitigations","text":"<ul> <li>Risk: Deepgram API outage</li> <li>Mitigation: Buffer audio to NVMe during outages (M5), catch up on reconnect</li> <li>Risk: API pricing changes</li> <li>Mitigation: Budget monitoring, fallback to Google Cloud STT if costs spike</li> <li>Risk: Diarization errors (Speaker 0 vs Speaker 1 swapped)</li> <li>Mitigation: Local speaker identification with <code>identifier</code> service overrides Deepgram labels (M12)</li> </ul>"},{"location":"20_architecture/adrs/0004-deepgram-selection/#alternatives-considered","title":"Alternatives Considered","text":""},{"location":"20_architecture/adrs/0004-deepgram-selection/#alternative-1-google-cloud-speech-to-text","title":"Alternative 1: Google Cloud Speech-to-Text","text":"<p>Pros: - Excellent accuracy (comparable to Deepgram) - Native GCP integration (if using GCP for other services)</p> <p>Why rejected: - 40% higher cost (\\$0.006/min vs \\$0.0043/min) - Worse WebSocket reconnection handling (manual exponential backoff required) - PhraseSet boosting less effective (anecdotal) - reports of worse diarization accuracy</p>"},{"location":"20_architecture/adrs/0004-deepgram-selection/#alternative-2-aws-transcribe","title":"Alternative 2: AWS Transcribe","text":"<p>Pros: - Native AWS integration - Support for custom vocabulary</p> <p>Why rejected: - 5x higher cost (\\$0.024/min) - Batch-only transcription (streaming via HTTP Live requires polling) - No native speaker diarization (requires Amazon Transcribe Medical)</p>"},{"location":"20_architecture/adrs/0004-deepgram-selection/#alternative-3-azure-speech-services","title":"Alternative 3: Azure Speech Services","text":"<p>Pros: - Good accuracy - Native Azure integration</p> <p>Why rejected: - 3x higher cost (\\$0.015/min) - Requires Azure account (all other infrastructure is Docker-based) - SDK less mature than Deepgram (more boilerplate)</p>"},{"location":"20_architecture/adrs/0004-deepgram-selection/#alternative-4-whisper-openai-on-device","title":"Alternative 4: Whisper (OpenAI) - On-Device","text":"<p>Pros: - Free (open-source model) - No cloud dependency - Excellent accuracy</p> <p>Why rejected: - Inference latency: \\~2-5 seconds per 30s chunk on Jetson (unacceptable for real-time) - VRAM requirements: \\~3GB for <code>medium</code> model (Jetson only has 8GB total) - No streaming: Must buffer audio in chunks, sends \"bursts\" of transcripts (poor UX)</p>"},{"location":"20_architecture/adrs/0004-deepgram-selection/#references","title":"References","text":"<ul> <li>Deepgram Documentation</li> <li>stt-provider Implementation - Integration code</li> <li>PhraseSet Seed Data - Custom vocabulary</li> <li>Roadmap M3 - stt-provider development milestone</li> </ul>"},{"location":"20_architecture/adrs/0005-balenaos-deployment/","title":"Use BalenaOS for Edge Deployment","text":"<ul> <li>Status: Accepted</li> <li>Date: 2025-11-19</li> </ul>"},{"location":"20_architecture/adrs/0005-balenaos-deployment/#context","title":"Context","text":"<p>The initial use case for the Live STT system will be deployed to edge hardware (Jetson Orin Nano) in a church environment with the following operational requirements:</p> <ol> <li>Remote management: Deploy updates without physical access to devices</li> <li>Over-the-air updates: Zero-downtime container updates</li> <li>Public URL: HTTPS endpoint for remote access without static IP or VPN</li> </ol> <p>The system must be managed by non-technical staff (church volunteers) while remaining debuggable by remote developers.</p>"},{"location":"20_architecture/adrs/0005-balenaos-deployment/#decision","title":"Decision","text":"<p>We will use BalenaOS as the deployment platform for Tier 1 (Jetson Orin Nano) devices.</p>"},{"location":"20_architecture/adrs/0005-balenaos-deployment/#key-features-used","title":"Key Features Used","text":"<ul> <li>balenaCloud: Fleet management dashboard</li> <li>Public Device URL: Auto-provisioned HTTPS endpoint (<code>&lt;uuid&gt;.balena-devices.com</code>)</li> <li>Delta Updates: Only changed layers pushed to device (saves bandwidth)</li> <li>Supervisor: Auto-restart containers, log aggregation</li> <li>SSH Access: Secure remote shell via balena CLI (<code>balena ssh &lt;device-uuid&gt;</code>)</li> </ul>"},{"location":"20_architecture/adrs/0005-balenaos-deployment/#deployment-workflow","title":"Deployment Workflow","text":"<pre><code># Developer pushes update\nbalena push live-stt-fleet\n\n# BalenaCloud builds images, generates delta\n# Supervisor pulls delta (~10MB vs ~500MB full image)\n# Containers restarted with new version\n# Public URL remains accessible during update\n</code></pre>"},{"location":"20_architecture/adrs/0005-balenaos-deployment/#consequences","title":"Consequences","text":""},{"location":"20_architecture/adrs/0005-balenaos-deployment/#positive","title":"Positive","text":"<ul> <li>Zero-config networking: No port forwarding, no static IP, no DDNS</li> <li>Built-in TPM support: Balena integrates with Jetson's TPM 2.0 module</li> <li>SSH tunneling: Developers can debug live devices via <code>balena ssh</code> (no exposed SSH port)</li> <li>Log aggregation: All container logs viewable in balenaCloud dashboard</li> <li>Immutable infrastructure: Every deploy is a fresh container (no config drift)</li> </ul>"},{"location":"20_architecture/adrs/0005-balenaos-deployment/#negative","title":"Negative","text":"<ul> <li>Vendor lock-in: Migrating to vanilla Docker/Kubernetes requires rewriting deployment scripts</li> <li>Internet dependency for updates: Cannot push updates during internet outages (acceptable, updates are not urgent)</li> <li>balenaCloud dependency: If Balena goes down, cannot deploy new updates (existing devices unaffected)</li> <li>Cost: \\$10/month per device after 10 devices (free tier: 10 devices)</li> </ul>"},{"location":"20_architecture/adrs/0005-balenaos-deployment/#risks-and-mitigations","title":"Risks and Mitigations","text":"<ul> <li>Risk: Balena company shutdown</li> <li>Mitigation: BalenaOS is open-source, can self-host balenaCloud replacement</li> <li>Risk: Supervisor bug causes boot loop</li> <li>Mitigation: Balena has rollback mechanism, can revert to previous release</li> <li>Risk: Public URL exposes device to attacks</li> <li>Mitigation: Ticket-based WebSocket auth (M7), rate limiting</li> </ul>"},{"location":"20_architecture/adrs/0005-balenaos-deployment/#alternatives-considered","title":"Alternatives Considered","text":""},{"location":"20_architecture/adrs/0005-balenaos-deployment/#alternative-1-standard-docker-portainer","title":"Alternative 1: Standard Docker + Portainer","text":"<p>Pros: - No vendor lock-in - Lower cost (free)</p> <p>Why rejected: - No remote access solution: Requires VPN or exposed SSH (security risk) - Manual updates: Must SSH to each device, run <code>docker compose pull</code> manually - No fleet management: Cannot push updates to 10+ devices simultaneously</p>"},{"location":"20_architecture/adrs/0005-balenaos-deployment/#alternative-2-kubernetes-k3s-on-jetson","title":"Alternative 2: Kubernetes (K3s on Jetson)","text":"<p>Pros: - Industry-standard orchestration - Rich ecosystem (Helm charts, operators)</p> <p>Why rejected: - Overkill for single-device deployment: K3s designed for clusters, not edge appliances - Resource overhead: \\~500MB RAM for control plane (Jetson only has 8GB total) - Complexity: Requires Kubernetes expertise for troubleshooting</p>"},{"location":"20_architecture/adrs/0005-balenaos-deployment/#alternative-3-ansible-docker-compose","title":"Alternative 3: Ansible + Docker Compose","text":"<p>Pros: - Open-source - Flexible (can target any Linux host)</p> <p>Why rejected: - No fleet visibility: Must SSH to each device to check status - Playbook authoring: Requires YAML expertise (higher barrier than <code>git push</code>) - No automatic rollback: Failed deploy requires manual intervention</p>"},{"location":"20_architecture/adrs/0005-balenaos-deployment/#alternative-4-aws-iot-greengrass","title":"Alternative 4: AWS IoT Greengrass","text":"<p>Pros: - Native AWS integration - Lambda@Edge support</p> <p>Why rejected: - AWS lock-in: Entire stack becomes AWS-dependent - Complexity: Greengrass architecture is heavyweight (multiple daemons) - Cost: Per-device pricing higher than Balena</p>"},{"location":"20_architecture/adrs/0005-balenaos-deployment/#references","title":"References","text":"<ul> <li>Balena Documentation</li> <li>Deployment Runbooks - Balena deploy procedures</li> <li>System Design - Section 2.1 (Discovery), Section 7 (Deployment)</li> </ul>"},{"location":"20_architecture/adrs/0006-maintainer-tooling/","title":"Maintainer Tooling vs. End-User Admin Interface","text":"<ul> <li>Status: Accepted</li> <li>Date: 2025-11-24</li> <li>Deciders: Tom Dakan</li> </ul>"},{"location":"20_architecture/adrs/0006-maintainer-tooling/#context","title":"Context","text":"<p>The Live STT system requires two distinct categories of administrative functionality:</p> <ol> <li>End-User Operations (M8: Admin Dashboard)</li> <li>Routine management (PhraseSet editing, user enrollment)</li> <li>Polished UI suitable for non-technical operators</li> <li> <p>Production-ready, stable interfaces</p> </li> <li> <p>Developer/Maintainer Operations (This ADR)</p> </li> <li>Deployment validation (thermal burn-in, network resilience tests)</li> <li>Hardware diagnostics (GPU availability, disk space, temperature monitoring)</li> <li>Quality assurance (running Gold Standard regression tests manually)</li> <li>Troubleshooting utilities (log analysis, service health checks)</li> </ol> <p>Problem Statement: Developer/maintainer operations are too technical for the polished admin UI, but too important to leave ad-hoc or undocumented. We need a formalized approach to maintainer tooling.</p>"},{"location":"20_architecture/adrs/0006-maintainer-tooling/#decision","title":"Decision","text":"<p>We will implement a two-tier administrative interface strategy:</p>"},{"location":"20_architecture/adrs/0006-maintainer-tooling/#tier-1-end-user-admin-dashboard-m8","title":"Tier 1: End-User Admin Dashboard (M8)","text":"<ul> <li>Technology: SQLAdmin integrated into <code>api-gateway</code></li> <li>Access: Local network only (<code>:8000/admin</code>)</li> <li>Audience: Church staff, operators, admins</li> <li>Examples: PhraseSet editor, speaker enrollment, basic status</li> </ul>"},{"location":"20_architecture/adrs/0006-maintainer-tooling/#tier-2-maintainerdevops-tools-m85","title":"Tier 2: Maintainer/DevOps Tools (M8.5)","text":"<ul> <li>Technology: <code>just</code> command recipes + optional barebones web dashboard</li> <li>Access:</li> <li>Primary: CLI via Balena SSH (<code>balena ssh &lt;device-uuid&gt;</code>)</li> <li>Optional: Simple web UI on port <code>:9000</code> (disabled by default in production)</li> <li>Audience: System administrators, deployers, troubleshooters</li> <li>Examples: Hardware burn-in, WER regression tests, log aggregation</li> </ul>"},{"location":"20_architecture/adrs/0006-maintainer-tooling/#architecture","title":"Architecture","text":""},{"location":"20_architecture/adrs/0006-maintainer-tooling/#phase-1-cli-first-m851","title":"Phase 1: CLI-First (M8.5.1)","text":"<p>Extend <code>justfile</code> with maintainer commands:</p> <pre><code># Deployment validation\njust burn-in-test          # 60-min stress-ng + temp monitoring\njust validate-network      # 10-min offline buffer test\njust validate-gold-corpus  # Run WER regression test\n\n# Diagnostics\njust health-check          # Check all services + hardware\njust gpu-info              # Verify GPU availability (Tier 1/2)\njust disk-usage            # Report /data volume usage\n\n# Troubleshooting\njust logs-aggregate        # Tail all service logs\njust reset-buffers         # Clear /data/buffer (troubleshooting)\n</code></pre> <p>Access Method:</p> <pre><code>balena ssh &lt;device-uuid&gt;\ncd /app  # Application directory\njust burn-in-test\n</code></pre>"},{"location":"20_architecture/adrs/0006-maintainer-tooling/#phase-2-optional-web-dashboard-m852-future","title":"Phase 2: Optional Web Dashboard (M8.5.2 - Future)","text":"<p>If CLI proves insufficient, add minimal Flask/FastAPI service:</p> <pre><code>devops-dashboard:\n  build: ./services/devops-dashboard\n  ports:\n    - \"9000:9000\"  # Separate port from admin UI\n  environment:\n    - ENABLE_DASHBOARD=false  # Disabled by default\n</code></pre> <p>Features: - Real-time burn-in progress bars - Live log tailing (web-based <code>docker logs -f</code>) - One-click regression test execution - Hardware metrics visualization (temp, GPU util)</p> <p>Security: Only runs when explicitly enabled, local network only</p>"},{"location":"20_architecture/adrs/0006-maintainer-tooling/#consequences","title":"Consequences","text":""},{"location":"20_architecture/adrs/0006-maintainer-tooling/#positive","title":"Positive","text":"<ul> <li>Clear separation of concerns: Routine ops vs. deployment/diagnostics</li> <li>Low initial complexity: CLI-first approach requires minimal new code</li> <li>Balena compatibility: SSH access is native to BalenaOS</li> <li>Flexibility: Can add web dashboard later if needed</li> <li>Documentation: Commands are self-documenting via <code>just --list</code></li> </ul>"},{"location":"20_architecture/adrs/0006-maintainer-tooling/#negative","title":"Negative","text":"<ul> <li>Requires CLI familiarity: Deployers need SSH comfort (mitigated by good docs)</li> <li>Two admin interfaces: Potential confusion (mitigated by clear naming: \"Admin UI\" vs. \"DevOps CLI\")</li> <li>Balena-specific: <code>just</code> commands assume Balena environment (acceptable for Tier 1 focus)</li> </ul>"},{"location":"20_architecture/adrs/0006-maintainer-tooling/#risks-and-mitigations","title":"Risks and Mitigations","text":"<ul> <li>Risk: Less technical deployers struggle with CLI</li> <li>Mitigation: Provide step-by-step runbooks, consider web dashboard in M8.5.2</li> <li>Risk: <code>just</code> commands not portable to non-Balena environments</li> <li>Mitigation: Keep commands simple, avoid Balena-specific APIs</li> <li>Risk: Security of web dashboard (if implemented)</li> <li>Mitigation: Disabled by default, local network only, optional feature</li> </ul>"},{"location":"20_architecture/adrs/0006-maintainer-tooling/#alternatives-considered","title":"Alternatives Considered","text":""},{"location":"20_architecture/adrs/0006-maintainer-tooling/#alternative-1-single-unified-admin-ui","title":"Alternative 1: Single Unified Admin UI","text":"<p>Combine maintainer/devops tools into the SQLAdmin dashboard.</p> <p>Why Rejected: - Clutters end-user interface with technical noise - Burn-in tests can take 60+ minutes (not suitable for web UI timeout) - Hardware diagnostics require system-level access (awkward via web)</p>"},{"location":"20_architecture/adrs/0006-maintainer-tooling/#alternative-2-bash-scripts-only","title":"Alternative 2: Bash Scripts Only","text":"<p>Provide shell scripts instead of <code>just</code> recipes.</p> <p>Why Rejected: - <code>just</code> provides better discoverability (<code>just --list</code>) - <code>just</code> handles dependencies and command composition elegantly - Already using <code>justfile</code> for dev workflows</p>"},{"location":"20_architecture/adrs/0006-maintainer-tooling/#alternative-3-balena-supervisor-api","title":"Alternative 3: Balena Supervisor API","text":"<p>Use Balena's built-in device management API for operations.</p> <p>Why Rejected: - Limited to Balena environments (not portable to Tier 2/3) - Requires learning Balena-specific APIs - Less flexible than custom scripts</p>"},{"location":"20_architecture/adrs/0006-maintainer-tooling/#implementation-plan","title":"Implementation Plan","text":""},{"location":"20_architecture/adrs/0006-maintainer-tooling/#m851-cli-tooling","title":"M8.5.1: CLI Tooling","text":"<ol> <li>Extend <code>justfile</code> with maintainer recipes</li> <li>Document commands in <code>docs/60_ops/runbooks.md</code></li> <li>Add commands to deployment checklist</li> <li>Test on Tier 1 Balena device</li> </ol>"},{"location":"20_architecture/adrs/0006-maintainer-tooling/#m852-web-dashboard-optionalfuture","title":"M8.5.2: Web Dashboard (Optional/Future)","text":"<ol> <li>Prototype minimal Flask app</li> <li>Implement burn-in progress visualization</li> <li>Add log tailing web interface</li> <li>Security review (ensure local-only access)</li> </ol>"},{"location":"20_architecture/adrs/0006-maintainer-tooling/#references","title":"References","text":"<ul> <li>Deployment Checklist - Lists validation tasks</li> <li>ROADMAP.md - M8.5 milestone definition</li> <li>Runbooks - Operational procedures</li> <li>ADR-0002 - Decoupled UI architecture (end-user admin)</li> </ul>"},{"location":"20_architecture/adrs/0006-maintainer-tooling/#appendix-command-categories","title":"Appendix: Command Categories","text":""},{"location":"20_architecture/adrs/0006-maintainer-tooling/#validation-commands-pre-deployment","title":"Validation Commands (Pre-Deployment)","text":"<ul> <li><code>just burn-in-test</code> - Hardware thermal stability</li> <li><code>just validate-network</code> - Network resilience (offline buffering)</li> <li><code>just validate-gold-corpus</code> - STT accuracy (WER &lt; 5%)</li> <li><code>just validate-security</code> - TPM/encryption verification</li> </ul>"},{"location":"20_architecture/adrs/0006-maintainer-tooling/#diagnostic-commands-troubleshooting","title":"Diagnostic Commands (Troubleshooting)","text":"<ul> <li><code>just health-check</code> - All services + hardware status</li> <li><code>just gpu-info</code> - CUDA/cuDNN availability</li> <li><code>just disk-usage</code> - Storage utilization report</li> <li><code>just temp-monitor</code> - Real-time temperature logging</li> </ul>"},{"location":"20_architecture/adrs/0006-maintainer-tooling/#operational-commands-maintenance","title":"Operational Commands (Maintenance)","text":"<ul> <li><code>just logs-aggregate</code> - Combined service logs</li> <li><code>just backup-config</code> - Export settings/phraseSets</li> <li><code>just restore-config</code> - Import settings</li> <li><code>just reset-buffers</code> - Clear recovery buffers (troubleshooting)</li> </ul>"},{"location":"20_architecture/adrs/0007-platform-pivot-x86/","title":"ADR-0007: Platform Pivot to Industrial x86","text":"<p>Date: 2025-11-26 Status: ACCEPTED Context: The initial v6.x architecture relied on the NVIDIA Jetson Orin Nano (ARM64) to perform both transcription and biometric identification on the edge. However, during testing and review, several critical issues emerged: 1.  Resource Contention: Running STT and Biometrics simultaneously caused OOM (Out of Memory) kills. 2.  Filesystem Corruption: The Jetson lacks native Power Loss Protection (PLP), leading to corruption during power cuts. 3.  Complexity: Managing custom ARM builds and JetPack dependencies increased maintenance burden.</p> <p>Decision: We will pivot the hardware platform to the ASRock Industrial NUC BOX-N97 (Intel N97 x86).</p> <p>Rationale: 1.  Reliability: The NUC is fanless (0dB) and supports standard x86 Linux distributions (BalenaOS). 2.  PLP Support: The M.2 slot supports Industrial NVMe drives with hardware Power Loss Protection. 3.  Simplicity: Standard x86 Docker containers eliminate cross-compilation headaches. 4.  Cost: The NUC ($240) is significantly cheaper than the Jetson Orin Nano ($499).</p> <p>Consequences: -   Positive: \"Set and Forget\" reliability, lower cost, easier development. -   Negative: Loss of NVIDIA GPU requires migrating biometrics to OpenVINO (Intel iGPU). -   Mitigation: OpenVINO on Intel N97 is sufficient for the \"Split-Brain\" architecture where heavy STT is offloaded to the cloud.</p>"},{"location":"20_architecture/adrs/0008-split-brain-architecture/","title":"ADR-0008: Industrial Split-Brain Architecture","text":"<p>Date: 2025-11-26 Status: ACCEPTED Context: We need high-accuracy transcription (comparable to human captioning) AND low-latency speaker identification. -   Pure Edge (v6.x): Jetson STT models (Whisper-small) are not accurate enough for church sermons. -   Pure Cloud: Cloud diarization is good but cannot identify specific local speakers (e.g., \"Pastor John\") by name without training custom models, which is expensive and complex.</p> <p>Decision: Adopt a \"Split-Brain\" Architecture with a Hybrid Tagging Strategy.</p> <p>Details: 1.  Cloud Ear: Audio is streamed to Deepgram Nova-3 for high-accuracy text and segmentation (Speaker A, Speaker B). 2.  Edge Eye: Audio is locally processed by OpenVINO (WeSpeaker) to identify specific users (Speaker A = \"Alice\"). 3.  Hybrid Tagging: A local \"Identity Manager\" service correlates the two streams. It uses Deepgram's timestamps for when someone spoke and the local biometric result to tag the segment with the correct name.</p> <p>Consequences: -   Positive: Best of both worlds\u2014Cloud accuracy + Edge privacy/identity. -   Negative: Increased architectural complexity (synchronizing two streams). -   Mitigation: Use NATS messaging and a \"Time Zipper\" service to reliably merge the streams based on system uptime timestamps.</p>"},{"location":"20_architecture/adrs/0009-nats-migration/","title":"ADR-0009: Migration from ZeroMQ to NATS","text":"<p>Date: 2025-11-26 Status: ACCEPTED Supersedes: ADR-0001</p> <p>Context: The v6.x architecture used ZeroMQ (ZMQ) for inter-service communication. While fast, ZMQ presented challenges: 1.  No Persistence: If a service crashed, messages were lost unless complex application-level buffering was implemented. 2.  Opaque: Debugging ZMQ traffic required custom tools; there was no easy way to \"inspect\" the bus. 3.  Complexity: Implementing reliable pub/sub with reconnection logic in ZMQ is non-trivial.</p> <p>Decision: Migrate the messaging backbone to NATS (with JetStream).</p> <p>Rationale: 1.  Persistence: JetStream provides built-in message persistence, allowing services to \"catch up\" after a restart or network outage. 2.  Observability: NATS has excellent tooling (<code>nats-box</code>, <code>nats-surveyor</code>) for monitoring traffic and lag. 3.  Simplicity: The NATS client libraries handle reconnection and topology automatically. 4.  Ecosystem: NATS is a CNCF graduated project with broad language support.</p> <p>Consequences: -   Positive: drastically simplified application code (removed custom buffering logic), better debugging, \"Black Box\" recording capability. -   Negative: Introduces a new infrastructure dependency (NATS Server). -   Mitigation: NATS Server is a single static binary, extremely lightweight (&lt;20MB), and highly reliable, fitting well within the NUC's resources.</p>"},{"location":"20_architecture/adrs/0010-python-3-12-upgrade/","title":"10. Upgrade to Python 3.12","text":"<p>Date: 2025-11-28</p>"},{"location":"20_architecture/adrs/0010-python-3-12-upgrade/#status","title":"Status","text":"<p>Accepted</p>"},{"location":"20_architecture/adrs/0010-python-3-12-upgrade/#context","title":"Context","text":"<p>The project is pivoting from NVIDIA Jetson hardware (ARM64) to an Industrial x86 platform (Intel N97). This hardware change removes the constraints of NVIDIA JetPack, which would have locked the system to Python 3.10 until Nvidia released a new version of JetPack.</p> <p>We have an opportunity to modernize the technology stack. - Current State: Mixed Python versions (3.10 in root, 3.11 in <code>audio-producer</code>). - Drivers:     - Need for modern Python features and performance improvements.     - <code>audio-producer</code> already requires Python 3.11+.     - <code>deepgram-sdk</code> (a critical dependency) supports up to Python 3.12.     - Python 3.13 is still experimental for some key libraries (OpenVINO).</p>"},{"location":"20_architecture/adrs/0010-python-3-12-upgrade/#decision","title":"Decision","text":"<p>We will standardize the entire monorepo on Python 3.12.</p> <p>This version provides the best balance of: 1.  Modernity: Access to latest language features and performance improvements. 2.  Stability: Fully supported by all critical dependencies (<code>deepgram-sdk</code>, <code>nats-py</code>, <code>openvino</code>, <code>lancedb</code>). 3.  Longevity: Ensures a long support window before the next major upgrade is needed.</p>"},{"location":"20_architecture/adrs/0010-python-3-12-upgrade/#consequences","title":"Consequences","text":"<ol> <li>Root Configuration: The root <code>pyproject.toml</code> will be updated to require Python <code>&gt;=3.12</code>.</li> <li>Service Configuration: All service-level <code>pyproject.toml</code> files will be updated to target Python 3.12.</li> <li>Docker Images: All Dockerfiles will be updated to use <code>python:3.12-slim</code> (or equivalent) base images.</li> <li>CI/CD: CI pipelines must be updated to use Python 3.12 runners.</li> <li>Dev Environment: Developers will need to upgrade their local Python environment to 3.12.</li> </ol>"},{"location":"20_architecture/adrs/0011-retention-policy/","title":"ADR-0011: NATS JetStream Retention Policy","text":"<p>Date: 2025-12-06 Status: ACCEPTED</p> <p>Context: We are migrating to NATS JetStream for data persistence (\"Black Box\"). We need to define how long data is kept to balance disk usage on the NUC (256GB NVMe) against recovery capabilities.</p> <p>Decision: Set the following retention policies (MaxAge) for JetStream streams:</p> <ol> <li> <p>Audio Stream (<code>audio.raw</code>): 60 minutes</p> <ul> <li>Rationale: Raw audio (16kHz PCM) consumes ~115MB/hour. Keeping 24 hours would consume ~2.7GB. While the disk can handle this, the primary use case for \"catch up\" is short-term internet outages (minutes to hours). 60 minutes is sufficient for almost all outage scenarios.</li> <li>Configuration: <code>NATS_AUDIO_RETENTION</code> env var (Default: <code>3600s</code>).</li> </ul> </li> <li> <p>Transcript/Event Stream (<code>text.transcript</code>, <code>identity.event</code>): 7 days</p> <ul> <li>Rationale: JSON data is text-based and highly compressible. 7 days allows for weekly debugging and review of past events.</li> <li>Configuration: <code>NATS_TEXT_RETENTION</code> env var (Default: <code>604800s</code>).</li> </ul> </li> </ol> <p>Consequences: -   Positive: Efficient disk usage. Sufficient buffer for \"Split-Brain\" recovery (Cloud STT catching up). -   Negative: If an outage lasts longer than 1 hour, raw audio will be lost. -   Mitigation: The system is designed for real-time usage. Prolonged outages should trigger other alerts.</p>"},{"location":"30_data/biometric_policy/","title":"Biometric Data Policy (v7.3)","text":""},{"location":"30_data/biometric_policy/#1-overview","title":"1. Overview","text":"<p>This document defines policies for handling biometric data (voiceprints) in the Live STT system (v7.3), ensuring compliance with BIPA and GDPR.</p>"},{"location":"30_data/biometric_policy/#2-scope","title":"2. Scope","text":"<ul> <li>Voiceprints: 256-dimensional vectors (WeSpeaker ResNet34) stored in LanceDB.</li> <li>Enrollment Audio: Raw .wav files (encrypted) used for re-enrollment.</li> </ul>"},{"location":"30_data/biometric_policy/#3-data-storage","title":"3. Data Storage","text":""},{"location":"30_data/biometric_policy/#31-vector-storage-lancedb","title":"3.1 Vector Storage (LanceDB)","text":"<ul> <li>Location: <code>/data/lancedb</code></li> <li>Format: LanceDB Table (<code>voiceprints</code>)</li> <li>Encryption: Volume-level encryption (LUKS) on the physical disk.</li> </ul>"},{"location":"30_data/biometric_policy/#32-backup-strategy-black-box","title":"3.2 Backup Strategy (\"Black Box\")","text":"<ul> <li>Mechanism: LanceDB snapshots are periodically synced to the \"Black Box\" loopback filesystem (<code>/data/nats</code>).</li> <li>Purpose: Disaster recovery only.</li> </ul>"},{"location":"30_data/biometric_policy/#33-physical-security-tier-1-industrial-nuc","title":"3.3 Physical Security (Tier 1 - Industrial NUC)","text":"<ul> <li>Full Disk Encryption: LUKS enabled on BalenaOS.</li> <li>Secure Boot: Enabled in BIOS.</li> <li>TPM: Keys sealed to TPM 2.0 module.</li> </ul>"},{"location":"30_data/biometric_policy/#4-enrollment-process","title":"4. Enrollment Process","text":"<ol> <li>Consent: User must explicitly consent via UI checkbox.</li> <li>Recording: 15-second audio sample reading consent script.</li> <li>Processing:<ul> <li>Audio -&gt; WeSpeaker -&gt; Vector (256-float array).</li> <li>Vector -&gt; LanceDB.</li> <li>Audio -&gt; Encrypted Archive (AES-256).</li> </ul> </li> </ol>"},{"location":"30_data/biometric_policy/#5-data-retention-deletion","title":"5. Data Retention &amp; Deletion","text":""},{"location":"30_data/biometric_policy/#51-retention","title":"5.1 Retention","text":"<ul> <li>Voiceprints: Indefinite (until revocation).</li> <li>Transcripts: 30 days (rolling deletion).</li> </ul>"},{"location":"30_data/biometric_policy/#52-right-to-erasure","title":"5.2 Right to Erasure","text":"<ul> <li>Action: Admin clicks \"Delete\" in Dashboard.</li> <li>Technical:<ol> <li><code>DELETE FROM voiceprints WHERE id = 'Alice'</code></li> <li>Crypto-shredding of archived audio key.</li> <li>Vacuum LanceDB to remove vector data.</li> </ol> </li> </ul> <p>See Also: - Data Dictionary - Threat Model</p>"},{"location":"30_data/data_dictionary/","title":"Data Dictionary (v7.3)","text":""},{"location":"30_data/data_dictionary/#overview","title":"Overview","text":"<p>This document defines all data structures, message formats, database schemas, and file formats used in the Live STT system (v7.3 Industrial Split-Brain).</p>"},{"location":"30_data/data_dictionary/#1-nats-jetstream-subjects","title":"1. NATS JetStream Subjects","text":""},{"location":"30_data/data_dictionary/#11-audioraw","title":"1.1 <code>audio.raw</code>","text":"<p>Publisher: audio-producer Subscribers: stt-provider, identifier Format: Binary PCM Payload:</p> <pre><code>Bytes 0-1599: 16-bit signed PCM samples (800 samples \u00d7 2 bytes)\nSample Rate: 16kHz\nChannels: 1 (mono)\nChunk Duration: 50ms\n</code></pre>"},{"location":"30_data/data_dictionary/#12-texttranscript","title":"1.2 <code>text.transcript</code>","text":"<p>Publisher: stt-provider Subscribers: identity-manager Format: JSON Schema:</p> <pre><code>{\n  \"text\": \"string - Transcript text\",\n  \"confidence\": \"float - 0.0 to 1.0\",\n  \"speaker\": \"int - Deepgram speaker label (0, 1)\",\n  \"is_final\": \"bool\",\n  \"start\": \"float - Audio timestamp (seconds)\",\n  \"end\": \"float - Audio timestamp (seconds)\",\n  \"trace_id\": \"string - UUID for correlation\"\n}\n</code></pre>"},{"location":"30_data/data_dictionary/#13-identityevent","title":"1.3 <code>identity.event</code>","text":"<p>Publisher: identifier Subscribers: identity-manager Format: JSON Schema:</p> <pre><code>{\n  \"user_id\": \"string - Enrolled name (e.g., 'Alice')\",\n  \"confidence\": \"float - 0.0 to 1.0\",\n  \"start\": \"float - Audio timestamp (seconds)\",\n  \"end\": \"float - Audio timestamp (seconds)\",\n  \"trace_id\": \"string\"\n}\n</code></pre>"},{"location":"30_data/data_dictionary/#14-eventsmerged","title":"1.4 <code>events.merged</code>","text":"<p>Publisher: identity-manager Subscribers: api-gateway Format: JSON Schema:</p> <pre><code>{\n  \"text\": \"string - Transcript text\",\n  \"user\": \"string - Resolved name (e.g., 'Alice')\",\n  \"is_final\": \"bool\"\n}\n</code></pre>"},{"location":"30_data/data_dictionary/#2-lancedb-biometrics","title":"2. LanceDB (Biometrics)","text":"<p>Location: <code>/data/lancedb</code> Table: <code>voiceprints</code></p> Column Type Description <code>id</code> String Speaker Name (Primary Key) <code>vector</code> Vector(256) WeSpeaker ResNet34 embedding <code>enrolled_at</code> Timestamp Enrollment date <code>version</code> Int Schema version"},{"location":"30_data/data_dictionary/#3-sqlite-database-dataconfigdb","title":"3. SQLite Database (<code>/data/config.db</code>)","text":""},{"location":"30_data/data_dictionary/#31-table-phrase_set","title":"3.1 Table: <code>phrase_set</code>","text":"<p>Purpose: Custom vocabulary for Deepgram API Owner: api-gateway (write), stt-provider (read)</p> Column Type Description <code>id</code> INTEGER PK Unique ID <code>phrase</code> TEXT Phrase text <code>boost</code> INTEGER Weight (1-10)"},{"location":"30_data/data_dictionary/#4-black-box-storage","title":"4. \"Black Box\" Storage","text":"<p>Location: <code>/data/nats</code> (Loopback Mount) Format: NATS JetStream File Store Retention: - <code>audio.raw</code>: 60 Minutes (Configurable via <code>NATS_AUDIO_RETENTION</code>) - <code>text.transcript</code>: 7 Days (Configurable via <code>NATS_TEXT_RETENTION</code>) - <code>events.merged</code>: 30 Days</p> <p>See Also: - Biometric Policy - HSI</p>"},{"location":"30_data/erd/","title":"Entity-Relationship Diagram (ERD)","text":""},{"location":"30_data/erd/#overview","title":"Overview","text":"<p>This document visualizes the data model for the Live STT system, showing relationships between configuration, quality assurance, and biometric enrollment data.</p>"},{"location":"30_data/erd/#erd","title":"ERD","text":"<pre><code>erDiagram\n    PHRASE_SET ||--o{ TRANSCRIPT_EVENT : \"boosts\"\n    QUALITY_LOG ||--|| ENCRYPTED_SNIPPET : \"references\"\n    VOICEPRINT_ENROLLMENT ||--|| ENCRYPTED_VOICEPRINT : \"references\"\n    VOICEPRINT_ENROLLMENT ||--o{ IDENTITY_EVENT : \"identified_by\"\n    PERFORMANCE_LOG }o--|| SERVICE : \"logs_for\"\n\n    PHRASE_SET {\n        int id PK\n        string phrase UK\n        int boost \"1-10\"\n        timestamp created_at\n        string created_by\n    }\n\n    QUALITY_LOG {\n        int id PK\n        string snippet_id UK \"UUID\"\n        float confidence \"0.0-1.0\"\n        string text\n        int duration_ms\n        string file_path UK\n        blob encryption_key \"AES-256\"\n        timestamp created_at\n        bool reviewed\n    }\n\n    ENCRYPTED_SNIPPET {\n        string file_path PK \"/data/review/{uuid}.enc\"\n        blob nonce \"12 bytes\"\n        blob gcm_tag \"16 bytes\"\n        blob ciphertext\n    }\n\n    VOICEPRINT_ENROLLMENT {\n        string speaker_id PK \"e.g., 'Tom'\"\n        string file_path FK\n        blob encryption_key\n        blob embedding \"512D vector\"\n        timestamp enrolled_at\n        bool consented \"BIPA\"\n    }\n\n    ENCRYPTED_VOICEPRINT {\n        string file_path PK \"/data/enrollment/{speaker}.wav.enc\"\n        blob nonce\n        blob gcm_tag\n        blob ciphertext\n    }\n\n    IDENTITY_EVENT {\n        int event_id PK\n        string speaker_id FK\n        float confidence\n        timestamp timestamp_ms\n        int duration_ms\n    }\n\n    TRANSCRIPT_EVENT {\n        int event_id PK\n        string text\n        float confidence\n        int speaker \"Deepgram label\"\n        bool is_final\n        timestamp timestamp_ms\n    }\n\n    PERFORMANCE_LOG {\n        int id PK\n        string service FK\n        string metric\n        float value\n        timestamp timestamp\n    }\n\n    SERVICE {\n        string name PK\n        string status \"ok|degraded|down\"\n        timestamp last_ping\n    }\n</code></pre>"},{"location":"30_data/erd/#key-relationships","title":"Key Relationships","text":""},{"location":"30_data/erd/#1-phrase_set-transcript_event","title":"1. <code>PHRASE_SET</code> \u2192 <code>TRANSCRIPT_EVENT</code>","text":"<ul> <li>Type: One-to-Many (indirect)</li> <li>Description: Custom phrases in <code>phrase_set</code> are passed to Deepgram API, boosting their likelihood in transcripts</li> <li>Enforcement: Application logic in <code>stt-provider</code> (no foreign key)</li> </ul>"},{"location":"30_data/erd/#2-quality_log-encrypted_snippet","title":"2. <code>QUALITY_LOG</code> \u2192 <code>ENCRYPTED_SNIPPET</code>","text":"<ul> <li>Type: One-to-One</li> <li>Description: Each low-confidence snippet has metadata in <code>quality_log</code> and encrypted audio in filesystem</li> <li>Key: <code>quality_log.file_path</code> references physical file path</li> <li>Orphan Prevention: Admin deletes snippet \u2192 <code>quality_log</code> row deleted \u2192 file deleted \u2192 encryption key crypto-shredded</li> <li>Lookup: API uses <code>snippet_id</code> (UUID) for external references (e.g., <code>/admin/snippet/{snippet_id}</code>)</li> </ul>"},{"location":"30_data/erd/#3-voiceprint_enrollment-encrypted_voiceprint","title":"3. <code>VOICEPRINT_ENROLLMENT</code> \u2192 <code>ENCRYPTED_VOICEPRINT</code>","text":"<ul> <li>Type: One-to-One</li> <li>Description: Each enrolled speaker has metadata in <code>voiceprint_enrollment</code> and encrypted voiceprint in filesystem</li> <li>Key: <code>voiceprint_enrollment.file_path</code> references physical file path</li> <li>Crypto-shredding: Delete <code>voiceprint_enrollment.encryption_key</code> \u2192 file becomes permanently unrecoverable</li> </ul>"},{"location":"30_data/erd/#4-voiceprint_enrollment-identity_event","title":"4. <code>VOICEPRINT_ENROLLMENT</code> \u2192 <code>IDENTITY_EVENT</code>","text":"<ul> <li>Type: One-to-Many</li> <li>Description: Each voiceprint can match multiple identity events (every time speaker is detected)</li> <li>Key: <code>identity_event.speaker_id</code> references <code>voiceprint_enrollment.speaker_id</code></li> <li>Enforcement: Foreign key constraint in SQLite</li> </ul>"},{"location":"30_data/erd/#5-performance_log-service","title":"5. <code>PERFORMANCE_LOG</code> \u2192 <code>SERVICE</code>","text":"<ul> <li>Type: Many-to-One</li> <li>Description: Each service has many performance metrics logged over time</li> <li>Key: <code>performance_log.service</code> references <code>service.name</code></li> <li>Retention: Logs older than 30 days automatically deleted (for disk space)</li> </ul>"},{"location":"30_data/erd/#data-lifecycle","title":"Data Lifecycle","text":""},{"location":"30_data/erd/#transcript-event","title":"Transcript Event","text":"<pre><code>flowchart LR\n    A[Deepgram API] --&gt;|JSON| B[stt-provider]\n    B --&gt;|ZMQ pub| C[broker]\n    C --&gt;|ZMQ sub| D[api-gateway]\n    D --&gt;|WebSocket| E[Client Browser]\n\n    B --&gt;|If confidence &lt; 0.85| F[quality_log + encrypted snippet]\n    F --&gt;|Admin reviews| G[Corrected or Deleted]\n</code></pre>"},{"location":"30_data/erd/#voiceprint-enrollment","title":"Voiceprint Enrollment","text":"<pre><code>flowchart LR\n    A[Admin uploads WAV] --&gt;|POST /admin/enrollment| B[api-gateway]\n    B --&gt;|Encrypt with file key| C[/data/enrollment/*.enc]\n    B --&gt;|Store metadata| D[voiceprint_enrollment table]\n    D --&gt;|Embedding extracted| E[identifier service]\n    E --&gt;|Publishes identity.event| F[broker]\n</code></pre>"},{"location":"30_data/erd/#crypto-shredding-gdpr-right-to-erasure","title":"Crypto-Shredding (GDPR Right to Erasure)","text":"<pre><code>flowchart LR\n    A[Admin clicks Delete] --&gt;|DELETE /admin/voiceprint/{id}| B[api-gateway]\n    B --&gt;|DELETE encryption_key| C[voiceprint_enrollment table]\n    C --&gt;|File still exists but...| D[Encrypted voiceprint]\n    D -.-&gt;|Cannot decrypt without key| E[Data irretrievable]\n</code></pre>"},{"location":"30_data/erd/#indexing-strategy","title":"Indexing Strategy","text":"Table Index Columns Purpose <code>phrase_set</code> <code>idx_phrase</code> <code>phrase</code> Fast lookup for autocomplete in admin UI <code>quality_log</code> <code>idx_confidence</code> <code>confidence</code> Filter snippets by confidence range <code>quality_log</code> <code>idx_created_at</code> <code>created_at DESC</code> Sort snippets chronologically <code>performance_log</code> <code>idx_service_timestamp</code> <code>(service, timestamp)</code> Time-series queries for dashboards <code>voiceprint_enrollment</code> Primary Key <code>speaker_id</code> Enforce unique speaker names"},{"location":"30_data/erd/#data-retention-policy","title":"Data Retention Policy","text":"Data Type Retention Period Rationale Transcripts (in-memory) Session only Not persisted (privacy by design) Low-confidence snippets Until admin review Deleted after correction or approval Voiceprints Until speaker requests deletion BIPA compliance (consent-based) Performance logs 30 days Disk space constraints on Jetson Phrase set Indefinite Static configuration data <p>See Also: - Data Dictionary - Schema details - Biometric Policy - Voiceprint handling procedures - Threat Model - Crypto-shredding implementation</p>"},{"location":"40_hardware/assembly_guide/","title":"Assembly Guide (v7.3)","text":""},{"location":"40_hardware/assembly_guide/#tools-required","title":"Tools Required","text":"<ul> <li>Phillips #1 Screwdriver</li> <li>USB Keyboard &amp; HDMI Monitor (for initial BIOS setup)</li> <li>USB Flash Drive (for BalenaOS installation)</li> </ul>"},{"location":"40_hardware/assembly_guide/#1-hardware-assembly","title":"1. Hardware Assembly","text":""},{"location":"40_hardware/assembly_guide/#11-install-memory-storage","title":"1.1 Install Memory &amp; Storage","text":"<ol> <li>Unscrew the 4 bottom screws of the ASRock NUC BOX-N97.</li> <li>Lift the bottom cover carefully.</li> <li>RAM: Insert the Crucial 16GB SODIMM into the slot at a 45-degree angle and press down until it clicks.</li> <li>NVMe: Insert the Transcend MTE712A into the M.2 Key M slot and secure with the provided screw.</li> <li>Close the case and secure the 4 bottom screws.</li> </ol>"},{"location":"40_hardware/assembly_guide/#12-connect-peripherals","title":"1.2 Connect Peripherals","text":"<ol> <li>Connect Focusrite Scarlett Solo to a USB 3.2 port using the shielded USB-C cable.</li> <li>Connect Ethernet cable to the LAN1 port (2.5GbE).</li> <li>Connect Power Adapter.</li> </ol>"},{"location":"40_hardware/assembly_guide/#2-bios-configuration","title":"2. BIOS Configuration","text":"<p>Critical for \"Set and Forget\" reliability.</p> <ol> <li>Power on and press F2 or Del to enter BIOS.</li> <li>Power Management:<ul> <li>Navigate to <code>Advanced</code> &gt; <code>ACPI Configuration</code>.</li> <li>Set <code>Restore on AC/Power Loss</code> to Power On. (Ensures auto-boot after outage).</li> </ul> </li> <li>Watchdog:<ul> <li>Navigate to <code>Advanced</code> &gt; <code>Super IO Configuration</code>.</li> <li>Set <code>Watchdog Timer</code> to Enabled.</li> <li>Set <code>Timeout</code> to 60 seconds.</li> </ul> </li> <li>Boot:<ul> <li>Set <code>Boot Option #1</code> to USB (for initial install).</li> </ul> </li> <li>Save and Exit (F10).</li> </ol>"},{"location":"40_hardware/assembly_guide/#3-audio-interface-setup","title":"3. Audio Interface Setup","text":""},{"location":"40_hardware/assembly_guide/#31-focusrite-firmware","title":"3.1 Focusrite Firmware","text":"<p>[!IMPORTANT] The Focusrite Scarlett Solo must be in Class Compliant Mode to work driverless with Linux.</p> <ol> <li>(One-time) Connect to a Windows/Mac computer.</li> <li>Install Focusrite Control 2.</li> <li>Update Firmware if prompted.</li> <li>Ensure \"MSD Mode\" (Mass Storage Device) is OFF. (Hold the \"Air\" button for 5s while plugging in if it mounts as a drive).</li> </ol>"},{"location":"40_hardware/assembly_guide/#32-hardware-settings","title":"3.2 Hardware Settings","text":"<ul> <li>Gain Knob: Set to ~12 o'clock (50%).</li> <li>Inst/Air: Ensure \"Inst\" is OFF (Line level) and \"Air\" is OFF (Flat EQ).</li> <li>Direct Monitor: Set to OFF (Prevents audio loopback).</li> <li>48V Phantom Power: OFF (Unless using a condenser mic requiring it).</li> </ul>"},{"location":"40_hardware/assembly_guide/#4-software-installation","title":"4. Software Installation","text":"<p>See Quickstart for BalenaOS flashing instructions.</p>"},{"location":"40_hardware/environmental_constraints/","title":"Environmental Constraints (v7.3)","text":""},{"location":"40_hardware/environmental_constraints/#overview","title":"Overview","text":"<p>This document defines the operating environment requirements and constraints for the Live STT system (v7.3 Industrial Split-Brain).</p>"},{"location":"40_hardware/environmental_constraints/#1-physical-environment","title":"1. Physical Environment","text":""},{"location":"40_hardware/environmental_constraints/#temperature","title":"Temperature","text":"Tier Operating Range Storage Range Notes Tier 1 (NUC N97) 0\u00b0C to 40\u00b0C -20\u00b0C to 60\u00b0C Passive Cooling: Requires airflow (do not enclose in airtight box) Tier 2 (Desktop) 10\u00b0C to 35\u00b0C -20\u00b0C to 60\u00b0C Standard desktop PC range <p>Church Sanctuary Typical: 18-24\u00b0C (65-75\u00b0F)</p>"},{"location":"40_hardware/environmental_constraints/#humidity","title":"Humidity","text":"<ul> <li>Operating: 20% to 80% RH (non-condensing)</li> <li>Storage: 5% to 95% RH (non-condensing)</li> </ul>"},{"location":"40_hardware/environmental_constraints/#noise","title":"Noise","text":"<ul> <li>Requirement: 0dB (Silent)</li> <li>Implementation: Fanless Chassis (ASRock NUC BOX-N97)</li> <li>Constraint: No moving parts allowed (no HDD, no fans).</li> </ul>"},{"location":"40_hardware/environmental_constraints/#2-power-requirements","title":"2. Power Requirements","text":""},{"location":"40_hardware/environmental_constraints/#tier-1-asrock-nuc-n97","title":"Tier 1 (ASRock NUC N97)","text":"Parameter Specification Notes Input Voltage 12V-19V DC 12V/3A Adapter included Peak Power 25W During boot / heavy inference Idle Power 6W Silent periods Typical Power 10W Continuous transcription + ID <p>Power Conditioning: - PLP Protection: Transcend MTE712A NVMe handles sudden power loss. - UPS Optional: Recommended for graceful shutdown, but not strictly required for data integrity due to PLP + Journaling.</p>"},{"location":"40_hardware/environmental_constraints/#3-network-requirements","title":"3. Network Requirements","text":""},{"location":"40_hardware/environmental_constraints/#bandwidth","title":"Bandwidth","text":"Direction Min Recommended Purpose Upload 300 kbps 500 kbps Audio stream to Deepgram (Linear16 PCM) Download 10 kbps 50 kbps Transcript JSON from Deepgram WebSocket Clients 5 kbps/client 10 kbps/client Broadcast transcripts to 30 clients"},{"location":"40_hardware/environmental_constraints/#latency","title":"Latency","text":"<ul> <li>Target: &lt; 500ms (Text), &lt; 100ms (Identity)</li> <li>Deepgram Nova-3: ~300ms processing time</li> </ul>"},{"location":"40_hardware/environmental_constraints/#firewall-requirements","title":"Firewall Requirements","text":"Protocol Direction Port Destination Purpose WSS Outbound 443 api.deepgram.com STT streaming HTTPS Outbound 443 balena-cloud.com Fleet management"},{"location":"40_hardware/environmental_constraints/#4-acoustic-environment","title":"4. Acoustic Environment","text":""},{"location":"40_hardware/environmental_constraints/#microphone-placement","title":"Microphone Placement","text":"<ul> <li>Distance: 1-3 meters (3-10 feet)</li> <li>Mounting: Shock mount recommended to avoid podium vibrations.</li> </ul>"},{"location":"40_hardware/environmental_constraints/#background-noise","title":"Background Noise","text":"<ul> <li>Limit: &lt; 50dB SPL for optimal accuracy.</li> <li>Music Handling: <code>audio-classifier</code> (roadmap) or manual pause recommended during worship music.</li> </ul>"},{"location":"40_hardware/environmental_constraints/#audio-chain","title":"Audio Chain","text":"<ul> <li>Source: Focusrite Scarlett Solo (Line Level)</li> <li>Sample Rate: 48kHz (Hardware Native) \u2192 Resampled to 16kHz (Software)</li> <li>Bit Depth: 24-bit (Hardware) \u2192 16-bit (Software)</li> </ul>"},{"location":"40_hardware/environmental_constraints/#5-maintenance","title":"5. Maintenance","text":""},{"location":"40_hardware/environmental_constraints/#tier-1-nuc","title":"Tier 1 (NUC)","text":"Task Frequency Procedure Dust Cleaning Annually Compressed air (heatsink fins) NVMe Health Monthly Automated SMART check Reboot Weekly Automated via Balena (Sunday 3AM) <p>See Also: - HBOM - Component specifications - Assembly Guide - Setup instructions</p>"},{"location":"40_hardware/fru_guide/","title":"Field Replacement Unit (FRU) Guide","text":""},{"location":"40_hardware/fru_guide/#replacing-the-camera-module","title":"Replacing the Camera Module","text":""},{"location":"40_hardware/fru_guide/#symptoms","title":"Symptoms","text":"<ul> <li>No video feed</li> <li>Purple tint</li> </ul>"},{"location":"40_hardware/fru_guide/#procedure","title":"Procedure","text":"<ol> <li>Power down device.</li> <li>Remove 4 case screws.</li> <li>Disconnect ribbon cable.</li> </ol>"},{"location":"40_hardware/hbom/","title":"Hardware Bill of Materials (HBOM)","text":""},{"location":"40_hardware/hbom/#overview","title":"Overview","text":"<p>This document specifies the hardware components required for the v7.3 \"Industrial Split-Brain\" architecture.</p> <p>[!NOTE] All component models listed are illustrative examples to demonstrate viable options. They are not prescriptive recommendations or endorsements. Use equivalent components that meet the specified requirements (power, connectivity, performance).</p>"},{"location":"40_hardware/hbom/#tier-1-production-industrial-x86","title":"Tier 1: Production (Industrial x86)","text":""},{"location":"40_hardware/hbom/#core-components","title":"Core Components","text":"Component Model Quantity Price (USD) Purpose Compute ASRock Industrial NUC BOX-N97 1 $240 Main compute (Fanless, Intel N97) Memory Crucial 16GB DDR4-3200 SODIMM 1 $35 RAM (Single stick) Storage Transcend MTE712A 256GB NVMe 1 $65 OS + \"Black Box\" (PLP protected) Audio Interface Focusrite Scarlett Solo 4th Gen 1 $140 Low-noise preamp (-127dB EIN) Cabling USB-C to USB-C (Shielded) 1 $15 Audio interface connection"},{"location":"40_hardware/hbom/#optional-components","title":"Optional Components","text":"Component Model Quantity Price (USD) Purpose UPS APC Back-UPS 425VA 1 $55 Power conditioning (optional with PLP) <p>Total Cost (Tier 1): ~$495 (Hardware only)</p>"},{"location":"40_hardware/hbom/#tier-2-desktop-development-x86_64","title":"Tier 2: Desktop Development (x86_64)","text":""},{"location":"40_hardware/hbom/#core-components_1","title":"Core Components","text":"Component Model Quantity Price (USD) Purpose Audio Interface Same as Tier 1 1 $140 USB audio input <p>Notes: - Uses developer's existing desktop/laptop - Can run full stack (OpenVINO runs on CPU if no iGPU)</p> <p>Total Cost (Tier 2): ~$140 (Audio gear only)</p>"},{"location":"40_hardware/hbom/#tier-3-cicd-cpu-only-development","title":"Tier 3: CI/CD &amp; CPU-Only Development","text":""},{"location":"40_hardware/hbom/#core-components_2","title":"Core Components","text":"Component Model Quantity Price (USD) Purpose Audio Interface Mock audio files (no hardware) 0 $0 Testing with pre-recorded sermons <p>Notes: - Runs on GitHub Actions runners or developer laptops - <code>identifier</code> service runs in CPU mode (slower but functional)</p> <p>Total Cost (Tier 3): $0</p>"},{"location":"40_hardware/hbom/#part-selection-rationale","title":"Part Selection Rationale","text":""},{"location":"40_hardware/hbom/#why-asrock-nuc-box-n97","title":"Why ASRock NUC BOX-N97?","text":"<ul> <li>Reliability: Fanless design (no moving parts to fail)</li> <li>Silence: 0dB operation (critical for church sanctuary)</li> <li>Performance: Intel N97 (4C/4T) sufficient for OpenVINO inference</li> <li>Watchdog: Built-in hardware watchdog timer (ITE IT8xxx)</li> <li>Cost: $240 (vs $499 for Jetson)</li> </ul>"},{"location":"40_hardware/hbom/#why-transcend-mte712a","title":"Why Transcend MTE712A?","text":"<ul> <li>PLP: Power Loss Protection capacitors prevent data corruption</li> <li>Endurance: Industrial grade NAND</li> <li>Reliability: Essential for \"Black Box\" filesystem integrity</li> </ul>"},{"location":"40_hardware/hbom/#why-focusrite-scarlett-solo","title":"Why Focusrite Scarlett Solo?","text":"<ul> <li>Noise Floor: -127dB EIN (vs -90dB for cheap USB mics)</li> <li>Quality: \"Clean Lab\" quality audio improves biometric accuracy</li> <li>Driverless: Class-compliant USB audio (works with Linux/PipeWire)</li> </ul>"},{"location":"40_hardware/hbom/#supply-chain-availability","title":"Supply Chain &amp; Availability","text":"Component Lead Time Availability Alternative ASRock NUC N97 1-2 weeks Newegg/Amazon ASUS PN42 (N100) Transcend NVMe In stock Mouser/DigiKey Innodisk 3TE7 Focusrite Solo In stock Music retailers Motu M2"},{"location":"40_hardware/hbom/#environmental-impact","title":"Environmental Impact","text":"Component Power (Watts) Annual kWh Annual Cost (@$0.12/kWh) NUC N97 10W avg 88 kWh $10.50 NVMe SSD 2W avg 18 kWh $2.15 Audio Interface 2.5W avg 22 kWh $2.60 Total (24/7) 14.5W 128 kWh $15.36/year <p>Comparison: A typical desktop PC (150W) costs ~$158/year to run 24/7.</p> <p>See Also: - Environmental Constraints - Operating conditions - Architecture Definition - Multi-tier strategy - ADR-0007 - Platform rationale</p>"},{"location":"50_qa/master_test_plan/","title":"Master Test Plan","text":""},{"location":"50_qa/master_test_plan/#1-introduction","title":"1. Introduction","text":"<p>This document outlines the testing strategy for the Live STT system, covering unit, integration, and end-to-end testing across all hardware tiers.</p>"},{"location":"50_qa/master_test_plan/#2-test-scope","title":"2. Test Scope","text":""},{"location":"50_qa/master_test_plan/#in-scope","title":"In Scope","text":"<ul> <li>Core Services: audio-producer, broker, stt-provider, api-gateway</li> <li>ML Services: audio-classifier, identifier (Tier 1/2 only)</li> <li>Hardware Tiers: Jetson Orin Nano (Tier 1), Desktop (Tier 2), CI (Tier 3)</li> <li>Resilience: Network outages, power loss, service crashes</li> </ul>"},{"location":"50_qa/master_test_plan/#out-of-scope","title":"Out of Scope","text":"<ul> <li>Deepgram API Internal Accuracy: We assume Deepgram works as advertised</li> <li>BalenaOS Internals: We assume the OS is stable</li> <li>Hardware Durability: Physical drop testing, water resistance</li> </ul>"},{"location":"50_qa/master_test_plan/#3-data-strategy-v62","title":"3. Data Strategy (v6.2)","text":""},{"location":"50_qa/master_test_plan/#31-silver-standard-phrase-mining","title":"3.1 Silver Standard (Phrase Mining)","text":"<ul> <li>Source: YouTube Auto-Captions (~20 hours of church services)</li> <li>Purpose: Extract high-frequency proper nouns for <code>initial_phrases.json</code></li> <li>Tool: <code>scripts/mine_phrases.py</code></li> <li>Output: PhraseSet seed file (staff names, liturgical terms, locations)</li> <li>Constraint: Never used for WER calculation (AI-generated, contains inherent errors)</li> </ul>"},{"location":"50_qa/master_test_plan/#32-gold-standard-regression-testing","title":"3.2 Gold Standard (Regression Testing)","text":"<ul> <li>Source: Manually corrected transcripts (Human-in-the-Loop)</li> <li>Volume: ~1 hour (20 \u00d7 3-minute clips)</li> <li>Composition: Stratified sampling</li> <li>30% Sermon (main teaching content)</li> <li>30% Liturgy (responsive readings, prayers)</li> <li>20% Announcements (community updates)</li> <li>20% Transitions (worship team, scene changes)</li> <li>Purpose: CI regression testing</li> <li>Pass Criteria: Word Error Rate (WER) &lt; 5%</li> <li>Location: <code>tests/data/gold_standard/</code></li> </ul> <p>Workflow: 1. Download service recordings 2. Extract representative clips using ffmpeg 3. Use Subtitle Edit for manual transcript correction 4. Commit <code>.wav</code> + <code>.txt</code> pairs to Git 5. CI pipeline runs Gold clips through <code>stt-provider</code> and calculates WER</p>"},{"location":"50_qa/master_test_plan/#4-testing-levels","title":"4. Testing Levels","text":""},{"location":"50_qa/master_test_plan/#31-unit-testing-tier-3","title":"3.1 Unit Testing (Tier 3)","text":"<ul> <li>Focus: Individual functions and classes</li> <li>Tools: <code>pytest</code>, <code>pytest-mock</code></li> <li>Coverage Target: 80% line coverage</li> <li>Execution: CI pipeline (every commit)</li> </ul> <p>Key Areas: - Audio chunking logic - ZMQ message serialization - Database CRUD operations - Configuration parsing</p>"},{"location":"50_qa/master_test_plan/#32-integration-testing-tier-3","title":"3.2 Integration Testing (Tier 3)","text":"<ul> <li>Focus: Service-to-service communication</li> <li>Tools: <code>docker compose</code>, <code>pytest</code> integration suite</li> <li>Execution: CI pipeline (every PR)</li> </ul> <p>Key Scenarios: - Audio producer \u2192 Broker \u2192 STT Provider flow - WebSocket client connection &amp; subscription - Database persistence of transcripts - Error handling (e.g., Deepgram API timeout)</p>"},{"location":"50_qa/master_test_plan/#33-end-to-end-e2e-testing-tier-12","title":"3.3 End-to-End (E2E) Testing (Tier 1/2)","text":"<ul> <li>Focus: Full system validation with real hardware</li> <li>Tools: Manual verification, automated load scripts</li> <li>Execution: Before release</li> </ul> <p>Key Scenarios: - Full Session: 60-minute continuous transcription - Outage Recovery: Disconnect internet for 5 mins, verify catch-up - Voiceprint: Enroll speaker, verify identification in live stream - Performance: Verify &lt;500ms latency under load</p>"},{"location":"50_qa/master_test_plan/#4-test-environment","title":"4. Test Environment","text":"Environment Hardware Purpose Data Local Dev Tier 2/3 Unit/Integration tests Mock audio files CI Runner Tier 3 Automated regression Synthetic data Staging Tier 1 E2E / Acceptance testing Real microphone input Production Tier 1 Live monitoring Real service audio"},{"location":"50_qa/master_test_plan/#5-test-data-strategy","title":"5. Test Data Strategy","text":""},{"location":"50_qa/master_test_plan/#mock-audio","title":"Mock Audio","text":"<ul> <li>Source: <code>test_fixtures/audio/sermon_sample.wav</code> (16kHz mono)</li> <li>Usage: Injected by <code>audio-producer</code> when <code>MOCK_FILE</code> env var is set</li> <li>Content: 5 minutes of clear speech with known transcript</li> </ul>"},{"location":"50_qa/master_test_plan/#voiceprints","title":"Voiceprints","text":"<ul> <li>Test Set: 5 distinct speakers (male/female, various accents)</li> <li>Enrollment: Scripted consent reading (15s)</li> <li>Validation: Cross-validation matrix (verify no false positives)</li> </ul>"},{"location":"50_qa/master_test_plan/#6-automated-test-suite","title":"6. Automated Test Suite","text":""},{"location":"50_qa/master_test_plan/#structure","title":"Structure","text":"<pre><code>tests/\n\u251c\u2500\u2500 unit/\n\u2502   \u251c\u2500\u2500 test_audio_producer.py\n\u2502   \u251c\u2500\u2500 test_stt_provider.py\n\u2502   \u2514\u2500\u2500 ...\n\u251c\u2500\u2500 integration/\n\u2502   \u251c\u2500\u2500 test_zmq_flow.py\n\u2502   \u251c\u2500\u2500 test_database.py\n\u2502   \u2514\u2500\u2500 ...\n\u251c\u2500\u2500 e2e/\n\u2502   \u251c\u2500\u2500 test_latency.py\n\u2502   \u2514\u2500\u2500 ...\n\u2514\u2500\u2500 fixtures/\n    \u2514\u2500\u2500 sermon_sample.wav\n</code></pre>"},{"location":"50_qa/master_test_plan/#running-tests","title":"Running Tests","text":"<pre><code># Run all unit tests\njust test\n\n# Run integration tests (requires Docker)\njust test-integration\n\n# Run specific test\npytest tests/unit/test_audio_producer.py\n</code></pre>"},{"location":"50_qa/master_test_plan/#7-manual-test-cases","title":"7. Manual Test Cases","text":""},{"location":"50_qa/master_test_plan/#tc-001-cold-boot-to-live","title":"TC-001: Cold Boot to Live","text":"<ol> <li>Power on device</li> <li>Wait 60 seconds</li> <li>Speak into microphone</li> <li>Expected: Transcript appears on Web UI within 2 seconds</li> </ol>"},{"location":"50_qa/master_test_plan/#tc-002-internet-recovery","title":"TC-002: Internet Recovery","text":"<ol> <li>Start transcription</li> <li>Unplug Ethernet/WAN</li> <li>Continue speaking for 2 minutes</li> <li>Reconnect Ethernet</li> <li>Expected: Buffered transcripts appear within 30 seconds, ordered correctly</li> </ol>"},{"location":"50_qa/master_test_plan/#tc-003-speaker-identification","title":"TC-003: Speaker Identification","text":"<ol> <li>Enroll \"Pastor Mike\"</li> <li>Have \"Pastor Mike\" speak</li> <li>Expected: Transcript labeled \"Pastor Mike\"</li> <li>Have unknown person speak</li> <li>Expected: Transcript labeled \"Speaker 0\"</li> </ol>"},{"location":"50_qa/master_test_plan/#8-defect-management","title":"8. Defect Management","text":""},{"location":"50_qa/master_test_plan/#severity-levels","title":"Severity Levels","text":"<ul> <li>Critical: System crash, data loss, no transcription</li> <li>High: High latency (&gt;2s), speaker ID failure, API key leak</li> <li>Medium: UI glitch, minor transcript formatting issue</li> <li>Low: Typo in logs, documentation error</li> </ul>"},{"location":"50_qa/master_test_plan/#reporting","title":"Reporting","text":"<ul> <li>Tool: GitHub Issues</li> <li>Required Info: Logs, steps to reproduce, hardware tier</li> </ul>"},{"location":"50_qa/master_test_plan/#9-release-criteria","title":"9. Release Criteria","text":"<ul> <li>[ ] All unit tests pass (100%)</li> <li>[ ] Integration tests pass (100%)</li> <li>[ ] Code coverage &gt; 80%</li> <li>[ ] Gold Standard regression test: WER &lt; 5%</li> <li>[ ] No critical/high open defects</li> <li>[ ] Successful 1-hour stability run on Tier 1 hardware</li> <li>[ ] Security scan (Bandit/Safety) clean</li> </ul> <p>See Also: - Performance Benchmarks - Latency/throughput targets - CI/CD - Automation pipeline</p>"},{"location":"50_qa/penetration_test_report/","title":"Penetration Test Report","text":"<p>Date: Tester:</p>"},{"location":"50_qa/penetration_test_report/#executive-summary","title":"Executive Summary","text":"<p>Summary of findings...</p>"},{"location":"50_qa/penetration_test_report/#findings","title":"Findings","text":"ID Severity Vulnerability Remediation Status VULN-001 High Kiosk Escape Disable hotkeys Open"},{"location":"50_qa/performance_benchmarks/","title":"Performance Benchmarks","text":""},{"location":"50_qa/performance_benchmarks/#1-overview","title":"1. Overview","text":"<p>This document defines the performance targets (SLAs) and benchmarking methodology for the Live STT system.</p>"},{"location":"50_qa/performance_benchmarks/#2-key-performance-indicators-kpis","title":"2. Key Performance Indicators (KPIs)","text":""},{"location":"50_qa/performance_benchmarks/#21-latency","title":"2.1 Latency","text":"<p>Definition: Time from sound wave hitting microphone to text appearing on Web UI.</p> Metric Target Max Acceptable Measurement Method Glass-to-Glass Latency &lt; 500ms 1000ms High-speed camera (clap test) Deepgram Processing &lt; 300ms 500ms API response timestamp delta Local Processing &lt; 50ms 100ms Internal log timestamps Network RTT &lt; 50ms 150ms <code>ping api.deepgram.com</code>"},{"location":"50_qa/performance_benchmarks/#22-throughput-stability","title":"2.2 Throughput &amp; Stability","text":"Metric Target Notes Continuous Runtime 4 hours Typical Sunday service length Memory Usage (Jetson) &lt; 6GB Total system RAM (8GB available) CPU Usage (Jetson) &lt; 50% avg Leave headroom for OS/bursts Disk I/O &lt; 10MB/s NVMe bandwidth is plenty"},{"location":"50_qa/performance_benchmarks/#23-accuracy-wer","title":"2.3 Accuracy (WER)","text":"<p>Word Error Rate targets for \"Church Audio\" domain:</p> Scenario Target WER Notes Clear Speech (Sermon) &lt; 5% Single speaker, good mic Liturgy (Reading) &lt; 3% Predictable text Discussion (Meeting) &lt; 10% Overlapping speech, casual Music/Singing N/A Should be ignored by classifier"},{"location":"50_qa/performance_benchmarks/#3-benchmark-scenarios","title":"3. Benchmark Scenarios","text":""},{"location":"50_qa/performance_benchmarks/#scenario-a-standard-load","title":"Scenario A: Standard Load","text":"<ul> <li>Input: 16kHz Mono WAV (Sermon)</li> <li>Services: All enabled (including identifier)</li> <li>Clients: 10 WebSocket listeners</li> <li>Hardware: Tier 1 (Jetson Orin Nano)</li> </ul>"},{"location":"50_qa/performance_benchmarks/#scenario-b-stress-test","title":"Scenario B: Stress Test","text":"<ul> <li>Input: High-density speech (auctioneer style)</li> <li>Services: All enabled</li> <li>Clients: 50 WebSocket listeners</li> <li>Network: Simulated 5% packet loss, 200ms jitter</li> </ul>"},{"location":"50_qa/performance_benchmarks/#scenario-c-recovery-test","title":"Scenario C: Recovery Test","text":"<ul> <li>Action: Disconnect WAN for 5 minutes</li> <li>Metric: Time to catch up after reconnection</li> <li>Target: Catch-up speed &gt; 2x real-time (e.g., 5 min buffer processed in &lt; 2.5 min)</li> </ul>"},{"location":"50_qa/performance_benchmarks/#4-baseline-results-estimated","title":"4. Baseline Results (Estimated)","text":"Component Latency Contribution Notes Audio Capture 50ms 1600 sample buffer @ 16kHz ZMQ Broker &lt; 1ms Zero-copy transport Network RTT 40ms Fiber connection to US East Deepgram API 250ms Streaming inference Web UI Render 20ms DOM update Total ~361ms Passes Target (&lt;500ms)"},{"location":"50_qa/performance_benchmarks/#5-load-testing-tools","title":"5. Load Testing Tools","text":""},{"location":"50_qa/performance_benchmarks/#locust-websocket-load","title":"<code>locust</code> (WebSocket Load)","text":"<p>Used to simulate multiple client connections to the API Gateway.</p> <pre><code># locustfile.py\nfrom locust import HttpUser, task, between\n\nclass WebsiteUser(HttpUser):\n    wait_time = between(1, 5)\n\n    @task\n    def view_transcript(self):\n        self.client.get(\"/\")\n        # Note: Real test needs WebSocket client simulation\n</code></pre>"},{"location":"50_qa/performance_benchmarks/#stress-ng-system-stress","title":"<code>stress-ng</code> (System Stress)","text":"<p>Used to verify stability under CPU/Memory pressure.</p> <pre><code>stress-ng --cpu 4 --io 2 --vm 1 --vm-bytes 1G --timeout 60s\n</code></pre>"},{"location":"50_qa/performance_benchmarks/#6-optimization-tuning","title":"6. Optimization Tuning","text":"<p>If targets are missed, tune these parameters:</p> <ol> <li>Audio Buffer Size:</li> <li>Current: 1600 samples (100ms)</li> <li>Tuning: Reduce to 800 samples (50ms) \u2192 Reduces capture latency by 50ms</li> <li> <p>Risk: Increased CPU overhead, potential dropouts</p> </li> <li> <p>Deepgram Model:</p> </li> <li>Current: <code>nova-2</code> (balanced)</li> <li> <p>Tuning: Switch to <code>nova-2-general</code> (faster) vs <code>enhanced</code> (slower)</p> </li> <li> <p>ZMQ HWM (High Water Mark):</p> </li> <li>Current: 1000 messages</li> <li>Tuning: Reduce to drop old frames faster during congestion</li> </ol> <p>See Also: - Master Test Plan - Testing strategy - Environmental Constraints - Hardware limits</p>"},{"location":"50_qa/vpat/","title":"Voluntary Product Accessibility Template (VPAT)","text":"<p>Product: live-stt Standard: WCAG 2.1 Level AA</p> Criteria Conformance Level Remarks 1.1.1 Non-text Content Supports Alt text provided 1.2.1 Audio-only and Video-only Not Applicable No media content"},{"location":"60_ops/air_gap_update/","title":"Air-Gap Update Procedure","text":""},{"location":"60_ops/air_gap_update/#prerequisites","title":"Prerequisites","text":"<ul> <li>Secure USB Drive (Encrypted)</li> <li>Update Artifact (<code>update.tar.gz</code>)</li> </ul>"},{"location":"60_ops/air_gap_update/#steps","title":"Steps","text":"<ol> <li>Insert USB drive into port.</li> <li>Mount drive:    <code>bash    mount /dev/sda1 /mnt/usb</code></li> <li>Run update script:    <code>bash    /mnt/usb/update.sh</code></li> <li>Verify checksum.</li> </ol>"},{"location":"60_ops/cicd/","title":"CI/CD Pipeline Documentation","text":""},{"location":"60_ops/cicd/#overview","title":"Overview","text":"<p>This document describes the Continuous Integration and Continuous Deployment pipeline for the Live STT system, including GitHub Actions workflows, Docker build strategy, and Balena deployment automation.</p>"},{"location":"60_ops/cicd/#1-cicd-architecture","title":"1. CI/CD Architecture","text":"<pre><code>flowchart LR\n    A[Git Push] --&gt; B[GitHub Actions]\n    B --&gt; C{Branch?}\n    C --&gt;|main| D[Build &amp; Test]\n    C --&gt;|feature/*| E[Test Only]\n    D --&gt; F[Security Scan]\n    F --&gt; G[Build Multi-Arch Images]\n    G --&gt; H[Push to Docker Hub]\n    H --&gt; I[Balena Deploy]\n    I --&gt; J[Tier 1 Devices]\n</code></pre>"},{"location":"60_ops/cicd/#2-github-actions-workflows","title":"2. GitHub Actions Workflows","text":""},{"location":"60_ops/cicd/#21-test-lint-githubworkflowstestyml","title":"2.1 Test &amp; Lint (<code>.github/workflows/test.yml</code>)","text":"<p>Trigger: Every push, every PR</p> <pre><code>name: Test &amp; Lint\n\non: [push, pull_request]\n\njobs:\n  quality:\n    runs-on: ubuntu-latest\n    steps:\n      - uses: actions/checkout@v4\n\n      - name: Set up Python\n        uses: actions/setup-python@v5\n        with:\n          python-version: '3.13'\n\n      - name: Install uv\n        uses: astral-sh/setup-uv@v3\n        with:\n          version: \"latest\"\n\n      - name: Install dependencies\n        run: uv sync\n\n      - name: Run Ruff (format check)\n        run: uv run ruff format . --check\n\n      - name: Run Ruff (lint)\n        run: uv run ruff check .\n\n      - name: Run MyPy\n        run: uv run mypy .\n\n      - name: Run Pytest\n        run: uv run pytest --cov=services --cov-report=xml\n\n      - name: Upload coverage\n        uses: codecov/codecov-action@v3\n</code></pre>"},{"location":"60_ops/cicd/#22-security-scan-githubworkflowssecurityyml","title":"2.2 Security Scan (<code>.github/workflows/security.yml</code>)","text":"<p>Trigger: Daily cron + every push to <code>main</code></p> <pre><code>name: Security Scan\n\non:\n  schedule:\n    - cron: '0 2 * * *'  # 2 AM daily\n  push:\n    branches: [main]\n\njobs:\n  scan:\n    runs-on: ubuntu-latest\n    steps:\n      - uses: actions/checkout@v4\n\n      - name: Run Safety (Python deps)\n        run: |\n          pip install safety\n          safety check --json | tee safety-report.json\n\n      - name: Run Bandit (code scan)\n        run: |\n          pip install bandit\n          bandit -r services -f json -o bandit-report.json\n\n      - name: Run Trivy (Docker images)\n        uses: aquasecurity/trivy-action@master\n        with:\n          image-ref: 'live-stt/api-gateway:latest'\n          format: 'sarif'\n          output: 'trivy-results.sarif'\n\n      - name: Upload to GitHub Security\n        uses: github/codeql-action/upload-sarif@v2\n        with:\n          sarif_file: 'trivy-results.sarif'\n</code></pre>"},{"location":"60_ops/cicd/#23-deploy-docker-githubworkflowsdeploy-dockeryaml","title":"2.3 Deploy Docker (<code>.github/workflows/deploy-docker.yaml</code>)","text":"<p>Trigger: Tagged releases (<code>v*</code>) ONLY.</p> <pre><code>name: Deploy Docker\n\non:\n  push:\n    tags:\n      - \"v*\"\n\njobs:\n  build-and-push:\n    runs-on: ubuntu-latest\n    steps:\n      - uses: actions/checkout@v4\n      - name: Scaffold Build Context\n        run: |\n          uv run python scripts/scaffold_context.py\n          uv run python scripts/generate_dockerignore.py\n      - name: Build and push (multi-arch)\n        uses: docker/build-push-action@v5\n        # ... builds for linux/amd64,linux/arm64 ...\n\n  deploy-balena:\n    needs: build-and-push\n    runs-on: ubuntu-latest\n    steps:\n      - uses: actions/checkout@v4\n      - name: Deploy to Balena\n        uses: balena-io/deploy-to-balena-action@v0.1.0\n        with:\n          fleet: live-stt-production\n          create_tag: true\n          version: ${{ github.ref_name }}\n</code></pre>"},{"location":"60_ops/cicd/#3-docker-build-strategy","title":"3. Docker Build Strategy","text":""},{"location":"60_ops/cicd/#31-standard-host-deployment-non-balena","title":"3.1 Standard Host Deployment (Non-Balena)","text":"<p>For deploying to a standard container host (e.g., a cloud VM or local server), use the following steps:</p> <ol> <li> <p>Clone the Repository:     <code>bash     git clone https://github.com/yourusername/live-stt.git     cd live-stt</code></p> </li> <li> <p>Install Prerequisites:</p> <ul> <li>Docker &amp; Docker Compose</li> <li><code>uv</code> (Python package manager)</li> <li><code>just</code> (Command runner)</li> </ul> </li> <li> <p>Scaffold and Run:     The <code>just up</code> command automatically scaffolds the build context before starting containers.     <code>bash     # Starts the stack in detached mode     just up</code></p> <p>To force a rebuild: <code>bash just up-build</code></p> </li> </ol>"},{"location":"60_ops/cicd/#32-multi-stage-builds","title":"3.2 Multi-Stage Builds","text":"<pre><code># Example: services/stt-provider/Dockerfile\n\n# Stage 1: Builder (install dependencies)\nFROM ghcr.io/astral-sh/uv:latest as builder\nWORKDIR /app\nCOPY pyproject.toml uv.lock ./\nRUN uv sync --frozen --no-install-project\n\n# Stage 2: Runtime (minimal image)\nFROM python:3.13-slim\nWORKDIR /app\nCOPY --from=builder /app/.venv /app/.venv\nENV PATH=\"/app/.venv/bin:$PATH\"\nCOPY src/ ./src/\nCMD [\"python\", \"-m\", \"src.main\"]\n</code></pre> <p>Benefits: - Smaller images (~150MB vs ~500MB with full build tools) - No build artifacts in production image - Faster deployment to Balena</p>"},{"location":"60_ops/cicd/#32-multi-architecture-support","title":"3.2 Multi-Architecture Support","text":"<pre><code># Build for both x64 (Tier 2/3) and ARM64 (Tier 1)\ndocker buildx build \\\n  --platform linux/amd64,linux/arm64 \\\n  --tag live-stt/api-gateway:latest \\\n  --push \\\n  .\n</code></pre> <p>Supported Platforms: - <code>linux/amd64</code>: Tier 2/3 (desktop, cloud) - <code>linux/arm64</code>: Tier 1 (Jetson Orin Nano)</p>"},{"location":"60_ops/cicd/#33-docker-build-scaffolding-cross-platform","title":"3.3 Docker Build Scaffolding (Cross-Platform)","text":"<p>To enable cross-platform Docker builds (Windows/Linux/macOS) without complex shell commands, we use a Python-based scaffolding approach:</p>"},{"location":"60_ops/cicd/#scaffold-docker-context","title":"Scaffold Docker Context","text":"<p>Before building Docker images, run:</p> <pre><code>python scripts/scaffold_context.py\n</code></pre> <p>This creates <code>.docker-context/</code> containing: - Root <code>uv.lock</code> and <code>pyproject.toml</code> - All service and library <code>pyproject.toml</code> files</p> <p>Why? This ensures Docker dependency layer caching works correctly and avoids platform-specific file path issues.</p>"},{"location":"60_ops/cicd/#generate-dockerignore","title":"Generate .dockerignore","text":"<p>To prevent platform-specific artifacts (<code>.venv/</code>, <code>__pycache__/</code>, etc.) from corrupting Linux containers:</p> <pre><code>python scripts/generate_dockerignore.py\n</code></pre> <p>This generates <code>.dockerignore</code> at the repository root with appropriate exclusions.</p>"},{"location":"60_ops/cicd/#dockerfile-pattern","title":"Dockerfile Pattern","text":"<p>All service Dockerfiles use the <code>.docker-context/</code> pattern:</p> <pre><code># Builder stage\nFROM python:3.12-slim as builder\nCOPY --from=ghcr.io/astral-sh/uv:latest /uv /bin/uv\nWORKDIR /app\n\n# Copy scaffolded build context (dependency files only)\nCOPY .docker-context/ ./\n\n# Install dependencies (cached layer)\nRUN uv sync --frozen --no-install-project --package my-service\n\n# Runtime stage\nFROM python:3.12-slim\nCOPY --from=builder /app/.venv /app/.venv\nENV PATH=\"/app/.venv/bin:$PATH\"\n\n# Copy source code (changes frequently, not cached)\nCOPY libs/messaging ./libs/messaging\nCOPY services/my-service ./services/my-service\nCMD [\"python\", \"-m\", \"my_service.main\"]\n</code></pre>"},{"location":"60_ops/cicd/#34-layer-caching","title":"3.4 Layer Caching","text":"<pre><code># Copy dependency files first (cache layer)\nCOPY pyproject.toml uv.lock ./\nRUN uv sync --frozen --no-install-project\n\n# Copy source code last (most frequently changed)\nCOPY src/ ./src/\n</code></pre> <p>Cache Hit Rate: ~90% (dependencies change infrequently)</p>"},{"location":"60_ops/cicd/#4-balena-deployment-workflow","title":"4. Balena Deployment Workflow","text":""},{"location":"60_ops/cicd/#41-balena-build-process","title":"4.1 Balena Build Process","text":"<pre><code>sequenceDiagram\n    participant Dev as Developer\n    participant GH as GitHub Actions\n    participant Balena as BalenaCloud\n    participant Device as Jetson Device\n\n    Dev-&gt;&gt;GH: git push (tag v1.2.3)\n    GH-&gt;&gt;GH: Run tests\n    GH-&gt;&gt;Balena: balena push live-stt-production\n    Balena-&gt;&gt;Balena: Build Docker images\n    Balena-&gt;&gt;Balena: Generate delta (changed layers only)\n    Balena-&gt;&gt;Device: Push delta (~10MB)\n    Device-&gt;&gt;Device: Pull images, restart containers\n    Device--&gt;&gt;Balena: Health check success\n</code></pre>"},{"location":"60_ops/cicd/#42-deployment-environments","title":"4.2 Deployment Environments","text":"Environment Balena Fleet Trigger Devices Development live-stt-dev Manual push 1 test device Staging live-stt-staging Push to <code>main</code> 1 staging device Production live-stt-production Tagged release (<code>v*</code>) All production devices"},{"location":"60_ops/cicd/#43-rollback-procedure","title":"4.3 Rollback Procedure","text":"<pre><code># Via Balena CLI\nbalena fleet live-stt-production\nbalena release list\nbalena device set-release &lt;DEVICE_UUID&gt; &lt;PREVIOUS_RELEASE_ID&gt;\n\n# Via Balena Dashboard\n# 1. Navigate to fleet\n# 2. Click \"Releases\"\n# 3. Pin device to previous release\n</code></pre> <p>Rollback Time: ~5 minutes (download previous release)</p>"},{"location":"60_ops/cicd/#5-testing-strategy","title":"5. Testing Strategy","text":""},{"location":"60_ops/cicd/#51-unit-tests","title":"5.1 Unit Tests","text":"<pre><code># Run locally\nuv run pytest tests/unit/\n\n# Coverage threshold: 80%\nuv run pytest --cov=services --cov-fail-under=80\n</code></pre>"},{"location":"60_ops/cicd/#52-integration-tests","title":"5.2 Integration Tests","text":"<pre><code># Requires Docker Compose\ndocker compose -f docker-compose.test.yml up --abort-on-container-exit\n\n# Tests:\n# - Mock audio \u2192 broker \u2192 stt-provider \u2192 api-gateway\n# - WebSocket broadcast to multiple clients\n# - Database CRUD operations\n</code></pre>"},{"location":"60_ops/cicd/#53-end-to-end-tests-manual","title":"5.3 End-to-End Tests (Manual)","text":"<p>Cadence: Before each production release</p> <p>Checklist: - [ ] Deploy to staging device - [ ] Verify live transcription with real microphone - [ ] Test 10-minute outage recovery (disconnect internet) - [ ] Enroll test voiceprint, verify speaker ID - [ ] Check admin dashboard accessibility</p>"},{"location":"60_ops/cicd/#6-deployment-metrics","title":"6. Deployment Metrics","text":""},{"location":"60_ops/cicd/#61-build-performance","title":"6.1 Build Performance","text":"Metric Target Current Trend CI Test Duration \\&lt;5 min 3.2 min \u2705 Docker Build Time \\&lt;10 min 8.5 min \u2705 Balena Deploy (Delta) \\&lt;5 min 4.1 min \u2705 Balena Deploy (Full) \\&lt;15 min 12.3 min \u2705"},{"location":"60_ops/cicd/#62-deployment-frequency","title":"6.2 Deployment Frequency","text":"<ul> <li>Development: ~5 deploys/day</li> <li>Staging: ~3 deploys/week</li> <li>Production: ~1 deploy/month</li> </ul>"},{"location":"60_ops/cicd/#63-failure-rate","title":"6.3 Failure Rate","text":"<ul> <li>CI Test Failures: \\&lt;5% (flaky tests excluded)</li> <li>Deployment Failures: \\&lt;2%</li> </ul>"},{"location":"60_ops/cicd/#7-secret-management-in-cicd","title":"7. Secret Management in CI/CD","text":""},{"location":"60_ops/cicd/#github-secrets","title":"GitHub Secrets","text":"Secret Used In Purpose DOCKERHUB_USERNAME <code>deploy.yml</code> Docker Hub login DOCKERHUB_TOKEN <code>deploy.yml</code> Docker Hub authentication BALENA_API_TOKEN <code>deploy.yml</code> Balena CLI authentication CODECOV_TOKEN <code>test.yml</code> Code coverage upload <p>Rotation Policy: Every 90 days (automated via GitHub API)</p>"},{"location":"60_ops/cicd/#runtime-secrets-balena","title":"Runtime Secrets (Balena)","text":"<ul> <li>Configured via Balena environment variables (not in Git)</li> <li>See Secrets Manifest</li> </ul>"},{"location":"60_ops/cicd/#8-continuous-monitoring","title":"8. Continuous Monitoring","text":""},{"location":"60_ops/cicd/#81-build-status-badges","title":"8.1 Build Status Badges","text":"<pre><code>[![Tests](https://github.com/user/live-stt/workflows/test/badge.svg)](https://github.com/user/live-stt/actions)\n[![Security](https://github.com/user/live-stt/workflows/security/badge.svg)](https://github.com/user/live-stt/actions)\n</code></pre>"},{"location":"60_ops/cicd/#82-balena-fleet-health","title":"8.2 Balena Fleet Health","text":"<p>Dashboard: <code>https://dashboard.balena-cloud.com/apps/&lt;fleet-id&gt;</code></p> <p>Alerts: - Device offline &gt;1 hour \u2192 Slack notification - Failed update &gt;2 retries \u2192 Email alert</p>"},{"location":"60_ops/cicd/#9-dependency-updates-automated","title":"9. Dependency Updates (Automated)","text":""},{"location":"60_ops/cicd/#dependabot-configuration-githubdependabotyml","title":"Dependabot Configuration (<code>.github/dependabot.yml</code>)","text":"<pre><code>version: 2\nupdates:\n  - package-ecosystem: \"pip\"\n    directory: \"/\"\n    schedule:\n      interval: \"weekly\"\n    open-pull-requests-limit: 5\n\n  - package-ecosystem: \"docker\"\n    directory: \"/services/api-gateway\"\n    schedule:\n      interval: \"weekly\"\n</code></pre> <p>Review Process: 1. Dependabot opens PR 2. CI runs tests automatically 3. If tests pass \u2192 Auto-merge (minor/patch updates) 4. If tests fail \u2192 Manual review</p>"},{"location":"60_ops/cicd/#10-release-process","title":"10. Release Process","text":""},{"location":"60_ops/cicd/#versioning-semantic-versioning-semver","title":"Versioning: Semantic Versioning (SemVer)","text":"<ul> <li>Major (v2.0.0): Breaking changes (API, database schema)</li> <li>Minor (v1.1.0): New features (backward-compatible)</li> <li>Patch (v1.0.1): Bug fixes</li> </ul>"},{"location":"60_ops/cicd/#release-checklist","title":"Release Checklist","text":"<pre><code># 1. Update CHANGELOG.md\n# 2. Bump version in pyproject.toml\n# 3. Create Git tag\ngit tag -a v1.2.3 -m \"Release v1.2.3\"\ngit push origin v1.2.3\n\n# 4. GitHub Actions automatically:\n#    - Builds Docker images\n#    - Runs security scans\n#    - Deploys to Balena production fleet\n#    - Creates GitHub Release with notes\n</code></pre> <p>See Also: - Runbooks - Deployment procedures - SBOM - Dependency inventory - Secrets Manifest - CI/CD credentials</p>"},{"location":"60_ops/deployment_checklist/","title":"Deployment Pre-Flight Checklist (v7.3)","text":""},{"location":"60_ops/deployment_checklist/#overview","title":"Overview","text":"<p>Complete this checklist before deploying Live STT (v7.3 Industrial Split-Brain) to production.</p>"},{"location":"60_ops/deployment_checklist/#1-hardware-validation-asrock-nuc-n97","title":"1. Hardware Validation (ASRock NUC N97)","text":""},{"location":"60_ops/deployment_checklist/#11-bios-settings","title":"1.1 BIOS Settings","text":"<ul> <li>[ ] Restore AC Power Loss: Power On</li> <li>[ ] Watchdog Timer: Enabled</li> <li>[ ] Virtualization: VT-d Enabled (for Docker)</li> </ul>"},{"location":"60_ops/deployment_checklist/#12-audio-interface-focusrite-solo","title":"1.2 Audio Interface (Focusrite Solo)","text":"<ul> <li>[ ] Sample Rate: 48kHz (System default) -&gt; 16kHz (Resampled by PipeWire)</li> <li>[ ] Gain Knob: Set to ~50% (Green halo on speech)</li> <li>[ ] Phantom Power (48V): OFF (unless using condenser mic)</li> </ul>"},{"location":"60_ops/deployment_checklist/#13-thermal-stress","title":"1.3 Thermal Stress","text":"<ul> <li>[ ] Burn-in: Run <code>stress-ng</code> for 30 mins.</li> <li>[ ] Check: Case should be warm but touchable. No throttling.</li> </ul>"},{"location":"60_ops/deployment_checklist/#2-software-validation","title":"2. Software Validation","text":""},{"location":"60_ops/deployment_checklist/#21-nats-messaging","title":"2.1 NATS Messaging","text":"<ul> <li>[ ] Health Check: <code>just nats-health</code> returns OK.</li> <li>[ ] Persistence: \"Black Box\" mount (<code>/data/nats</code>) is writable.</li> <li>[ ] Spy Test: <code>just nats-spy</code> shows <code>audio.raw</code> traffic when speaking.</li> </ul>"},{"location":"60_ops/deployment_checklist/#22-deepgram-connectivity","title":"2.2 Deepgram Connectivity","text":"<ul> <li>[ ] API Key: Valid (Check <code>stt-provider</code> logs).</li> <li>[ ] Latency: Transcript appears &lt; 1s after speech.</li> </ul>"},{"location":"60_ops/deployment_checklist/#23-biometrics","title":"2.3 Biometrics","text":"<ul> <li>[ ] Enrollment: Successfully enroll a test user.</li> <li>[ ] Identification: Speak as test user -&gt; Transcript shows correct name.</li> </ul>"},{"location":"60_ops/deployment_checklist/#3-failure-recovery","title":"3. Failure Recovery","text":"<ul> <li>[ ] Unplug Internet: System buffers audio.</li> <li>[ ] Reconnect Internet: Transcripts \"catch up\" rapidly.</li> <li>[ ] Power Pull: System reboots automatically and resumes.</li> </ul>"},{"location":"60_ops/deployment_checklist/#sign-off","title":"Sign-Off","text":"<p>Deployed By: __ Date: __ Device UUID: ___ WER Score: ______%</p>"},{"location":"60_ops/drp/","title":"Disaster Recovery Plan (DRP)","text":""},{"location":"60_ops/drp/#scenario-bricked-device","title":"Scenario: Bricked Device","text":"<p>Goal: Restore to factory state.</p>"},{"location":"60_ops/drp/#procedure","title":"Procedure","text":"<ol> <li>Boot into Recovery Mode (Hold button A during power on).</li> <li>Flash factory image via USB-C.</li> <li>Restore configuration from backup.</li> </ol>"},{"location":"60_ops/nats_tooling/","title":"NATS Developer Tooling","text":""},{"location":"60_ops/nats_tooling/#overview","title":"Overview","text":"<p>This document describes the tooling available for developing, debugging, and monitoring the NATS messaging backbone in the Live STT system.</p>"},{"location":"60_ops/nats_tooling/#1-nats-cli-nats-box","title":"1. NATS CLI (<code>nats-box</code>)","text":"<p>We use the official <code>natsio/nats-box</code> Docker image to interact with the NATS server. This provides a pre-configured environment with <code>nats</code>, <code>nats-top</code>, and <code>stan-sub</code> tools.</p>"},{"location":"60_ops/nats_tooling/#common-commands-via-just","title":"Common Commands (via <code>just</code>)","text":"Command Description Equivalent Raw Command <code>just nats-cli</code> Open interactive shell <code>docker run -it nats-box sh</code> <code>just nats-spy</code> Watch all messages <code>nats sub \"&gt;\"</code> <code>just nats-health</code> Check server status <code>nats server check</code>"},{"location":"60_ops/nats_tooling/#manual-debugging","title":"Manual Debugging","text":"<p>Inside the <code>nats-cli</code> shell:</p> <pre><code># List all streams\nnats stream ls\n\n# View stream details\nnats stream info EVENTS\n\n# Publish a test message\nnats pub audio.raw \"test-data\"\n\n# Benchmark pub/sub performance\nnats bench audio.raw --pub 1 --sub 1 --msgs 10000\n</code></pre>"},{"location":"60_ops/nats_tooling/#2-observability-nats-surveyor","title":"2. Observability (NATS Surveyor)","text":"<p>We use NATS Surveyor for visual monitoring of the NATS cluster.</p>"},{"location":"60_ops/nats_tooling/#access","title":"Access","text":"<ul> <li>URL: <code>http://localhost:8080</code> (when running <code>docker compose up</code>)</li> <li>Metrics:</li> <li>Message throughput</li> <li>Client connections</li> <li>JetStream storage usage</li> <li>Slow consumers</li> </ul>"},{"location":"60_ops/nats_tooling/#configuration","title":"Configuration","text":"<p>Surveyor is configured in <code>docker-compose.dev.yml</code>:</p> <pre><code>nats-surveyor:\n  image: natsio/nats-surveyor:latest\n  environment:\n    - SURVEYOR_SERVERS=nats://nats:4222\n</code></pre>"},{"location":"60_ops/nats_tooling/#3-message-tracing","title":"3. Message Tracing","text":"<p>All messages in the system include a <code>trace_id</code> header for distributed tracing.</p>"},{"location":"60_ops/nats_tooling/#inspecting-headers","title":"Inspecting Headers","text":"<p>To view headers, use the <code>--headers</code> flag with <code>nats sub</code>:</p> <pre><code>nats sub \"&gt;\" --headers\n</code></pre> <p>Output Example:</p> <pre><code>[#1] Received on \"text.transcript\"\nNats-Msg-Id: nuid_12345\nTrace-Id: 550e8400-e29b-41d4-a716-446655440000\nTimestamp: 2025-11-26T12:00:00Z\n\n{\"text\": \"Hello world...\"}\n</code></pre>"},{"location":"60_ops/nats_tooling/#4-structured-logging","title":"4. Structured Logging","text":"<p>Services log to stdout in JSON format, including the <code>trace_id</code>.</p> <p>Example Log:</p> <pre><code>{\n  \"level\": \"INFO\",\n  \"timestamp\": \"2025-11-26T12:00:00Z\",\n  \"service\": \"stt-provider\",\n  \"trace_id\": \"550e8400-e29b-41d4-a716-446655440000\",\n  \"message\": \"Published transcript event\",\n  \"subject\": \"text.transcript\"\n}\n</code></pre> <p>Use <code>docker compose logs -f | grep &lt;trace_id&gt;</code> to trace a request across all services.</p>"},{"location":"60_ops/runbooks/","title":"Operational Runbooks (v7.3)","text":""},{"location":"60_ops/runbooks/#overview","title":"Overview","text":"<p>This document provides step-by-step procedures for common operational tasks for the Live STT system (v7.3 Industrial Split-Brain).</p>"},{"location":"60_ops/runbooks/#runbook-index","title":"Runbook Index","text":"<ol> <li>NATS Debugging</li> <li>Initial Deployment (Industrial NUC)</li> <li>Recovering from Internet Outage</li> <li>Debugging Audio Issues</li> <li>Rotating Deepgram API Key</li> <li>Emergency Shutdown</li> <li>Troubleshooting Service Crashes</li> </ol>"},{"location":"60_ops/runbooks/#1-nats-debugging","title":"1. NATS Debugging","text":"<p>Purpose: Inspect message flow and troubleshoot communication issues.</p>"},{"location":"60_ops/runbooks/#11-spy-on-all-messages","title":"1.1 Spy on All Messages","text":"<p>Watch live traffic on the bus:</p> <pre><code>just nats-spy\n# Output:\n# [#1] Received on \"audio.raw\"\n# [#2] Received on \"text.transcript\": {\"text\": \"Hello world\", ...}\n</code></pre>"},{"location":"60_ops/runbooks/#12-check-server-health","title":"1.2 Check Server Health","text":"<p>Verify NATS JetStream status:</p> <pre><code>just nats-health\n# Output: OK\n</code></pre>"},{"location":"60_ops/runbooks/#13-inspect-specific-topic","title":"1.3 Inspect Specific Topic","text":"<p>Debug audio flow specifically:</p> <pre><code>just nats-tail subject=\"audio.raw\"\n</code></pre>"},{"location":"60_ops/runbooks/#2-initial-deployment-industrial-nuc","title":"2. Initial Deployment (Industrial NUC)","text":"<p>Prerequisites: - ASRock NUC N97 with BalenaOS flashed - Deepgram API key</p> <p>Steps: 1.  Provision Device: Follow Assembly Guide. 2.  Set Variables (Balena Dashboard):     - <code>DEEPGRAM_API_KEY</code>: <code>&lt;your_key&gt;</code>     - <code>LOG_LEVEL</code>: <code>INFO</code> 3.  Deploy:     <code>bash     balena push live-stt-production</code> 4.  Verify:     - Check \"Black Box\" mount: <code>balena ssh &lt;uuid&gt; mount | grep nats</code>     - Check NATS health: <code>docker logs nats</code></p>"},{"location":"60_ops/runbooks/#3-recovering-from-internet-outage","title":"3. Recovering from Internet Outage","text":"<p>Scenario: Internet drops for 30 minutes during service.</p> <p>Automatic Recovery: 1.  <code>stt-provider</code> detects disconnect. 2.  Audio is buffered to NATS JetStream (persisted to <code>/data/nats</code> \"Black Box\"). 3.  When internet returns, <code>stt-provider</code> replays missed messages. 4.  Transcripts appear with historical timestamps.</p> <p>Manual Verification:</p> <pre><code># Check NATS JetStream storage usage\nbalena ssh &lt;uuid&gt;\ndu -sh /data/nats\n</code></pre>"},{"location":"60_ops/runbooks/#4-debugging-audio-issues","title":"4. Debugging Audio Issues","text":""},{"location":"60_ops/runbooks/#issue-no-audio-detected","title":"Issue: No Audio Detected","text":"<pre><code># 1. Spy on audio.raw subject\njust nats-tail subject=\"audio.raw\"\n# If no messages appear, audio-producer is failing to capture.\n\n# 2. Check audio-producer logs\ndocker compose logs audio-producer\n# Look for \"Input overflow\" or \"Device not found\"\n</code></pre>"},{"location":"60_ops/runbooks/#issue-clipping-alerts","title":"Issue: Clipping Alerts","text":"<pre><code># 1. Check system.alert subject\njust nats-tail subject=\"system.alert\"\n# Look for {\"type\": \"clipping\", \"severity\": \"warn\"}\n\n# 2. Adjust Focusrite Gain Knob (aim for green halo, not red)\n</code></pre>"},{"location":"60_ops/runbooks/#5-rotating-deepgram-api-key","title":"5. Rotating Deepgram API Key","text":"<p>Trigger: Key compromised or expired.</p> <p>Steps: 1.  Generate new key in Deepgram Console. 2.  Update Balena Variable: <code>DEEPGRAM_API_KEY</code>. 3.  Services will auto-restart. 4.  Verify:     <code>bash     docker logs stt-provider | grep \"Connected to Deepgram\"</code></p>"},{"location":"60_ops/runbooks/#6-emergency-shutdown","title":"6. Emergency Shutdown","text":"<p>Scenarios: Fire alarm, power maintenance.</p> <p>Steps: 1.  Graceful: <code>balena ssh &lt;uuid&gt; poweroff</code> 2.  Forced: Hold power button 10s.     - Note: \"Black Box\" journaling prevents corruption even on forced shutdown.</p>"},{"location":"60_ops/runbooks/#7-troubleshooting-service-crashes","title":"7. Troubleshooting Service Crashes","text":""},{"location":"60_ops/runbooks/#stt-provider-crash-loop","title":"stt-provider Crash Loop","text":"<pre><code># 1. Check logs\ndocker logs stt-provider --tail 50\n\n# Common causes:\n# - Invalid API Key (401 Unauthorized)\n# - NATS unreachable (Check nats container)\n</code></pre>"},{"location":"60_ops/runbooks/#nats-server-failing","title":"NATS Server Failing","text":"<pre><code># 1. Check disk space (Black Box full?)\ndf -h /data\n\n# 2. Check permissions\nls -l /data/nats\n# Should be owned by nats:nats (1000:1000)\n</code></pre> <p>See Also: - NATS Tooling - Advanced debugging - HSI - Service topology</p>"},{"location":"60_ops/sbom/","title":"Software Bill of Materials (SBOM)","text":""},{"location":"60_ops/sbom/#overview","title":"Overview","text":"<p>This document catalogs all software dependencies, Docker base images, and third-party libraries used in the Live STT system.</p>"},{"location":"60_ops/sbom/#1-docker-base-images","title":"1. Docker Base Images","text":"Service Base Image Version Source Security Scan broker <code>scratch</code> N/A Docker Hub \u2705 No vulnerabilities (empty image) audio-producer <code>python:3.13-slim</code> 3.13.1 Docker Hub Official \u2705 Scanned weekly stt-provider <code>python:3.13-slim</code> 3.13.1 Docker Hub Official \u2705 Scanned weekly api-gateway <code>python:3.13-slim</code> 3.13.1 Docker Hub Official \u2705 Scanned weekly audio-classifier <code>python:3.13-slim</code> 3.13.1 Docker Hub Official \u2705 Scanned weekly identifier (Tier 1) <code>nvcr.io/nvidia/l4t-pytorch</code> r36.2.0 (Py 3.10) NVIDIA NGC \u2705 Locked to JetPack version identifier (Tier 2) <code>pytorch/pytorch</code> 2.1.0 (Py 3.10) Docker Hub \u2705 PyTorch official health-watchdog <code>python:3.13-slim</code> 3.13.1 Docker Hub Official \u2705 Scanned weekly"},{"location":"60_ops/sbom/#2-python-dependencies","title":"2. Python Dependencies","text":""},{"location":"60_ops/sbom/#core-services-audio-producer-stt-provider-api-gateway","title":"Core Services (audio-producer, stt-provider, api-gateway)","text":"<p>Generated from <code>uv.lock</code> (pinned versions):</p> Package Version License Purpose CVE Status deepgram-sdk 3.3.6 MIT Deepgram API client \u2705 No known CVEs fastapi 0.110.0 MIT Web framework (api-gateway) \u2705 No known CVEs uvicorn 0.27.1 BSD-3 ASGI server \u2705 No known CVEs sounddevice 0.4.6 MIT Audio capture \u2705 Actively maintained (PortAudio wrapper) pyzmq 25.1.2 LGPL+BSD ZMQ bindings \u2705 No known CVEs numpy 1.26.4 BSD Audio processing \u2705 No known CVEs sqlalchemy 2.0.27 MIT ORM for config.db \u2705 No known CVEs cryptography 42.0.5 Apache-2.0/BSD AES encryption \u2705 No known CVEs pydantic 2.6.3 MIT Data validation \u2705 No known CVEs python-multipart 0.0.9 Apache-2.0 File uploads \u2705 No known CVEs <p>Full Dependency Tree: See <code>uv.lock</code> (150+ transitive dependencies)</p>"},{"location":"60_ops/sbom/#ml-services-audio-classifier-identifier","title":"ML Services (audio-classifier, identifier)","text":"Package Version License Purpose CVE Status torch 2.1.0 BSD-3 PyTorch (identifier) \u2705 No known CVEs torchaudio 2.1.0 BSD-2 Audio preprocessing \u2705 No known CVEs speechbrain 0.5.16 Apache-2.0 Speaker identification \u2705 No known CVEs tensorflow-lite 2.15.0 Apache-2.0 YAMNet inference \u2705 No known CVEs"},{"location":"60_ops/sbom/#3-system-libraries-debian-packages-in-docker-images","title":"3. System Libraries (Debian packages in Docker images)","text":"Package Version Purpose Included In libportaudio2 19.6.0-1.2 PyAudio backend audio-producer libzmq5 4.3.4-1 ZMQ library broker, all services libsqlite3-0 3.40.1-2 SQLite library api-gateway libssl3 3.0.11-1 TLS support stt-provider (Deepgram WSS) ca-certificates 20230311 Root CA certs All services <p>Security Updates: Automatically applied via <code>apt-get update &amp;&amp; apt-get upgrade</code> in Dockerfile</p>"},{"location":"60_ops/sbom/#4-pre-trained-ml-models","title":"4. Pre-Trained ML Models","text":"Model Version Source License Size CVE Status YAMNet TFLite (2021) TensorFlow Hub Apache-2.0 10 MB \u2705 No known issues ECAPA-TDNN SpeechBrain Hugging Face Apache-2.0 500 MB \u2705 No known issues <p>Download Location: Models pulled during Docker build from public repositories</p>"},{"location":"60_ops/sbom/#5-javascript-dependencies-web-ui","title":"5. JavaScript Dependencies (Web UI)","text":"<p>None - The Live STT web UI uses vanilla JavaScript (no npm dependencies)</p> <p>Static Assets: - <code>styles.css</code> - Custom CSS (no frameworks) - <code>app.js</code> - WebSocket client (vanilla JS)</p> <p>Rationale: Minimize attack surface, no npm supply chain risk</p>"},{"location":"60_ops/sbom/#6-build-tools-development-only","title":"6. Build Tools (Development Only)","text":"Tool Version Purpose Used In uv latest Python dependency manager CI/CD, local dev ruff 0.2.2 Linter &amp; formatter CI/CD, pre-commit mypy 1.8.0 Type checker CI/CD pytest 8.0.2 Test runner CI/CD docker 25.0.3 Container runtime All environments docker-compose 2.24.6 Multi-container orchestration Tier 2/3"},{"location":"60_ops/sbom/#7-third-party-services","title":"7. Third-Party Services","text":"Service Provider Purpose License/Terms Data Shared Deepgram API Deepgram Inc. Cloud STT Commercial (pay-per-use) PCM audio only BalenaCloud Balena Inc. Fleet management Free tier (10 devices) Docker images, logs <p>Data Residency: - Deepgram: Audio processed in US East (configurable) - BalenaCloud: Metadata stored in AWS (EU/US)</p>"},{"location":"60_ops/sbom/#8-license-compliance","title":"8. License Compliance","text":""},{"location":"60_ops/sbom/#permissive-licenses-no-attribution-required-in-binary","title":"Permissive Licenses (No Attribution Required in Binary)","text":"<ul> <li>MIT: 80% of dependencies</li> <li>Apache-2.0: 15% of dependencies</li> <li>BSD-3: 5% of dependencies</li> </ul>"},{"location":"60_ops/sbom/#copyleft-licenses-must-distribute-source","title":"Copyleft Licenses (Must Distribute Source)","text":"<ul> <li>LGPL: pyzmq (dynamically linked, compliant)</li> <li>GPL-3.0: Live STT codebase (must provide source to users)</li> </ul> <p>Compliance: All dependencies compatible with GPL-3.0</p>"},{"location":"60_ops/sbom/#9-vulnerability-scanning","title":"9. Vulnerability Scanning","text":""},{"location":"60_ops/sbom/#automated-scans-cicd","title":"Automated Scans (CI/CD)","text":"<pre><code># Python dependencies\nsafety check --json\n\n# Docker images\ndocker scan live-stt/api-gateway:latest\n</code></pre> <p>Frequency: - On Commit: Static analysis (Bandit) - Prevent new vulnerabilities in code - Daily: Dependency scanning (Safety, Trivy) - Detect newly disclosed CVEs in dependencies - Weekly: Full container scan - Deep audit of base images</p>"},{"location":"60_ops/sbom/#automated-audits-scheduled","title":"Automated Audits (Scheduled)","text":"<ul> <li>Frequency: Weekly (GitHub Actions / Dependabot)</li> <li>Tools: <code>pip-audit</code>, Snyk, Dependabot</li> <li>SLA: Critical CVEs patched within 24 hours (auto-PR creation)</li> </ul>"},{"location":"60_ops/sbom/#10-dependency-update-policy","title":"10. Dependency Update Policy","text":"Severity Target SLA Notification Critical (CVSS 9.0+) 24 hours email High (CVSS 7.0-8.9) 7 days GitHub issue Medium (CVSS 4.0-6.9) 30 days Automated monthly audit Low (CVSS 0.1-3.9) Best effort Automated quarterly audit <p>Version Pinning: All production dependencies pinned in <code>uv.lock</code> (reproducible builds)</p>"},{"location":"60_ops/sbom/#11-sbom-export-formats","title":"11. SBOM Export Formats","text":""},{"location":"60_ops/sbom/#cyclonedx-json","title":"CycloneDX (JSON)","text":"<pre><code># Pending uv support\n# uv export --format cyclonedx &gt; sbom-cyclonedx.json\n</code></pre>"},{"location":"60_ops/sbom/#spdx-rdf","title":"SPDX (RDF)","text":"<pre><code># Pending uv support\n# uv export --format spdx &gt; sbom-spdx.rdf\n</code></pre> <p>Storage: Committed to <code>/docs/60_ops/sbom/</code> directory with each release</p> <p>See Also: - CI/CD - Automated security scans - Secrets Manifest - Credential inventory - Threat Model - Supply chain risks</p>"},{"location":"60_ops/secrets_manifest/","title":"Secrets Manifest","text":""},{"location":"60_ops/secrets_manifest/#overview","title":"Overview","text":"<p>This document catalogs all secrets, credentials, and encryption keys used in the Live STT system, including storage locations, rotation policies, and access controls.</p>"},{"location":"60_ops/secrets_manifest/#1-secrets-inventory","title":"1. Secrets Inventory","text":"Secret ID Type Purpose Required Tier Rotation Period DEEPGRAM_API_KEY API Key Cloud STT service All 90 days ENCRYPTION_MASTER_KEY AES-256 Key Encrypt per-file keys Tier 2/3 365 days TPM_SEALED_KEY AES-256 Key Encrypt per-file keys Tier 1 Never (sealed to hardware) ADMIN_PASSWORD Password Admin dashboard access All 180 days WEBSOCKET_SECRET JWT Secret WebSocket ticket signing All (M7+) 90 days DB_ENCRYPTION_KEY AES-256 Key Encrypt sensitive DB columns Future 365 days"},{"location":"60_ops/secrets_manifest/#2-secret-storage","title":"2. Secret Storage","text":""},{"location":"60_ops/secrets_manifest/#tier-1-balena","title":"Tier 1 (Balena)","text":"Secret Storage Location Access Method Encryption at Rest DEEPGRAM_API_KEY Balena environment variables <code>os.getenv(\"DEEPGRAM_API_KEY\")</code> \u2705 (Balena Vault) TPM_SEALED_KEY TPM 2.0 PCR registers <code>tpm2_unseal(pcr=[0,7])</code> \u2705 (Hardware-sealed) ADMIN_PASSWORD Balena environment variables <code>os.getenv(\"ADMIN_PASSWORD\")</code> \u2705 (Balena Vault) WEBSOCKET_SECRET Balena environment variables <code>os.getenv(\"WEBSOCKET_SECRET\")</code> \u2705 (Balena Vault)"},{"location":"60_ops/secrets_manifest/#tier-23-docker-compose","title":"Tier 2/3 (Docker Compose)","text":"Secret Storage Location Access Method Encryption at Rest DEEPGRAM_API_KEY <code>.env</code> file (gitignored) <code>os.getenv(\"DEEPGRAM_API_KEY\")</code> \u274c (User responsibility) ENCRYPTION_MASTER_KEY <code>/config/master.key</code> Read from file \u274c (User responsibility) ADMIN_PASSWORD <code>.env</code> file <code>os.getenv(\"ADMIN_PASSWORD\")</code> \u274c (User responsibility) <p>Recommendation (Tier 2/3): Use Docker Secrets for production deployments</p> <pre><code>echo \"&lt;api-key&gt;\" | docker secret create deepgram_api_key -\n</code></pre>"},{"location":"60_ops/secrets_manifest/#3-secret-generation","title":"3. Secret Generation","text":""},{"location":"60_ops/secrets_manifest/#deepgram_api_key","title":"DEEPGRAM_API_KEY","text":"<p>Generation: 1. Sign up at https://console.deepgram.com 2. Navigate to \"API Keys\" 3. Click \"Create New Key\" 4. Copy key (displayed once)</p> <p>Format: <code>a1b2c3d4e5f6...</code> (64-character hex string)</p>"},{"location":"60_ops/secrets_manifest/#encryption_master_key-tier-23","title":"ENCRYPTION_MASTER_KEY (Tier 2/3)","text":"<p>Generation:</p> <pre><code># Generate 256-bit random key\nopenssl rand -hex 32 &gt; /config/master.key\nchmod 600 /config/master.key\n</code></pre> <p>Format: 64-character hex string (32 bytes)</p>"},{"location":"60_ops/secrets_manifest/#tpm_sealed_key-tier-1","title":"TPM_SEALED_KEY (Tier 1)","text":"<p>Generation (automatic on first boot):</p> <pre><code># Performed by Balena OS provisioning script\ntpm2_createprimary -C o -g sha256 -G rsa -c primary.ctx\ntpm2_create -C primary.ctx -g sha256 -G keyedhash \\\n    -r key.priv -u key.pub -I /dev/urandom\ntpm2_load -C primary.ctx -u key.pub -r key.priv -c key.ctx\ntpm2_evictcontrol -C o -c key.ctx 0x81000001  # Persist to NV\n</code></pre> <p>Format: Binary blob (not human-readable)</p>"},{"location":"60_ops/secrets_manifest/#admin_password","title":"ADMIN_PASSWORD","text":"<p>Generation:</p> <pre><code># Generate strong random password\nopenssl rand -base64 24\n# Example output: \"Xk9J2mN8pL4qR7sT3vW6yZ1a\"\n</code></pre> <p>Requirements: - Minimum 16 characters - Mix of uppercase, lowercase, numbers, symbols</p>"},{"location":"60_ops/secrets_manifest/#websocket_secret-m7","title":"WEBSOCKET_SECRET (M7+)","text":"<p>Generation:</p> <pre><code>openssl rand -hex 32\n</code></pre> <p>Format: 64-character hex string</p>"},{"location":"60_ops/secrets_manifest/#4-secret-access-matrix","title":"4. Secret Access Matrix","text":"Secret Service Permission Why Needed DEEPGRAM_API_KEY stt-provider Read Connect to Deepgram WSS ENCRYPTION_MASTER_KEY api-gateway Read Decrypt per-file keys ENCRYPTION_MASTER_KEY stt-provider Read Encrypt audio snippets ENCRYPTION_MASTER_KEY identifier Read Decrypt voiceprints ADMIN_PASSWORD api-gateway Read Verify admin login WEBSOCKET_SECRET api-gateway Read Sign/verify JWT tickets TPM_SEALED_KEY api-gateway Read Unseal master key <p>Principle of Least Privilege: No service has access to secrets it doesn't need</p>"},{"location":"60_ops/secrets_manifest/#5-secret-rotation-procedures","title":"5. Secret Rotation Procedures","text":""},{"location":"60_ops/secrets_manifest/#rotating-deepgram_api_key","title":"Rotating DEEPGRAM_API_KEY","text":"<p>Trigger: Every 90 days, or on suspected compromise</p> <p>Steps: 1. Generate new key in Deepgram console 2. Update environment variable (see Runbooks) 3. Restart <code>stt-provider</code> service 4. Verify connectivity in logs 5. Revoke old key in Deepgram console</p> <p>Downtime: ~30 seconds</p>"},{"location":"60_ops/secrets_manifest/#rotating-encryption_master_key-tier-23","title":"Rotating ENCRYPTION_MASTER_KEY (Tier 2/3)","text":"<p>Trigger: Every 365 days, or on suspected compromise</p> <p>\u26a0\ufe0f WARNING: This requires re-encrypting all existing files</p> <p>Steps:</p> <pre><code># 1. Stop all services\ndocker compose down\n\n# 2. Generate new master key\nopenssl rand -hex 32 &gt; /config/master.key.new\n\n# 3. Re-encrypt all per-file keys in database\npython scripts/rotate_master_key.py \\\n    --old /config/master.key \\\n    --new /config/master.key.new\n\n# 4. Replace master key\nmv /config/master.key /config/master.key.old\nmv /config/master.key.new /config/master.key\n\n# 5. Restart services\ndocker compose up -d\n\n# 6. Verify (test voiceprint decryption)\n# 7. Delete old key\nshred -u /config/master.key.old\n</code></pre> <p>Downtime: ~5 minutes</p>"},{"location":"60_ops/secrets_manifest/#rotating-tpm_sealed_key-tier-1","title":"Rotating TPM_SEALED_KEY (Tier 1)","text":"<p>Not recommended: TPM key is sealed to hardware and boot state. Rotation requires reflashing entire device.</p> <p>Alternative: If compromise suspected, wipe device and start fresh.</p>"},{"location":"60_ops/secrets_manifest/#rotating-admin_password","title":"Rotating ADMIN_PASSWORD","text":"<p>Trigger: Every 180 days, or on suspected compromise</p> <p>Steps: 1. Generate new password 2. Update <code>ADMIN_PASSWORD</code> environment variable 3. Restart <code>api-gateway</code> service 4. Verify login with new password</p> <p>Downtime: None (admin dashboard only)</p>"},{"location":"60_ops/secrets_manifest/#6-secret-leak-detection","title":"6. Secret Leak Detection","text":""},{"location":"60_ops/secrets_manifest/#pre-commit-hook-git","title":"Pre-Commit Hook (Git)","text":"<pre><code># Install pre-commit framework\npip install pre-commit\n\n# .pre-commit-config.yaml\nrepos:\n  - repo: https://github.com/Yelp/detect-secrets\n    rev: v1.4.0\n    hooks:\n      - id: detect-secrets\n        args: ['--baseline', '.secrets.baseline']\n</code></pre> <p>Excluded Patterns: - <code>.env.example</code> (placeholder values only) - <code>test_fixtures/</code> (fake keys for testing)</p>"},{"location":"60_ops/secrets_manifest/#continuous-monitoring","title":"Continuous Monitoring","text":"<pre><code># Scan codebase for hardcoded secrets\ndocker run --rm -v $(pwd):/src trufflesecurity/trufflehog git file:///src\n</code></pre> <p>CI/CD Integration: Fails build if secrets detected</p>"},{"location":"60_ops/secrets_manifest/#7-secret-compromise-response","title":"7. Secret Compromise Response","text":""},{"location":"60_ops/secrets_manifest/#deepgram_api_key-leak","title":"DEEPGRAM_API_KEY Leak","text":"<p>Impact: Unauthorized STT usage (cost escalation)</p> <p>Response: 1. Immediately revoke key in Deepgram console 2. Generate new key and rotate (see above) 3. Review Deepgram usage logs for anomalies 4. Enable rate limiting on new key</p>"},{"location":"60_ops/secrets_manifest/#encryption_master_key-leak","title":"ENCRYPTION_MASTER_KEY Leak","text":"<p>Impact: All encrypted files can be decrypted</p> <p>Response: 1. If backups exist: Reflash device, restore from backup with new key 2. If no backups: Rotate master key (see above) 3. If voiceprints compromised: Notify affected speakers (GDPR/BIPA requirement)</p>"},{"location":"60_ops/secrets_manifest/#tpm_sealed_key-leak","title":"TPM_SEALED_KEY Leak","text":"<p>Impact: Minimal (key cannot be unsealed without physical device + secure boot)</p> <p>Response: No action required (key is hardware-bound)</p>"},{"location":"60_ops/secrets_manifest/#8-secret-sharing-team-access","title":"8. Secret Sharing (Team Access)","text":""},{"location":"60_ops/secrets_manifest/#development-secrets-tier-3","title":"Development Secrets (Tier 3)","text":"<p>Storage: 1Password or BitWarden shared vault</p> <p>Access: - Deepgram API key: Read-only, shared with all developers - Admin password: Development instance only (not production)</p>"},{"location":"60_ops/secrets_manifest/#production-secrets-tier-1","title":"Production Secrets (Tier 1)","text":"<p>Storage: Balena environment variables (admin access only)</p> <p>Access: - Only system administrator (USER) - No shared credentials</p> <p>Audit Trail: Balena logs all environment variable changes</p>"},{"location":"60_ops/secrets_manifest/#9-secrets-in-logs","title":"9. Secrets in Logs","text":""},{"location":"60_ops/secrets_manifest/#log-sanitization-rules","title":"Log Sanitization Rules","text":"<pre><code># api-gateway logging filter\nimport logging\nimport re\n\nclass SanitizeSecretsFilter(logging.Filter):\n    def filter(self, record):\n        # Redact API keys\n        record.msg = re.sub(\n            r'DEEPGRAM_API_KEY=[\\w]{64}',\n            'DEEPGRAM_API_KEY=***REDACTED***',\n            str(record.msg)\n        )\n        return True\n\nlogging.getLogger().addFilter(SanitizeSecretsFilter())\n</code></pre> <p>Never Logged: - Full API keys (only first 8 characters: <code>a1b2c3d4...</code>) - Encryption keys (never referenced in logs) - Admin passwords (only hashed values)</p>"},{"location":"60_ops/secrets_manifest/#10-compliance","title":"10. Compliance","text":"Regulation Requirement Implementation PCI DSS No plaintext secrets in logs Log sanitization filter GDPR Encryption key management Per-file keys, crypto-shredding BIPA Biometric data security TPM sealing, voiceprint encryption <p>See Also: - Threat Model - Secret compromise scenarios - Biometric Policy - Voiceprint encryption procedures - Runbooks - Secret rotation procedures</p>"},{"location":"70_legal/dpia/","title":"Data Protection Impact Assessment (DPIA)","text":"<p>[!IMPORTANT] Status: TODO This document will be populated prior to the V1.0 production release.</p>"},{"location":"70_legal/dpia/#purpose","title":"Purpose","text":"<p>To assess privacy risks associated with biometric voiceprint collection (BIPA/GDPR).</p>"},{"location":"70_legal/dpia/#planned-content","title":"Planned Content","text":"<ul> <li>Data flow analysis</li> <li>Risk assessment (unauthorized access, misuse)</li> <li>Mitigation strategies (encryption, crypto-shredding, automated retention)</li> <li>data-sweeper service: Automated deletion of review files &gt; RETENTION_HOURS</li> <li>Consultation with stakeholders</li> </ul>"},{"location":"70_legal/eula/","title":"End User License Agreement (EULA)","text":"<p>[!IMPORTANT] Status: TODO This document will be populated prior to the V1.0 production release.</p>"},{"location":"70_legal/eula/#purpose","title":"Purpose","text":"<p>To define terms of use for the appliance.</p>"},{"location":"70_legal/eula/#planned-content","title":"Planned Content","text":"<ul> <li>Grant of license (GPL-3.0)</li> <li>Restrictions on misuse (e.g., surveillance)</li> <li>Warranty disclaimer</li> <li>Liability limitation</li> </ul>"},{"location":"70_legal/license_attestation/","title":"License Attestation","text":""},{"location":"70_legal/license_attestation/#overview","title":"Overview","text":"<p>This document attests to the open-source license compliance of the Live STT system and its dependencies.</p>"},{"location":"70_legal/license_attestation/#1-project-license","title":"1. Project License","text":"<p>Live STT is licensed under the GNU General Public License v3.0 (GPL-3.0). - Source Code: Available at https://github.com/TomDakan/LiveSTT.git - Modifications: Any modifications to this software must be released under GPL-3.0 if distributed. - Network Use: Under GPL-3.0, network interaction does not trigger source distribution requirements (unlike AGPL), but we voluntarily provide source access.</p>"},{"location":"70_legal/license_attestation/#2-dependency-licenses","title":"2. Dependency Licenses","text":"<p>The following third-party libraries are used. All are compatible with GPL-3.0.</p>"},{"location":"70_legal/license_attestation/#python-dependencies","title":"Python Dependencies","text":"Package License Compatibility Notes FastAPI MIT \u2705 Yes Permissive Uvicorn BSD-3-Clause \u2705 Yes Permissive Deepgram SDK MIT \u2705 Yes Permissive PyZMQ LGPL+BSD \u2705 Yes Dynamically linked SoundDevice MIT \u2705 Yes Permissive NumPy BSD-3-Clause \u2705 Yes Permissive SQLAlchemy MIT \u2705 Yes Permissive Cryptography Apache-2.0 \u2705 Yes Permissive"},{"location":"70_legal/license_attestation/#machine-learning-models","title":"Machine Learning Models","text":"Model License Compatibility Notes SpeechBrain Apache-2.0 \u2705 Yes Permissive YAMNet Apache-2.0 \u2705 Yes Permissive"},{"location":"70_legal/license_attestation/#system-libraries-docker","title":"System Libraries (Docker)","text":"<ul> <li>Debian Base Image: GPL/LGPL/MIT/BSD (Standard Linux distribution licenses)</li> <li>NVIDIA L4T: Proprietary drivers (Tier 1 only). Allowed under system library exception or non-distribution (internal use).</li> </ul>"},{"location":"70_legal/license_attestation/#3-attribution-notices","title":"3. Attribution Notices","text":""},{"location":"70_legal/license_attestation/#apache-20-components","title":"Apache-2.0 Components","text":"<p>This product includes software developed by the Apache Software Foundation (http://www.apache.org/).</p>"},{"location":"70_legal/license_attestation/#mit-components","title":"MIT Components","text":"<p>Permission is hereby granted, free of charge, to any person obtaining a copy of this software...</p>"},{"location":"70_legal/license_attestation/#4-non-open-source-components","title":"4. Non-Open Source Components","text":"<ul> <li>Deepgram API: This is a remote SaaS service. The API client SDK is open source (MIT), but the backend service is proprietary. This does not violate GPL-3.0 as the backend code is not linked or distributed.</li> </ul> <p>Disclaimer: This document is for informational purposes and does not constitute legal advice.</p>"},{"location":"90_optional/faq/","title":"Frequently Asked Questions (FAQ)","text":""},{"location":"90_optional/faq/#general","title":"General","text":""},{"location":"90_optional/faq/#q-does-this-system-require-the-internet","title":"Q: Does this system require the internet?","text":"<p>A: Yes and No. - Yes: It needs internet to send audio to Deepgram for transcription. - No: It is \"Offline-First\" in design. If the internet cuts out, it will buffer audio locally and upload it when the connection returns. It will not crash.</p>"},{"location":"90_optional/faq/#q-why-not-use-whisper-running-locally","title":"Q: Why not use Whisper running locally?","text":"<p>A: We evaluated Whisper (see ADR-0004). While accurate, the latency on the Jetson Orin Nano for real-time streaming was too high (&gt;1s) for a live captioning experience. Deepgram offers &lt;300ms latency. We may revisit this as hardware improves.</p>"},{"location":"90_optional/faq/#q-can-i-use-a-raspberry-pi-instead-of-a-jetson","title":"Q: Can I use a Raspberry Pi instead of a Jetson?","text":"<p>A: You can run the core transcription stack (Tier 3) on a Raspberry Pi 4/5. However, the Speaker Identification feature requires a GPU for acceptable performance. On a Pi, speaker ID would be too slow or disabled.</p>"},{"location":"90_optional/faq/#operations","title":"Operations","text":""},{"location":"90_optional/faq/#q-how-do-i-add-a-new-speaker","title":"Q: How do I add a new speaker?","text":"<p>A: Currently, this is done via the API or CLI. A proper Web UI for enrollment is planned for v1.5. See the Biometric Policy for the enrollment script.</p>"},{"location":"90_optional/faq/#q-what-happens-if-the-power-goes-out","title":"Q: What happens if the power goes out?","text":"<p>A: The device should be on a UPS. If power is lost abruptly, the filesystem is journaled (ext4) and should recover, but the current audio buffer in RAM will be lost.</p>"},{"location":"90_optional/faq/#q-how-much-bandwidth-does-it-use","title":"Q: How much bandwidth does it use?","text":"<p>A: Very little. About 50-100 kbps upload for the compressed audio stream. A standard DSL or 4G connection is sufficient.</p>"},{"location":"90_optional/faq/#troubleshooting","title":"Troubleshooting","text":""},{"location":"90_optional/faq/#q-the-transcript-is-stuck-not-showing-up","title":"Q: The transcript is stuck / not showing up.","text":"<p>A: 1. Check if the \"On Air\" light is active on the device. 2. Check your internet connection. 3. Refresh the web page. 4. See Runbooks for detailed logs analysis.</p>"},{"location":"90_optional/faq/#q-it-keeps-identifying-the-wrong-person","title":"Q: It keeps identifying the wrong person.","text":"<p>A: - The speaker might be too far from the mic. - The voiceprint might be poor quality. Try re-enrolling the user. - Adjust the confidence threshold in the config.</p>"},{"location":"90_optional/glossary/","title":"Glossary","text":""},{"location":"90_optional/glossary/#a","title":"A","text":"<ul> <li>ADR (Architecture Decision Record): A document that captures an important architectural decision made along with its context and consequences.</li> <li>Audio Producer: The microservice responsible for capturing audio from the hardware interface (ALSA/USB) and publishing it to the ZMQ broker.</li> </ul>"},{"location":"90_optional/glossary/#b","title":"B","text":"<ul> <li>BalenaOS: A minimal Linux operating system optimized for running Docker containers on embedded devices like the Jetson.</li> <li>Biometric Enrollment: The process of recording a user's voice to create a voiceprint for future identification.</li> </ul>"},{"location":"90_optional/glossary/#d","title":"D","text":"<ul> <li>Deepgram: The third-party API used for Speech-to-Text (STT) transcription.</li> <li>Diarization: The process of partitioning an audio stream into homogeneous segments according to the speaker identity (Who spoke when?).</li> </ul>"},{"location":"90_optional/glossary/#e","title":"E","text":"<ul> <li>ECAPA-TDNN: The neural network architecture used by SpeechBrain for speaker embedding extraction.</li> <li>Edge Computing: Processing data near the source of generation (the Jetson device) rather than in a centralized cloud.</li> </ul>"},{"location":"90_optional/glossary/#g","title":"G","text":"<ul> <li>Glass-to-Glass Latency: The total time elapsed from an event occurring (sound wave) to it being visible on the display (text on screen).</li> </ul>"},{"location":"90_optional/glossary/#h","title":"H","text":"<ul> <li>HSI (Hardware-Software Interface): The boundary where software interacts with physical hardware components.</li> </ul>"},{"location":"90_optional/glossary/#i","title":"I","text":"<ul> <li>Identifier: The microservice responsible for speaker identification using local biometric voiceprints.</li> </ul>"},{"location":"90_optional/glossary/#j","title":"J","text":"<ul> <li>Jetson Orin Nano: The target embedded hardware platform from NVIDIA, featuring an ARM64 CPU and Ampere GPU.</li> </ul>"},{"location":"90_optional/glossary/#p","title":"P","text":"<ul> <li>PCM (Pulse Code Modulation): The standard format for uncompressed digital audio.</li> <li>Provisioning: The process of setting up the hardware and software for the first time.</li> </ul>"},{"location":"90_optional/glossary/#r","title":"R","text":"<ul> <li>RTO (Recovery Time Objective): The targeted duration of time and a service level within which a business process must be restored after a disaster.</li> </ul>"},{"location":"90_optional/glossary/#s","title":"S","text":"<ul> <li>SBOM (Software Bill of Materials): A list of all the open source and third-party components used in the codebase.</li> <li>SpeechBrain: An open-source conversational AI toolkit used for the local speaker identification features.</li> </ul>"},{"location":"90_optional/glossary/#t","title":"T","text":"<ul> <li>Tier 1/2/3: The hardware deployment classification system used in this project (Jetson / Desktop / CPU-only).</li> </ul>"},{"location":"90_optional/glossary/#v","title":"V","text":"<ul> <li>Voiceprint: A mathematical representation (embedding vector) of the unique characteristics of a person's voice.</li> </ul>"},{"location":"90_optional/glossary/#w","title":"W","text":"<ul> <li>WER (Word Error Rate): A common metric for the performance of a speech recognition or machine translation system.</li> <li>WebSocket: A communication protocol that provides full-duplex communication channels over a single TCP connection.</li> </ul>"},{"location":"90_optional/glossary/#z","title":"Z","text":"<ul> <li>ZMQ (ZeroMQ): A high-performance asynchronous messaging library, used for inter-service communication.</li> </ul>"},{"location":"90_optional/troubleshooting/","title":"Troubleshooting","text":"<p>[!NOTE] The troubleshooting guide has been merged into the Runbooks document to keep operational procedures in one place.</p> <p>Please refer to docs/60_ops/runbooks.md.</p>"},{"location":"implementation_guides/00_workflow/","title":"AI Collaboration Workflow: \"Guide-not-Drive\"","text":"<p>This document defines the standard operating procedure for collaboration between the User (Developer) and the AI Agent (Tech Lead/Architect).</p>"},{"location":"implementation_guides/00_workflow/#core-philosophy","title":"Core Philosophy","text":"<ul> <li>Agent as Architect: High-level specifications have already been written in the roadmap and design docs. The Agent's role is to provide guidance and scaffolding.</li> <li>User as Developer: The User writes the actual logic, tests, and implementation details.</li> <li>Code is Truth: The codebase is the final authority. Design discussions happen via code reviews.</li> </ul>"},{"location":"implementation_guides/00_workflow/#the-workflow-loop","title":"The Workflow Loop","text":""},{"location":"implementation_guides/00_workflow/#1-spec-agent","title":"1. Spec (Agent)","text":"<p>The Agent analyzes the requirements and creates a guide in <code>docs/implementation_guides/</code>. The agent must ensure that it reviews any/all .md files that may be relevant to the current task. -   Content: Objectives, Interface Definitions (Protocols), Testing Strategy, Tricky Concepts. -   Output: <code>docs/implementation_guides/XX_feature_name.md</code></p>"},{"location":"implementation_guides/00_workflow/#2-scaffold-agent","title":"2. Scaffold (Agent)","text":"<p>The Agent creates the initial Python files. -   Imports: Necessary libraries and typing. -   Signatures: Strictly typed function/method signatures (<code>def foo(x: int) -&gt; str:</code>). -   Docstrings: Detailed behavior descriptions. -   The \"Hole\": Bodies are left as <code>raise NotImplementedError</code> or <code>pass</code>. -   Tests: Empty test files are created.</p>"},{"location":"implementation_guides/00_workflow/#3-review-refine-user-agent","title":"3. Review &amp; Refine (User + Agent)","text":"<p>Critical Step: Before implementing, the User reviews the scaffold. -   Direct Edit: The User is encouraged to modify signatures, rename methods, or change types directly in the file. -   Sync: The User notifies the Agent of changes. The Agent reads the updated file to align its context.</p>"},{"location":"implementation_guides/00_workflow/#4-implement-user","title":"4. Implement (User)","text":"<p>The User writes the code. -   Tests First: Implement the Mocks and Unit Tests as described in the Guide. -   Logic Second: Implement the concrete classes to pass the tests.</p>"},{"location":"implementation_guides/00_workflow/#5-verify-user","title":"5. Verify (User)","text":"<p>The User runs the project's standard verification tools. -   <code>just test</code>: Ensure all tests pass. -   <code>just lint</code>: Ensure code style compliance. -   <code>just type-check</code>: Ensure strict type safety.</p>"},{"location":"implementation_guides/00_workflow/#design-standards","title":"Design Standards","text":"<ul> <li>Object-Oriented: Prioritize Object-Oriented Design (Classes, Interfaces/Protocols) over functional patterns where idiomatic.</li> <li>Encapsulation: Use classes to bundle state and behavior.</li> <li>Interfaces: Use <code>typing.Protocol</code> or <code>abc.ABC</code> to define clear contracts between components.</li> <li>Data Models: Use standard library <code>@dataclass</code> (prefer <code>frozen=True</code>, <code>slots=True</code>) for value objects. Avoid heavy validation libraries like Pydantic unless necessary for edge I/O.</li> <li>Dependency Injection: Pass dependencies via <code>__init__</code> rather than instantiating them inside classes.</li> <li>Immutability: Prefer immutable state for events and messages to ensure thread-safety in async contexts.</li> </ul>"},{"location":"implementation_guides/00_workflow/#toolchain-constraints","title":"Toolchain Constraints","text":"<ul> <li>Linting: Ruff</li> <li>Typing: MyPy (Strict)</li> <li>Tasks: Just</li> <li>Package Manager: uv</li> <li>Commits: Conventional Commits (via <code>commitizen</code>, see CONTRIBUTING.md section 6)</li> <li>Branching: See CONTRIBUTING.md section 6 for branch naming and merge strategy</li> </ul>"},{"location":"implementation_guides/01_audio_producer/","title":"Implementation Guide: Audio Producer","text":""},{"location":"implementation_guides/01_audio_producer/#objective","title":"Objective","text":"<p>Implement the <code>AudioSource</code> abstraction and a <code>MockAudioSource</code> for testing. This is the foundation of the <code>audio-producer</code> service.</p>"},{"location":"implementation_guides/01_audio_producer/#1-the-interface-audiosource","title":"1. The Interface (<code>AudioSource</code>)","text":"<p>We need a protocol that defines how we get audio. It should be agnostic to the source (Microphone vs. File vs. Mock).</p>"},{"location":"implementation_guides/01_audio_producer/#requirements","title":"Requirements","text":"<ul> <li>Protocol Name: <code>AudioSource</code></li> <li>Method: <code>stream()</code><ul> <li>Returns: An <code>AsyncIterator[bytes]</code> (chunks of raw PCM audio).</li> <li>Context Manager: It should likely be an async context manager (<code>__aenter__</code>/<code>__aexit__</code>) to handle resource cleanup (opening/closing streams).</li> </ul> </li> </ul>"},{"location":"implementation_guides/01_audio_producer/#reference-implementation-scaffold","title":"Reference Implementation (Scaffold)","text":"<pre><code>from typing import Protocol, AsyncIterator, runtime_checkable\n\n@runtime_checkable\nclass AudioSource(Protocol):\n    \"\"\"Interface for an audio source.\"\"\"\n\n    async def stream(self) -&gt; AsyncIterator[bytes]:\n        \"\"\"Yields chunks of raw PCM audio bytes.\"\"\"\n        ...\n</code></pre>"},{"location":"implementation_guides/01_audio_producer/#2-the-implementation-mockaudiosource","title":"2. The Implementation (<code>MockAudioSource</code>)","text":"<p>Since we are on dev machines without specific hardware, we need a Mock that simulates a microphone.</p>"},{"location":"implementation_guides/01_audio_producer/#requirements_1","title":"Requirements","text":"<ul> <li>Class Name: <code>MockAudioSource</code></li> <li>Config: Should accept <code>sample_rate</code> (default 16000) and <code>chunk_size</code> (default 1024 or 4096).</li> <li>Behavior:<ul> <li>In <code>stream()</code>, it should <code>yield</code> bytes.</li> <li>Content: Silence (<code>b'\\x00' * size</code>) or Random Noise (using <code>os.urandom</code> or <code>numpy</code>).</li> <li>Timing: It MUST simulate real-time. If <code>chunk_size</code> represents 100ms of audio, it should <code>await asyncio.sleep(0.1)</code> between yields.</li> </ul> </li> </ul>"},{"location":"implementation_guides/01_audio_producer/#3-testing-strategy","title":"3. Testing Strategy","text":"<p>We need to verify that our <code>MockAudioSource</code> behaves like a real stream.</p>"},{"location":"implementation_guides/01_audio_producer/#test-case-1-interface-compliance","title":"Test Case 1: Interface Compliance","text":"<ul> <li>Verify <code>MockAudioSource</code> implements <code>AudioSource</code> (using <code>isinstance</code> if <code>@runtime_checkable</code> is used, or just duck typing).</li> </ul>"},{"location":"implementation_guides/01_audio_producer/#test-case-2-timing-accuracy","title":"Test Case 2: Timing Accuracy","text":"<ul> <li>Goal: Ensure it doesn't dump all data instantly.</li> <li>Logic:<ol> <li>Initialize <code>MockAudioSource(rate=16000, chunk_size=1600)</code>. (1600 samples @ 16kHz = 0.1 seconds).</li> <li>Consume 10 chunks.</li> <li>Measure elapsed time.</li> <li>Assert elapsed time is roughly 1.0 second (allow some jitter, e.g., 0.9s to 1.1s).</li> </ol> </li> </ul>"},{"location":"implementation_guides/01_audio_producer/#test-case-3-data-format","title":"Test Case 3: Data Format","text":"<ul> <li>Assert yielded chunks are <code>bytes</code>.</li> <li>Assert <code>len(chunk)</code> equals the configured byte size (Note: 16-bit audio = 2 bytes per sample. So <code>chunk_size=1600</code> samples = 3200 bytes).</li> </ul>"},{"location":"implementation_guides/01_audio_producer/#4-helpful-snippets","title":"4. Helpful Snippets","text":""},{"location":"implementation_guides/01_audio_producer/#async-test-structure","title":"Async Test Structure","text":"<pre><code>import pytest\nimport asyncio\nfrom producer import MockAudioSource  # Import from local src\n\n@pytest.mark.asyncio\nasync def test_mock_timing():\n    source = MockAudioSource(rate=16000, chunk_size=1600)\n    # ... implementation ...\n</code></pre>"},{"location":"implementation_guides/02_nats_publisher/","title":"Implementation Guide: NATS Publisher (Audio Producer)","text":""},{"location":"implementation_guides/02_nats_publisher/#objective","title":"Objective","text":"<p>Implement the <code>main.py</code> entrypoint and the <code>NatsAudioPublisher</code> class. This component bridges the <code>AudioSource</code> (data) and NATS (transport).</p>"},{"location":"implementation_guides/02_nats_publisher/#1-the-natsaudiopublisher-class","title":"1. The <code>NatsAudioPublisher</code> Class","text":"<p>This class orchestrates the streaming process.</p>"},{"location":"implementation_guides/02_nats_publisher/#responsibilities","title":"Responsibilities","text":"<ol> <li>Dependency Injection: Accepts an <code>AudioSource</code> and a NATS <code>Client</code> in <code>__init__</code>.</li> <li>Publishing: Iterates over <code>source.stream()</code> and publishes data to the <code>audio.raw</code> subject.</li> <li>Graceful Shutdown: Stops streaming when a stop signal is received.</li> </ol>"},{"location":"implementation_guides/02_nats_publisher/#reference-implementation-scaffold","title":"Reference Implementation (Scaffold)","text":"<pre><code>from dataclasses import dataclass\nfrom nats.aio.client import Client as NATS\nfrom audiosource import AudioSource\n\n@dataclass\nclass NatsAudioPublisher:\n    source: AudioSource\n    nats: NATS\n    subject: str = \"audio.raw\"\n\n    async def start(self) -&gt; None:\n        \"\"\"Consumes audio from source and publishes to NATS.\"\"\"\n        async with self.source as stream_source:\n            async for chunk in stream_source.stream():\n                await self.nats.publish(self.subject, chunk)\n</code></pre>"},{"location":"implementation_guides/02_nats_publisher/#2-the-main-entrypoint","title":"2. The <code>main()</code> Entrypoint","text":"<p>This is the application bootstrapper.</p>"},{"location":"implementation_guides/02_nats_publisher/#responsibilities_1","title":"Responsibilities","text":"<ol> <li>Configuration: Read env vars (e.g., <code>NATS_URL</code>, <code>SAMPLE_RATE</code>).</li> <li>Setup:<ul> <li>Connect to NATS.</li> <li>Initialize <code>MockAudioSource</code> (or <code>PyAudioSource</code> later).</li> <li>Initialize <code>NatsAudioPublisher</code>.</li> </ul> </li> <li>Execution: Run the publisher.</li> <li>Cleanup: Close NATS connection on exit.</li> </ol>"},{"location":"implementation_guides/02_nats_publisher/#nats-connection-pattern","title":"NATS Connection Pattern","text":"<pre><code>nc = NATS()\nawait nc.connect(\"nats://localhost:4222\")\n# ... use nc ...\nawait nc.close()\n</code></pre>"},{"location":"implementation_guides/02_nats_publisher/#3-testing-strategy","title":"3. Testing Strategy","text":"<p>Since this involves network I/O (NATS), we have two options: 1.  Mock NATS: Pass a <code>MockNatsClient</code> to <code>NatsAudioPublisher</code> and verify <code>publish</code> was called. 2.  Integration Test: Run a real NATS server (via <code>just up</code>) and verify messages appear.</p> <p>For this phase, let's focus on Unit Testing with a Mock NATS client.</p>"},{"location":"implementation_guides/02_nats_publisher/#test-case-publish-logic","title":"Test Case: Publish Logic","text":"<ul> <li>Setup: <code>MockAudioSource</code> (yields 3 chunks), <code>MockNatsClient</code>.</li> <li>Action: <code>await publisher.start()</code></li> <li>Assert: <code>MockNatsClient.publish</code> called 3 times with correct subject and data.</li> </ul>"},{"location":"implementation_guides/03_hardware_integration/","title":"Implementation Guide: Hardware Integration","text":""},{"location":"implementation_guides/03_hardware_integration/#objective","title":"Objective","text":"<p>Implement the concrete <code>AudioSource</code> classes for Windows and Linux to capture real microphone audio.</p>"},{"location":"implementation_guides/03_hardware_integration/#1-dependencies","title":"1. Dependencies","text":"<p>We need platform-specific libraries to access the audio hardware.</p> <ul> <li>Windows: <code>pyaudio</code> (PortAudio wrapper).</li> <li>Linux: <code>pyalsaaudio</code> (ALSA wrapper, works with PipeWire via ALSA plugin).</li> </ul>"},{"location":"implementation_guides/03_hardware_integration/#pyprojecttoml-updates","title":"<code>pyproject.toml</code> Updates","text":"<pre><code>dependencies = [\n    \"nats-py&gt;=2.6.0\",\n    \"pyalsaaudio&gt;=0.10.0; sys_platform == 'linux'\",\n    \"pyaudio&gt;=0.2.14; sys_platform == 'win32'\",\n    \"numpy&gt;=1.26.0\",\n]\n</code></pre>"},{"location":"implementation_guides/03_hardware_integration/#2-windowssource-pyaudio","title":"2. <code>WindowsSource</code> (PyAudio)","text":"<p>Uses <code>pyaudio</code> to open a blocking stream and read chunks.</p>"},{"location":"implementation_guides/03_hardware_integration/#implementation-details","title":"Implementation Details","text":"<ul> <li>Init: Initialize <code>PyAudio</code>, open stream (Format=Int16, Channels=1, Rate=16000).</li> <li>Stream: Loop <code>stream.read(chunk_size)</code>.</li> <li>Cleanup: Close stream, terminate PyAudio.</li> <li>Blocking I/O: <code>pyaudio</code> is blocking. We should run the read in a separate thread or use <code>asyncio.to_thread</code> to avoid blocking the asyncio event loop.</li> </ul> <pre><code>import pyaudio\nimport asyncio\n\nclass WindowsSource(AudioSource):\n    def __init__(self, sample_rate: int, chunk_size: int):\n        self.pa = pyaudio.PyAudio()\n        self.stream_obj = self.pa.open(\n            format=pyaudio.paInt16,\n            channels=1,\n            rate=sample_rate,\n            input=True,\n            frames_per_buffer=chunk_size\n        )\n        self.chunk_size = chunk_size\n\n    async def stream(self) -&gt; AsyncIterator[bytes]:\n        while True:\n            # Run blocking read in thread\n            data = await asyncio.to_thread(\n                self.stream_obj.read, self.chunk_size, exception_on_overflow=False\n            )\n            yield data\n</code></pre>"},{"location":"implementation_guides/03_hardware_integration/#3-linuxsource-pyalsaaudio","title":"3. <code>LinuxSource</code> (PyAlsaAudio)","text":"<p>Uses <code>alsaaudio</code> to read from the default capture device (which PipeWire emulates).</p>"},{"location":"implementation_guides/03_hardware_integration/#implementation-details_1","title":"Implementation Details","text":"<ul> <li>Init: <code>alsaaudio.PCM(type=alsaaudio.PCM_CAPTURE, mode=alsaaudio.PCM_NORMAL)</code>.</li> <li>Config: Set channels, rate, format, period size.</li> <li>Stream: <code>l, data = inp.read()</code>.</li> <li>Blocking I/O: Similar to PyAudio, use <code>asyncio.to_thread</code>.</li> </ul> <pre><code>import alsaaudio\nimport asyncio\n\nclass LinuxSource(AudioSource):\n    def __init__(self, sample_rate: int, chunk_size: int):\n        self.inp = alsaaudio.PCM(alsaaudio.PCM_CAPTURE, alsaaudio.PCM_NORMAL)\n        self.inp.setchannels(1)\n        self.inp.setrate(sample_rate)\n        self.inp.setformat(alsaaudio.PCM_FORMAT_S16_LE)\n        self.inp.setperiodsize(chunk_size)\n        self.chunk_size = chunk_size\n\n    async def stream(self) -&gt; AsyncIterator[bytes]:\n        while True:\n            length, data = await asyncio.to_thread(self.inp.read)\n            if length &gt; 0:\n                yield data\n</code></pre>"},{"location":"implementation_guides/03_hardware_integration/#4-testing","title":"4. Testing","text":"<p>Since we cannot easily mock hardware in unit tests, we will rely on: 1.  Manual Verification: Running the service on the actual OS. 2.  Mock Tests: We already have <code>MockAudioSource</code> for logic testing.</p>"},{"location":"implementation_guides/04_stt_provider/","title":"Implementation Guide: STT Provider","text":""},{"location":"implementation_guides/04_stt_provider/#objective","title":"Objective","text":"<p>Implement the <code>stt-provider</code> service, which acts as the bridge between the raw audio stream (NATS) and the cloud transcription engine (Deepgram). It must be robust, handling network interruptions and API failures gracefully.</p>"},{"location":"implementation_guides/04_stt_provider/#1-the-architecture","title":"1. The Architecture","text":"<p>The service follows a \"Hexagonal\" or \"Ports and Adapters\" architecture to allow for easy testing and swapping of components.</p>"},{"location":"implementation_guides/04_stt_provider/#core-components","title":"Core Components","text":"<ol> <li><code>STTService</code>: The main application logic. It orchestrates the flow of data.</li> <li><code>NatsClient</code> (Adapter): Handles communication with the NATS message bus.</li> <li><code>Transcriber</code> (Adapter): Handles communication with the Speech-to-Text API (Deepgram).</li> </ol>"},{"location":"implementation_guides/04_stt_provider/#2-interfaces-protocols","title":"2. Interfaces (Protocols)","text":"<p>We define strict protocols to decouple the core logic from external dependencies.</p>"},{"location":"implementation_guides/04_stt_provider/#21-transcriber-protocol","title":"2.1 <code>Transcriber</code> Protocol","text":"<p>Abstracts the STT engine. This allows us to mock Deepgram for unit tests.</p> <p>Defined in <code>services/stt-provider/src/stt_provider/interfaces.py</code>.</p> <p>Represents a single transcription result.</p> Source code in <code>services/stt-provider/src/stt_provider/interfaces.py</code> <pre><code>@dataclass\nclass TranscriptionEvent:\n    \"\"\"Represents a single transcription result.\"\"\"\n\n    text: str\n    is_final: bool\n    confidence: float\n</code></pre> <p>               Bases: <code>Protocol</code></p> <p>Interface for a Speech-to-Text engine.</p> Source code in <code>services/stt-provider/src/stt_provider/interfaces.py</code> <pre><code>@runtime_checkable\nclass Transcriber(Protocol):\n    \"\"\"Interface for a Speech-to-Text engine.\"\"\"\n\n    async def connect(self) -&gt; None:\n        \"\"\"Establishes connection to the STT provider.\"\"\"\n        ...\n\n    async def send_audio(self, audio: bytes) -&gt; None:\n        \"\"\"Sends a chunk of audio for transcription.\"\"\"\n        ...\n\n    async def finish(self) -&gt; None:\n        \"\"\"Signals end of stream.\"\"\"\n        ...\n\n    def get_events(self) -&gt; AsyncIterator[TranscriptionEvent]:\n        \"\"\"Yields transcription events as they arrive.\"\"\"\n        ...\n</code></pre>"},{"location":"implementation_guides/04_stt_provider/#stt_provider.interfaces.Transcriber.connect","title":"<code>connect()</code>  <code>async</code>","text":"<p>Establishes connection to the STT provider.</p> Source code in <code>services/stt-provider/src/stt_provider/interfaces.py</code> <pre><code>async def connect(self) -&gt; None:\n    \"\"\"Establishes connection to the STT provider.\"\"\"\n    ...\n</code></pre>"},{"location":"implementation_guides/04_stt_provider/#stt_provider.interfaces.Transcriber.finish","title":"<code>finish()</code>  <code>async</code>","text":"<p>Signals end of stream.</p> Source code in <code>services/stt-provider/src/stt_provider/interfaces.py</code> <pre><code>async def finish(self) -&gt; None:\n    \"\"\"Signals end of stream.\"\"\"\n    ...\n</code></pre>"},{"location":"implementation_guides/04_stt_provider/#stt_provider.interfaces.Transcriber.get_events","title":"<code>get_events()</code>","text":"<p>Yields transcription events as they arrive.</p> Source code in <code>services/stt-provider/src/stt_provider/interfaces.py</code> <pre><code>def get_events(self) -&gt; AsyncIterator[TranscriptionEvent]:\n    \"\"\"Yields transcription events as they arrive.\"\"\"\n    ...\n</code></pre>"},{"location":"implementation_guides/04_stt_provider/#stt_provider.interfaces.Transcriber.send_audio","title":"<code>send_audio(audio)</code>  <code>async</code>","text":"<p>Sends a chunk of audio for transcription.</p> Source code in <code>services/stt-provider/src/stt_provider/interfaces.py</code> <pre><code>async def send_audio(self, audio: bytes) -&gt; None:\n    \"\"\"Sends a chunk of audio for transcription.\"\"\"\n    ...\n</code></pre>"},{"location":"implementation_guides/04_stt_provider/#22-natsclient-protocol","title":"2.2 <code>NatsClient</code> Protocol","text":"<p>Defined in <code>libs/messaging/src/messaging/nats.py</code>.</p> <p>               Bases: <code>Protocol</code></p> <p>Interface for NATS interaction.</p> Source code in <code>libs/messaging/src/messaging/nats.py</code> <pre><code>@runtime_checkable\nclass NatsClient(Protocol):\n    \"\"\"Interface for NATS interaction.\"\"\"\n\n    async def publish(self, subject: str, payload: bytes) -&gt; None:\n        \"\"\"Publishes a message to a subject.\"\"\"\n        ...\n\n    async def subscribe(\n        self, subject: str, queue: str = \"\", cb: Any = None, **kwargs: Any\n    ) -&gt; Any:\n        \"\"\"Subscribes to a subject with a callback.\"\"\"\n        ...\n\n    async def close(self) -&gt; None:\n        \"\"\"Closes the connection.\"\"\"\n        ...\n\n    async def connect(self, servers: list[str] | str) -&gt; None:\n        \"\"\"Connects to NATS server(s).\"\"\"\n        ...\n</code></pre>"},{"location":"implementation_guides/04_stt_provider/#messaging.nats.NatsClient.close","title":"<code>close()</code>  <code>async</code>","text":"<p>Closes the connection.</p> Source code in <code>libs/messaging/src/messaging/nats.py</code> <pre><code>async def close(self) -&gt; None:\n    \"\"\"Closes the connection.\"\"\"\n    ...\n</code></pre>"},{"location":"implementation_guides/04_stt_provider/#messaging.nats.NatsClient.connect","title":"<code>connect(servers)</code>  <code>async</code>","text":"<p>Connects to NATS server(s).</p> Source code in <code>libs/messaging/src/messaging/nats.py</code> <pre><code>async def connect(self, servers: list[str] | str) -&gt; None:\n    \"\"\"Connects to NATS server(s).\"\"\"\n    ...\n</code></pre>"},{"location":"implementation_guides/04_stt_provider/#messaging.nats.NatsClient.publish","title":"<code>publish(subject, payload)</code>  <code>async</code>","text":"<p>Publishes a message to a subject.</p> Source code in <code>libs/messaging/src/messaging/nats.py</code> <pre><code>async def publish(self, subject: str, payload: bytes) -&gt; None:\n    \"\"\"Publishes a message to a subject.\"\"\"\n    ...\n</code></pre>"},{"location":"implementation_guides/04_stt_provider/#messaging.nats.NatsClient.subscribe","title":"<code>subscribe(subject, queue='', cb=None, **kwargs)</code>  <code>async</code>","text":"<p>Subscribes to a subject with a callback.</p> Source code in <code>libs/messaging/src/messaging/nats.py</code> <pre><code>async def subscribe(\n    self, subject: str, queue: str = \"\", cb: Any = None, **kwargs: Any\n) -&gt; Any:\n    \"\"\"Subscribes to a subject with a callback.\"\"\"\n    ...\n</code></pre>"},{"location":"implementation_guides/04_stt_provider/#3-the-implementation-deepgramtranscriber","title":"3. The Implementation (<code>DeepgramTranscriber</code>)","text":"<p>This class implements the <code>Transcriber</code> protocol using the official <code>deepgram-sdk</code>.</p>"},{"location":"implementation_guides/04_stt_provider/#requirements","title":"Requirements","text":"<ul> <li>Config: API Key (from env), Audio Format (16kHz, S16LE).</li> <li>Behavior:<ul> <li><code>connect()</code>: Opens the WebSocket connection to Deepgram.</li> <li><code>send_audio()</code>: Forwards bytes to the socket.</li> <li><code>get_events()</code>: Listens to the <code>LiveTranscriptionEvents.Transcript</code> event and yields our internal <code>TranscriptionEvent</code> dataclass.</li> </ul> </li> </ul>"},{"location":"implementation_guides/04_stt_provider/#4-the-implementation-sttservice","title":"4. The Implementation (<code>STTService</code>)","text":"<p>This is the \"glue\" code.</p>"},{"location":"implementation_guides/04_stt_provider/#logic","title":"Logic","text":"<ol> <li>Initialize: Takes <code>NatsClient</code> and <code>Transcriber</code> as dependencies.</li> <li>Run Loop:<ul> <li>Connects to NATS.</li> <li>Subscribes to <code>audio.raw</code>.</li> <li>Connects to Transcriber.</li> <li>Ingest: When NATS message arrives -&gt; <code>transcriber.send_audio()</code>.</li> <li>Egest: Loops over <code>transcriber.get_events()</code> -&gt; Publishes JSON to <code>text.transcript</code>.</li> </ul> </li> <li>Error Handling:<ul> <li>If Deepgram connection dies, it should attempt to reconnect without crashing the service.</li> </ul> </li> </ol>"},{"location":"implementation_guides/04_stt_provider/#5-testing-strategy","title":"5. Testing Strategy","text":""},{"location":"implementation_guides/04_stt_provider/#51-unit-tests-test_stt_servicepy","title":"5.1 Unit Tests (<code>test_stt_service.py</code>)","text":"<ul> <li>Goal: Verify logic without real NATS or Deepgram.</li> <li>Mocks:<ul> <li><code>MockNatsClient</code>: Captures published messages.</li> <li><code>MockTranscriber</code>: Simulates sending audio and receiving fake transcripts.</li> </ul> </li> <li>Scenarios:<ol> <li>Happy Path: Audio in -&gt; Transcript out.</li> <li>Filtering: Ensure empty transcripts are ignored.</li> <li>JSON Format: Verify the output payload structure matches requirements.</li> </ol> </li> </ul>"},{"location":"implementation_guides/04_stt_provider/#52-integration-tests","title":"5.2 Integration Tests","text":"<ul> <li>(Covered separately, but involves real NATS and real Deepgram).</li> </ul>"},{"location":"implementation_guides/04_stt_provider/#6-step-by-step-implementation-plan","title":"6. Step-by-Step Implementation Plan","text":"<ol> <li>Define Protocols: Create <code>src/stt_provider/interfaces.py</code>.</li> <li>Create Mocks: Create <code>tests/mocks.py</code> implementing these protocols.</li> <li>Implement Service: Create <code>src/stt_provider/service.py</code> (The logic).</li> <li>Write Unit Tests: Create <code>tests/test_service.py</code> and verify <code>STTService</code> logic.</li> <li>Implement Deepgram Adapter: Create <code>src/stt_provider/deepgram_adapter.py</code>.</li> <li>Wire it up: Update <code>src/stt_provider/main.py</code> to use the new classes.</li> </ol>"}]}